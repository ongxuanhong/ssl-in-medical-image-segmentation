Epoch 0, iter 1, Dice Sup Loss: 0.46569, BCE Sup Loss: 0.72179
Epoch 0, iter 2, Dice Sup Loss: 0.4515, BCE Sup Loss: 0.65798
Epoch 0, iter 3, Dice Sup Loss: 0.52816, BCE Sup Loss: 0.59994
Epoch 0, iter 4, Dice Sup Loss: 0.52966, BCE Sup Loss: 0.59095
Epoch 0, iter 5, Dice Sup Loss: 0.50859, BCE Sup Loss: 0.64046
Epoch 0, iter 6, Dice Sup Loss: 0.52547, BCE Sup Loss: 0.59865
Epoch 0, iter 7, Dice Sup Loss: 0.44846, BCE Sup Loss: 0.68287
Epoch 0, iter 8, Dice Sup Loss: 0.51112, BCE Sup Loss: 0.61374
Epoch 0, iter 9, Dice Sup Loss: 0.49955, BCE Sup Loss: 0.66578
Epoch 0, iter 10, Dice Sup Loss: 0.50671, BCE Sup Loss: 0.66046
Epoch 0, iter 11, Dice Sup Loss: 0.4549, BCE Sup Loss: 0.68252
Epoch 0, iter 12, Dice Sup Loss: 0.46392, BCE Sup Loss: 0.65483
Epoch 0, iter 13, Dice Sup Loss: 0.5237, BCE Sup Loss: 0.68739
Epoch 0, iter 14, Dice Sup Loss: 0.44077, BCE Sup Loss: 0.66845
Epoch 0, iter 15, Dice Sup Loss: 0.48683, BCE Sup Loss: 0.67709
Epoch 0, iter 16, Dice Sup Loss: 0.46466, BCE Sup Loss: 0.68577
Epoch 0, iter 17, Dice Sup Loss: 0.43195, BCE Sup Loss: 0.68663
Epoch 0, iter 18, Dice Sup Loss: 0.4622, BCE Sup Loss: 0.67295
Epoch 0, iter 19, Dice Sup Loss: 0.46507, BCE Sup Loss: 0.68012
Epoch 0, iter 20, Dice Sup Loss: 0.47711, BCE Sup Loss: 0.67265
Epoch 0, iter 21, Dice Sup Loss: 0.4476, BCE Sup Loss: 0.66775
Epoch 0, iter 22, Dice Sup Loss: 0.45596, BCE Sup Loss: 0.66536
Epoch 0, iter 23, Dice Sup Loss: 0.5154, BCE Sup Loss: 0.63497
Epoch 0, iter 24, Dice Sup Loss: 0.52469, BCE Sup Loss: 0.64667
Epoch 0, iter 25, Dice Sup Loss: 0.45093, BCE Sup Loss: 0.65431
Epoch 0, iter 26, Dice Sup Loss: 0.47728, BCE Sup Loss: 0.66642
Epoch 0, iter 27, Dice Sup Loss: 0.47778, BCE Sup Loss: 0.63285
Epoch 0, iter 28, Dice Sup Loss: 0.47976, BCE Sup Loss: 0.66834
Epoch 0, iter 29, Dice Sup Loss: 0.49291, BCE Sup Loss: 0.67084
Epoch 0, iter 30, Dice Sup Loss: 0.54114, BCE Sup Loss: 0.60373
Epoch 0, Total train step 29 || AVG_loss: 0.5703, Avg Dice score: 0.1235, Avg IOU: 0.0692
Epoch 0, Validation || sum_loss: 1.14135, Dice score: 0.0968, IOU: 0.0543
New best epoch 0!===============================
Training and evaluating on epoch0 complete in 0m 9s
Epoch 1, iter 31, Dice Sup Loss: 0.47576, BCE Sup Loss: 0.66453
Epoch 1, iter 32, Dice Sup Loss: 0.50071, BCE Sup Loss: 0.62558
Epoch 1, iter 33, Dice Sup Loss: 0.46712, BCE Sup Loss: 0.64856
Epoch 1, iter 34, Dice Sup Loss: 0.47258, BCE Sup Loss: 0.65127
Epoch 1, iter 35, Dice Sup Loss: 0.49066, BCE Sup Loss: 0.62768
Epoch 1, iter 36, Dice Sup Loss: 0.46906, BCE Sup Loss: 0.63945
Epoch 1, iter 37, Dice Sup Loss: 0.56431, BCE Sup Loss: 0.66769
Epoch 1, iter 38, Dice Sup Loss: 0.44699, BCE Sup Loss: 0.67666
Epoch 1, iter 39, Dice Sup Loss: 0.50098, BCE Sup Loss: 0.62577
Epoch 1, iter 40, Dice Sup Loss: 0.49983, BCE Sup Loss: 0.6358
Epoch 1, iter 41, Dice Sup Loss: 0.4726, BCE Sup Loss: 0.642
Epoch 1, iter 42, Dice Sup Loss: 0.47846, BCE Sup Loss: 0.64663
Epoch 1, iter 43, Dice Sup Loss: 0.46713, BCE Sup Loss: 0.6436
Epoch 1, iter 44, Dice Sup Loss: 0.48677, BCE Sup Loss: 0.63362
Epoch 1, iter 45, Dice Sup Loss: 0.52219, BCE Sup Loss: 0.61173
Epoch 1, iter 46, Dice Sup Loss: 0.51908, BCE Sup Loss: 0.60238
Epoch 1, iter 47, Dice Sup Loss: 0.48836, BCE Sup Loss: 0.63362
Epoch 1, iter 48, Dice Sup Loss: 0.51781, BCE Sup Loss: 0.60243
Epoch 1, iter 49, Dice Sup Loss: 0.51251, BCE Sup Loss: 0.60486
Epoch 1, iter 50, Dice Sup Loss: 0.49799, BCE Sup Loss: 0.6176
Epoch 1, iter 51, Dice Sup Loss: 0.45161, BCE Sup Loss: 0.6635
Epoch 1, iter 52, Dice Sup Loss: 0.48106, BCE Sup Loss: 0.63124
Epoch 1, iter 53, Dice Sup Loss: 0.44842, BCE Sup Loss: 0.65541
Epoch 1, iter 54, Dice Sup Loss: 0.43591, BCE Sup Loss: 0.66554
Epoch 1, iter 55, Dice Sup Loss: 0.41965, BCE Sup Loss: 0.65712
Epoch 1, iter 56, Dice Sup Loss: 0.46961, BCE Sup Loss: 0.62974
Epoch 1, iter 57, Dice Sup Loss: 0.41551, BCE Sup Loss: 0.6823
Epoch 1, iter 58, Dice Sup Loss: 0.47166, BCE Sup Loss: 0.65489
Epoch 1, iter 59, Dice Sup Loss: 0.45263, BCE Sup Loss: 0.65584
Epoch 1, iter 60, Dice Sup Loss: 0.60709, BCE Sup Loss: 0.60045
Epoch 1, Total train step 59 || AVG_loss: 0.56043, Avg Dice score: 0.0595, Avg IOU: 0.0324
Epoch 1, Validation || sum_loss: 1.11869, Dice score: 0.1281, IOU: 0.0749
New best epoch 1!===============================
Training and evaluating on epoch1 complete in 0m 8s
Epoch 2, iter 61, Dice Sup Loss: 0.44106, BCE Sup Loss: 0.67206
Epoch 2, iter 62, Dice Sup Loss: 0.50808, BCE Sup Loss: 0.60568
Epoch 2, iter 63, Dice Sup Loss: 0.44612, BCE Sup Loss: 0.61407
Epoch 2, iter 64, Dice Sup Loss: 0.50997, BCE Sup Loss: 0.62395
Epoch 2, iter 65, Dice Sup Loss: 0.51534, BCE Sup Loss: 0.60028
Epoch 2, iter 66, Dice Sup Loss: 0.48557, BCE Sup Loss: 0.60596
Epoch 2, iter 67, Dice Sup Loss: 0.49564, BCE Sup Loss: 0.63764
Epoch 2, iter 68, Dice Sup Loss: 0.48431, BCE Sup Loss: 0.63619
Epoch 2, iter 69, Dice Sup Loss: 0.51622, BCE Sup Loss: 0.60208
Epoch 2, iter 70, Dice Sup Loss: 0.50914, BCE Sup Loss: 0.59044
Epoch 2, iter 71, Dice Sup Loss: 0.47912, BCE Sup Loss: 0.63444
Epoch 2, iter 72, Dice Sup Loss: 0.46363, BCE Sup Loss: 0.64624
Epoch 2, iter 73, Dice Sup Loss: 0.46586, BCE Sup Loss: 0.64781
Epoch 2, iter 74, Dice Sup Loss: 0.47309, BCE Sup Loss: 0.61673
Epoch 2, iter 75, Dice Sup Loss: 0.45827, BCE Sup Loss: 0.60148
Epoch 2, iter 76, Dice Sup Loss: 0.49384, BCE Sup Loss: 0.63789
Epoch 2, iter 77, Dice Sup Loss: 0.43757, BCE Sup Loss: 0.6585
Epoch 2, iter 78, Dice Sup Loss: 0.4881, BCE Sup Loss: 0.63439
Epoch 2, iter 79, Dice Sup Loss: 0.52116, BCE Sup Loss: 0.59204
Epoch 2, iter 80, Dice Sup Loss: 0.48362, BCE Sup Loss: 0.59431
Epoch 2, iter 81, Dice Sup Loss: 0.41774, BCE Sup Loss: 0.56247
Epoch 2, iter 82, Dice Sup Loss: 0.48225, BCE Sup Loss: 0.62925
Epoch 2, iter 83, Dice Sup Loss: 0.4638, BCE Sup Loss: 0.61148
Epoch 2, iter 84, Dice Sup Loss: 0.49745, BCE Sup Loss: 0.61602
Epoch 2, iter 85, Dice Sup Loss: 0.43841, BCE Sup Loss: 0.5968
Epoch 2, iter 86, Dice Sup Loss: 0.54416, BCE Sup Loss: 0.58464
Epoch 2, iter 87, Dice Sup Loss: 0.46089, BCE Sup Loss: 0.62447
Epoch 2, iter 88, Dice Sup Loss: 0.47199, BCE Sup Loss: 0.59159
Epoch 2, iter 89, Dice Sup Loss: 0.43328, BCE Sup Loss: 0.55228
Epoch 2, iter 90, Dice Sup Loss: 0.38976, BCE Sup Loss: 0.7238
Epoch 2, Total train step 89 || AVG_loss: 0.54671, Avg Dice score: 0.0614, Avg IOU: 0.0344
Epoch 2, Validation || sum_loss: 1.05667, Dice score: 0.1318, IOU: 0.0798
New best epoch 2!===============================
Training and evaluating on epoch2 complete in 0m 8s
Epoch 3, iter 91, Dice Sup Loss: 0.44974, BCE Sup Loss: 0.6583
Epoch 3, iter 92, Dice Sup Loss: 0.44267, BCE Sup Loss: 0.68647
Epoch 3, iter 93, Dice Sup Loss: 0.39146, BCE Sup Loss: 0.64192
Epoch 3, iter 94, Dice Sup Loss: 0.44739, BCE Sup Loss: 0.62766
Epoch 3, iter 95, Dice Sup Loss: 0.40493, BCE Sup Loss: 0.63148
Epoch 3, iter 96, Dice Sup Loss: 0.38062, BCE Sup Loss: 0.58579
Epoch 3, iter 97, Dice Sup Loss: 0.48456, BCE Sup Loss: 0.64333
Epoch 3, iter 98, Dice Sup Loss: 0.5247, BCE Sup Loss: 0.62029
Epoch 3, iter 99, Dice Sup Loss: 0.44524, BCE Sup Loss: 0.61453
Epoch 3, iter 100, Dice Sup Loss: 0.50186, BCE Sup Loss: 0.61265
Epoch 3, iter 101, Dice Sup Loss: 0.50589, BCE Sup Loss: 0.55142
Epoch 3, iter 102, Dice Sup Loss: 0.50003, BCE Sup Loss: 0.62968
Epoch 3, iter 103, Dice Sup Loss: 0.50914, BCE Sup Loss: 0.61952
Epoch 3, iter 104, Dice Sup Loss: 0.5337, BCE Sup Loss: 0.58369
Epoch 3, iter 105, Dice Sup Loss: 0.47468, BCE Sup Loss: 0.52682
Epoch 3, iter 106, Dice Sup Loss: 0.45416, BCE Sup Loss: 0.61029
Epoch 3, iter 107, Dice Sup Loss: 0.46116, BCE Sup Loss: 0.56574
Epoch 3, iter 108, Dice Sup Loss: 0.51543, BCE Sup Loss: 0.60439
Epoch 3, iter 109, Dice Sup Loss: 0.47241, BCE Sup Loss: 0.63642
Epoch 3, iter 110, Dice Sup Loss: 0.38308, BCE Sup Loss: 0.5347
Epoch 3, iter 111, Dice Sup Loss: 0.4794, BCE Sup Loss: 0.59224
Epoch 3, iter 112, Dice Sup Loss: 0.43534, BCE Sup Loss: 0.6009
Epoch 3, iter 113, Dice Sup Loss: 0.43399, BCE Sup Loss: 0.60072
Epoch 3, iter 114, Dice Sup Loss: 0.35666, BCE Sup Loss: 0.57433
Epoch 3, iter 115, Dice Sup Loss: 0.46929, BCE Sup Loss: 0.64762
Epoch 3, iter 116, Dice Sup Loss: 0.44942, BCE Sup Loss: 0.65309
Epoch 3, iter 117, Dice Sup Loss: 0.43316, BCE Sup Loss: 0.66282
Epoch 3, iter 118, Dice Sup Loss: 0.49972, BCE Sup Loss: 0.57335
Epoch 3, iter 119, Dice Sup Loss: 0.52344, BCE Sup Loss: 0.614
Epoch 3, iter 120, Dice Sup Loss: 0.49064, BCE Sup Loss: 0.62175
Epoch 3, Total train step 119 || AVG_loss: 0.53573, Avg Dice score: 0.1012, Avg IOU: 0.0569
Epoch 3, Validation || sum_loss: 1.02779, Dice score: 0.1506, IOU: 0.0921
New best epoch 3!===============================
Training and evaluating on epoch3 complete in 0m 8s
Epoch 4, iter 121, Dice Sup Loss: 0.49991, BCE Sup Loss: 0.61452
Epoch 4, iter 122, Dice Sup Loss: 0.41125, BCE Sup Loss: 0.51433
Epoch 4, iter 123, Dice Sup Loss: 0.43604, BCE Sup Loss: 0.6257
Epoch 4, iter 124, Dice Sup Loss: 0.46265, BCE Sup Loss: 0.57879
Epoch 4, iter 125, Dice Sup Loss: 0.44189, BCE Sup Loss: 0.57334
Epoch 4, iter 126, Dice Sup Loss: 0.42121, BCE Sup Loss: 0.56432
Epoch 4, iter 127, Dice Sup Loss: 0.48098, BCE Sup Loss: 0.62711
Epoch 4, iter 128, Dice Sup Loss: 0.42722, BCE Sup Loss: 0.66668
Epoch 4, iter 129, Dice Sup Loss: 0.51455, BCE Sup Loss: 0.63855
Epoch 4, iter 130, Dice Sup Loss: 0.4307, BCE Sup Loss: 0.66579
Epoch 4, iter 131, Dice Sup Loss: 0.43726, BCE Sup Loss: 0.6635
Epoch 4, iter 132, Dice Sup Loss: 0.49733, BCE Sup Loss: 0.64426
Epoch 4, iter 133, Dice Sup Loss: 0.44913, BCE Sup Loss: 0.61416
Epoch 4, iter 134, Dice Sup Loss: 0.4416, BCE Sup Loss: 0.60256
Epoch 4, iter 135, Dice Sup Loss: 0.3416, BCE Sup Loss: 0.56316
Epoch 4, iter 136, Dice Sup Loss: 0.45658, BCE Sup Loss: 0.57675
Epoch 4, iter 137, Dice Sup Loss: 0.43409, BCE Sup Loss: 0.52116
Epoch 4, iter 138, Dice Sup Loss: 0.42809, BCE Sup Loss: 0.58981
Epoch 4, iter 139, Dice Sup Loss: 0.44693, BCE Sup Loss: 0.5097
Epoch 4, iter 140, Dice Sup Loss: 0.46175, BCE Sup Loss: 0.66509
Epoch 4, iter 141, Dice Sup Loss: 0.5097, BCE Sup Loss: 0.60665
Epoch 4, iter 142, Dice Sup Loss: 0.52709, BCE Sup Loss: 0.58921
Epoch 4, iter 143, Dice Sup Loss: 0.52198, BCE Sup Loss: 0.59364
Epoch 4, iter 144, Dice Sup Loss: 0.50259, BCE Sup Loss: 0.61265
Epoch 4, iter 145, Dice Sup Loss: 0.43828, BCE Sup Loss: 0.56791
Epoch 4, iter 146, Dice Sup Loss: 0.4595, BCE Sup Loss: 0.56804
Epoch 4, iter 147, Dice Sup Loss: 0.48928, BCE Sup Loss: 0.54678
Epoch 4, iter 148, Dice Sup Loss: 0.49332, BCE Sup Loss: 0.62058
Epoch 4, iter 149, Dice Sup Loss: 0.50119, BCE Sup Loss: 0.61279
Epoch 4, iter 150, Dice Sup Loss: 0.44328, BCE Sup Loss: 0.67132
Epoch 4, Total train step 149 || AVG_loss: 0.52945, Avg Dice score: 0.1036, Avg IOU: 0.0587
Epoch 4, Validation || sum_loss: 1.02076, Dice score: 0.1489, IOU: 0.0913
Training and evaluating on epoch4 complete in 0m 8s
Epoch 5, iter 151, Dice Sup Loss: 0.41705, BCE Sup Loss: 0.52917
Epoch 5, iter 152, Dice Sup Loss: 0.49402, BCE Sup Loss: 0.62533
Epoch 5, iter 153, Dice Sup Loss: 0.4281, BCE Sup Loss: 0.59827
Epoch 5, iter 154, Dice Sup Loss: 0.46204, BCE Sup Loss: 0.64418
Epoch 5, iter 155, Dice Sup Loss: 0.50413, BCE Sup Loss: 0.62299
Epoch 5, iter 156, Dice Sup Loss: 0.39608, BCE Sup Loss: 0.59249
Epoch 5, iter 157, Dice Sup Loss: 0.42965, BCE Sup Loss: 0.6015
Epoch 5, iter 158, Dice Sup Loss: 0.48584, BCE Sup Loss: 0.62932
Epoch 5, iter 159, Dice Sup Loss: 0.42428, BCE Sup Loss: 0.57873
Epoch 5, iter 160, Dice Sup Loss: 0.40433, BCE Sup Loss: 0.56662
Epoch 5, iter 161, Dice Sup Loss: 0.43805, BCE Sup Loss: 0.58394
Epoch 5, iter 162, Dice Sup Loss: 0.49727, BCE Sup Loss: 0.61604
Epoch 5, iter 163, Dice Sup Loss: 0.49809, BCE Sup Loss: 0.6159
Epoch 5, iter 164, Dice Sup Loss: 0.48627, BCE Sup Loss: 0.62982
Epoch 5, iter 165, Dice Sup Loss: 0.3871, BCE Sup Loss: 0.49014
Epoch 5, iter 166, Dice Sup Loss: 0.50258, BCE Sup Loss: 0.61182
Epoch 5, iter 167, Dice Sup Loss: 0.3915, BCE Sup Loss: 0.53868
Epoch 5, iter 168, Dice Sup Loss: 0.48907, BCE Sup Loss: 0.62556
Epoch 5, iter 169, Dice Sup Loss: 0.45966, BCE Sup Loss: 0.58652
Epoch 5, iter 170, Dice Sup Loss: 0.44205, BCE Sup Loss: 0.5788
Epoch 5, iter 171, Dice Sup Loss: 0.48115, BCE Sup Loss: 0.63393
Epoch 5, iter 172, Dice Sup Loss: 0.43776, BCE Sup Loss: 0.57354
Epoch 5, iter 173, Dice Sup Loss: 0.48034, BCE Sup Loss: 0.63039
Epoch 5, iter 174, Dice Sup Loss: 0.44527, BCE Sup Loss: 0.58181
Epoch 5, iter 175, Dice Sup Loss: 0.47283, BCE Sup Loss: 0.56916
Epoch 5, iter 176, Dice Sup Loss: 0.47906, BCE Sup Loss: 0.63346
Epoch 5, iter 177, Dice Sup Loss: 0.39362, BCE Sup Loss: 0.52384
Epoch 5, iter 178, Dice Sup Loss: 0.46163, BCE Sup Loss: 0.64811
Epoch 5, iter 179, Dice Sup Loss: 0.47191, BCE Sup Loss: 0.63674
Epoch 5, iter 180, Dice Sup Loss: 0.47142, BCE Sup Loss: 0.63807
Epoch 5, Total train step 179 || AVG_loss: 0.52526, Avg Dice score: 0.1056, Avg IOU: 0.0604
Epoch 5, Validation || sum_loss: 1.01764, Dice score: 0.1589, IOU: 0.0982
New best epoch 5!===============================
Training and evaluating on epoch5 complete in 0m 8s
Epoch 6, iter 181, Dice Sup Loss: 0.43482, BCE Sup Loss: 0.59005
Epoch 6, iter 182, Dice Sup Loss: 0.46886, BCE Sup Loss: 0.64461
Epoch 6, iter 183, Dice Sup Loss: 0.45494, BCE Sup Loss: 0.65183
Epoch 6, iter 184, Dice Sup Loss: 0.48348, BCE Sup Loss: 0.57377
Epoch 6, iter 185, Dice Sup Loss: 0.48666, BCE Sup Loss: 0.63249
Epoch 6, iter 186, Dice Sup Loss: 0.47865, BCE Sup Loss: 0.63178
Epoch 6, iter 187, Dice Sup Loss: 0.50897, BCE Sup Loss: 0.60935
Epoch 6, iter 188, Dice Sup Loss: 0.50199, BCE Sup Loss: 0.61252
Epoch 6, iter 189, Dice Sup Loss: 0.44457, BCE Sup Loss: 0.58985
Epoch 6, iter 190, Dice Sup Loss: 0.43634, BCE Sup Loss: 0.52551
Epoch 6, iter 191, Dice Sup Loss: 0.49097, BCE Sup Loss: 0.62581
Epoch 6, iter 192, Dice Sup Loss: 0.37658, BCE Sup Loss: 0.53612
Epoch 6, iter 193, Dice Sup Loss: 0.40061, BCE Sup Loss: 0.49594
Epoch 6, iter 194, Dice Sup Loss: 0.48936, BCE Sup Loss: 0.62273
Epoch 6, iter 195, Dice Sup Loss: 0.40461, BCE Sup Loss: 0.51715
Epoch 6, iter 196, Dice Sup Loss: 0.49712, BCE Sup Loss: 0.61771
Epoch 6, iter 197, Dice Sup Loss: 0.43879, BCE Sup Loss: 0.5686
Epoch 6, iter 198, Dice Sup Loss: 0.33471, BCE Sup Loss: 0.47415
Epoch 6, iter 199, Dice Sup Loss: 0.51009, BCE Sup Loss: 0.6065
Epoch 6, iter 200, Dice Sup Loss: 0.3993, BCE Sup Loss: 0.60367
Epoch 6, iter 201, Dice Sup Loss: 0.48589, BCE Sup Loss: 0.62562
Epoch 6, iter 202, Dice Sup Loss: 0.43994, BCE Sup Loss: 0.66987
Epoch 6, iter 203, Dice Sup Loss: 0.41734, BCE Sup Loss: 0.60607
Epoch 6, iter 204, Dice Sup Loss: 0.45138, BCE Sup Loss: 0.5792
Epoch 6, iter 205, Dice Sup Loss: 0.44432, BCE Sup Loss: 0.66071
Epoch 6, iter 206, Dice Sup Loss: 0.39305, BCE Sup Loss: 0.60766
Epoch 6, iter 207, Dice Sup Loss: 0.50282, BCE Sup Loss: 0.64696
Epoch 6, iter 208, Dice Sup Loss: 0.43817, BCE Sup Loss: 0.59519
Epoch 6, iter 209, Dice Sup Loss: 0.50001, BCE Sup Loss: 0.62503
Epoch 6, iter 210, Dice Sup Loss: 0.4377, BCE Sup Loss: 0.66943
Epoch 6, Total train step 209 || AVG_loss: 0.52531, Avg Dice score: 0.1068, Avg IOU: 0.0622
Epoch 6, Validation || sum_loss: 1.00765, Dice score: 0.1631, IOU: 0.1012
New best epoch 6!===============================
Training and evaluating on epoch6 complete in 0m 8s
Epoch 7, iter 211, Dice Sup Loss: 0.49437, BCE Sup Loss: 0.6187
Epoch 7, iter 212, Dice Sup Loss: 0.50681, BCE Sup Loss: 0.60854
Epoch 7, iter 213, Dice Sup Loss: 0.5266, BCE Sup Loss: 0.58978
Epoch 7, iter 214, Dice Sup Loss: 0.53731, BCE Sup Loss: 0.58048
Epoch 7, iter 215, Dice Sup Loss: 0.41069, BCE Sup Loss: 0.42931
Epoch 7, iter 216, Dice Sup Loss: 0.51334, BCE Sup Loss: 0.61126
Epoch 7, iter 217, Dice Sup Loss: 0.52607, BCE Sup Loss: 0.59559
Epoch 7, iter 218, Dice Sup Loss: 0.50855, BCE Sup Loss: 0.62205
Epoch 7, iter 219, Dice Sup Loss: 0.50136, BCE Sup Loss: 0.62457
Epoch 7, iter 220, Dice Sup Loss: 0.42315, BCE Sup Loss: 0.52152
Epoch 7, iter 221, Dice Sup Loss: 0.43344, BCE Sup Loss: 0.57596
Epoch 7, iter 222, Dice Sup Loss: 0.41727, BCE Sup Loss: 0.58643
Epoch 7, iter 223, Dice Sup Loss: 0.42751, BCE Sup Loss: 0.59284
Epoch 7, iter 224, Dice Sup Loss: 0.46332, BCE Sup Loss: 0.64793
Epoch 7, iter 225, Dice Sup Loss: 0.3937, BCE Sup Loss: 0.53857
Epoch 7, iter 226, Dice Sup Loss: 0.38504, BCE Sup Loss: 0.59717
Epoch 7, iter 227, Dice Sup Loss: 0.38543, BCE Sup Loss: 0.54057
Epoch 7, iter 228, Dice Sup Loss: 0.44659, BCE Sup Loss: 0.65605
Epoch 7, iter 229, Dice Sup Loss: 0.47881, BCE Sup Loss: 0.63652
Epoch 7, iter 230, Dice Sup Loss: 0.46726, BCE Sup Loss: 0.56713
Epoch 7, iter 231, Dice Sup Loss: 0.40331, BCE Sup Loss: 0.59614
Epoch 7, iter 232, Dice Sup Loss: 0.45236, BCE Sup Loss: 0.66341
Epoch 7, iter 233, Dice Sup Loss: 0.43493, BCE Sup Loss: 0.60912
Epoch 7, iter 234, Dice Sup Loss: 0.4288, BCE Sup Loss: 0.57536
Epoch 7, iter 235, Dice Sup Loss: 0.47904, BCE Sup Loss: 0.63121
Epoch 7, iter 236, Dice Sup Loss: 0.43323, BCE Sup Loss: 0.58861
Epoch 7, iter 237, Dice Sup Loss: 0.47741, BCE Sup Loss: 0.63543
Epoch 7, iter 238, Dice Sup Loss: 0.45219, BCE Sup Loss: 0.57468
Epoch 7, iter 239, Dice Sup Loss: 0.39376, BCE Sup Loss: 0.58775
Epoch 7, iter 240, Dice Sup Loss: 0.43784, BCE Sup Loss: 0.65995
Epoch 7, Total train step 239 || AVG_loss: 0.52432, Avg Dice score: 0.1121, Avg IOU: 0.0644
Epoch 7, Validation || sum_loss: 1.01444, Dice score: 0.1606, IOU: 0.0994
Training and evaluating on epoch7 complete in 0m 8s
Epoch 8, iter 241, Dice Sup Loss: 0.39914, BCE Sup Loss: 0.60727
Epoch 8, iter 242, Dice Sup Loss: 0.37363, BCE Sup Loss: 0.60019
Epoch 8, iter 243, Dice Sup Loss: 0.42541, BCE Sup Loss: 0.66596
Epoch 8, iter 244, Dice Sup Loss: 0.39806, BCE Sup Loss: 0.53124
Epoch 8, iter 245, Dice Sup Loss: 0.45233, BCE Sup Loss: 0.58611
Epoch 8, iter 246, Dice Sup Loss: 0.52954, BCE Sup Loss: 0.62022
Epoch 8, iter 247, Dice Sup Loss: 0.48384, BCE Sup Loss: 0.62903
Epoch 8, iter 248, Dice Sup Loss: 0.39711, BCE Sup Loss: 0.58573
Epoch 8, iter 249, Dice Sup Loss: 0.38772, BCE Sup Loss: 0.5248
Epoch 8, iter 250, Dice Sup Loss: 0.46755, BCE Sup Loss: 0.55919
Epoch 8, iter 251, Dice Sup Loss: 0.40295, BCE Sup Loss: 0.50016
Epoch 8, iter 252, Dice Sup Loss: 0.45437, BCE Sup Loss: 0.58857
Epoch 8, iter 253, Dice Sup Loss: 0.489, BCE Sup Loss: 0.63861
Epoch 8, iter 254, Dice Sup Loss: 0.40935, BCE Sup Loss: 0.58418
Epoch 8, iter 255, Dice Sup Loss: 0.52315, BCE Sup Loss: 0.59455
Epoch 8, iter 256, Dice Sup Loss: 0.4644, BCE Sup Loss: 0.64382
Epoch 8, iter 257, Dice Sup Loss: 0.4579, BCE Sup Loss: 0.5628
Epoch 8, iter 258, Dice Sup Loss: 0.44646, BCE Sup Loss: 0.57579
Epoch 8, iter 259, Dice Sup Loss: 0.48823, BCE Sup Loss: 0.62902
Epoch 8, iter 260, Dice Sup Loss: 0.44246, BCE Sup Loss: 0.58805
Epoch 8, iter 261, Dice Sup Loss: 0.44843, BCE Sup Loss: 0.65335
Epoch 8, iter 262, Dice Sup Loss: 0.48521, BCE Sup Loss: 0.63299
Epoch 8, iter 263, Dice Sup Loss: 0.46996, BCE Sup Loss: 0.63929
Epoch 8, iter 264, Dice Sup Loss: 0.43906, BCE Sup Loss: 0.57016
Epoch 8, iter 265, Dice Sup Loss: 0.43724, BCE Sup Loss: 0.57817
Epoch 8, iter 266, Dice Sup Loss: 0.49469, BCE Sup Loss: 0.62774
Epoch 8, iter 267, Dice Sup Loss: 0.4812, BCE Sup Loss: 0.5428
Epoch 8, iter 268, Dice Sup Loss: 0.49043, BCE Sup Loss: 0.62206
Epoch 8, iter 269, Dice Sup Loss: 0.49046, BCE Sup Loss: 0.62381
Epoch 8, iter 270, Dice Sup Loss: 0.12714, BCE Sup Loss: 0.164
Epoch 8, Total train step 269 || AVG_loss: 0.52311, Avg Dice score: 0.1133, Avg IOU: 0.0654
Epoch 8, Validation || sum_loss: 1.00403, Dice score: 0.1609, IOU: 0.0998
Training and evaluating on epoch8 complete in 0m 7s
Epoch 9, iter 271, Dice Sup Loss: 0.43007, BCE Sup Loss: 0.58025
Epoch 9, iter 272, Dice Sup Loss: 0.479, BCE Sup Loss: 0.54881
Epoch 9, iter 273, Dice Sup Loss: 0.45416, BCE Sup Loss: 0.56094
Epoch 9, iter 274, Dice Sup Loss: 0.52827, BCE Sup Loss: 0.58875
Epoch 9, iter 275, Dice Sup Loss: 0.46179, BCE Sup Loss: 0.56088
Epoch 9, iter 276, Dice Sup Loss: 0.44271, BCE Sup Loss: 0.55777
Epoch 9, iter 277, Dice Sup Loss: 0.46601, BCE Sup Loss: 0.64734
Epoch 9, iter 278, Dice Sup Loss: 0.40472, BCE Sup Loss: 0.57916
Epoch 9, iter 279, Dice Sup Loss: 0.51914, BCE Sup Loss: 0.60527
Epoch 9, iter 280, Dice Sup Loss: 0.44696, BCE Sup Loss: 0.56358
Epoch 9, iter 281, Dice Sup Loss: 0.44982, BCE Sup Loss: 0.6538
Epoch 9, iter 282, Dice Sup Loss: 0.46376, BCE Sup Loss: 0.55988
Epoch 9, iter 283, Dice Sup Loss: 0.41536, BCE Sup Loss: 0.52455
Epoch 9, iter 284, Dice Sup Loss: 0.34686, BCE Sup Loss: 0.53614
Epoch 9, iter 285, Dice Sup Loss: 0.46941, BCE Sup Loss: 0.63852
Epoch 9, iter 286, Dice Sup Loss: 0.43281, BCE Sup Loss: 0.57865
Epoch 9, iter 287, Dice Sup Loss: 0.52718, BCE Sup Loss: 0.60341
Epoch 9, iter 288, Dice Sup Loss: 0.4453, BCE Sup Loss: 0.56677
Epoch 9, iter 289, Dice Sup Loss: 0.44104, BCE Sup Loss: 0.56094
Epoch 9, iter 290, Dice Sup Loss: 0.43763, BCE Sup Loss: 0.59549
Epoch 9, iter 291, Dice Sup Loss: 0.39348, BCE Sup Loss: 0.51071
Epoch 9, iter 292, Dice Sup Loss: 0.45965, BCE Sup Loss: 0.58285
Epoch 9, iter 293, Dice Sup Loss: 0.3905, BCE Sup Loss: 0.61686
Epoch 9, iter 294, Dice Sup Loss: 0.50908, BCE Sup Loss: 0.60641
Epoch 9, iter 295, Dice Sup Loss: 0.46768, BCE Sup Loss: 0.64224
Epoch 9, iter 296, Dice Sup Loss: 0.48154, BCE Sup Loss: 0.62947
Epoch 9, iter 297, Dice Sup Loss: 0.43809, BCE Sup Loss: 0.66287
Epoch 9, iter 298, Dice Sup Loss: 0.55314, BCE Sup Loss: 0.60752
Epoch 9, iter 299, Dice Sup Loss: 0.45357, BCE Sup Loss: 0.65053
Epoch 9, iter 300, Dice Sup Loss: 0.4973, BCE Sup Loss: 0.63005
Epoch 9, Total train step 299 || AVG_loss: 0.52309, Avg Dice score: 0.1087, Avg IOU: 0.0615
Epoch 9, Validation || sum_loss: 1.01237, Dice score: 0.1603, IOU: 0.0993
Training and evaluating on epoch9 complete in 0m 8s
Epoch 10, iter 301, Dice Sup Loss: 0.49197, BCE Sup Loss: 0.62998
Epoch 10, iter 302, Dice Sup Loss: 0.49947, BCE Sup Loss: 0.62232
Epoch 10, iter 303, Dice Sup Loss: 0.39059, BCE Sup Loss: 0.5311
Epoch 10, iter 304, Dice Sup Loss: 0.46879, BCE Sup Loss: 0.63979
Epoch 10, iter 305, Dice Sup Loss: 0.35355, BCE Sup Loss: 0.45512
Epoch 10, iter 306, Dice Sup Loss: 0.4897, BCE Sup Loss: 0.62065
Epoch 10, iter 307, Dice Sup Loss: 0.48394, BCE Sup Loss: 0.62837
Epoch 10, iter 308, Dice Sup Loss: 0.47375, BCE Sup Loss: 0.63859
Epoch 10, iter 309, Dice Sup Loss: 0.46048, BCE Sup Loss: 0.65122
Epoch 10, iter 310, Dice Sup Loss: 0.43851, BCE Sup Loss: 0.56501
Epoch 10, iter 311, Dice Sup Loss: 0.39299, BCE Sup Loss: 0.60021
Epoch 10, iter 312, Dice Sup Loss: 0.47431, BCE Sup Loss: 0.55516
Epoch 10, iter 313, Dice Sup Loss: 0.47493, BCE Sup Loss: 0.56309
Epoch 10, iter 314, Dice Sup Loss: 0.38623, BCE Sup Loss: 0.578
Epoch 10, iter 315, Dice Sup Loss: 0.47748, BCE Sup Loss: 0.63269
Epoch 10, iter 316, Dice Sup Loss: 0.46548, BCE Sup Loss: 0.55565
Epoch 10, iter 317, Dice Sup Loss: 0.44283, BCE Sup Loss: 0.67108
Epoch 10, iter 318, Dice Sup Loss: 0.30653, BCE Sup Loss: 0.47199
Epoch 10, iter 319, Dice Sup Loss: 0.41567, BCE Sup Loss: 0.55487
Epoch 10, iter 320, Dice Sup Loss: 0.44982, BCE Sup Loss: 0.57053
Epoch 10, iter 321, Dice Sup Loss: 0.49545, BCE Sup Loss: 0.61755
Epoch 10, iter 322, Dice Sup Loss: 0.45914, BCE Sup Loss: 0.55844
Epoch 10, iter 323, Dice Sup Loss: 0.51159, BCE Sup Loss: 0.60391
Epoch 10, iter 324, Dice Sup Loss: 0.46961, BCE Sup Loss: 0.54373
Epoch 10, iter 325, Dice Sup Loss: 0.46357, BCE Sup Loss: 0.58146
Epoch 10, iter 326, Dice Sup Loss: 0.49011, BCE Sup Loss: 0.53728
Epoch 10, iter 327, Dice Sup Loss: 0.46187, BCE Sup Loss: 0.65974
Epoch 10, iter 328, Dice Sup Loss: 0.49444, BCE Sup Loss: 0.61867
Epoch 10, iter 329, Dice Sup Loss: 0.47756, BCE Sup Loss: 0.63313
Epoch 10, iter 330, Dice Sup Loss: 0.42177, BCE Sup Loss: 0.68795
Epoch 10, Total train step 329 || AVG_loss: 0.52169, Avg Dice score: 0.112, Avg IOU: 0.0655
Epoch 10, Validation || sum_loss: 1.00862, Dice score: 0.1632, IOU: 0.1013
New best epoch 10!===============================
Training and evaluating on epoch10 complete in 0m 8s
Epoch 11, iter 331, Dice Sup Loss: 0.41292, BCE Sup Loss: 0.59482
Epoch 11, iter 332, Dice Sup Loss: 0.48646, BCE Sup Loss: 0.64129
Epoch 11, iter 333, Dice Sup Loss: 0.49186, BCE Sup Loss: 0.64784
Epoch 11, iter 334, Dice Sup Loss: 0.38501, BCE Sup Loss: 0.53911
Epoch 11, iter 335, Dice Sup Loss: 0.39574, BCE Sup Loss: 0.59283
Epoch 11, iter 336, Dice Sup Loss: 0.39154, BCE Sup Loss: 0.61178
Epoch 11, iter 337, Dice Sup Loss: 0.41834, BCE Sup Loss: 0.58981
Epoch 11, iter 338, Dice Sup Loss: 0.40764, BCE Sup Loss: 0.5852
Epoch 11, iter 339, Dice Sup Loss: 0.47244, BCE Sup Loss: 0.55782
Epoch 11, iter 340, Dice Sup Loss: 0.40647, BCE Sup Loss: 0.58659
Epoch 11, iter 341, Dice Sup Loss: 0.40851, BCE Sup Loss: 0.4857
Epoch 11, iter 342, Dice Sup Loss: 0.47695, BCE Sup Loss: 0.54396
Epoch 11, iter 343, Dice Sup Loss: 0.48535, BCE Sup Loss: 0.64114
Epoch 11, iter 344, Dice Sup Loss: 0.47597, BCE Sup Loss: 0.66127
Epoch 11, iter 345, Dice Sup Loss: 0.50575, BCE Sup Loss: 0.6122
Epoch 11, iter 346, Dice Sup Loss: 0.5038, BCE Sup Loss: 0.61083
Epoch 11, iter 347, Dice Sup Loss: 0.50054, BCE Sup Loss: 0.61344
Epoch 11, iter 348, Dice Sup Loss: 0.44329, BCE Sup Loss: 0.56591
Epoch 11, iter 349, Dice Sup Loss: 0.4563, BCE Sup Loss: 0.5551
Epoch 11, iter 350, Dice Sup Loss: 0.47648, BCE Sup Loss: 0.55349
Epoch 11, iter 351, Dice Sup Loss: 0.46115, BCE Sup Loss: 0.64461
Epoch 11, iter 352, Dice Sup Loss: 0.48519, BCE Sup Loss: 0.62944
Epoch 11, iter 353, Dice Sup Loss: 0.35136, BCE Sup Loss: 0.51705
Epoch 11, iter 354, Dice Sup Loss: 0.47513, BCE Sup Loss: 0.63533
Epoch 11, iter 355, Dice Sup Loss: 0.39643, BCE Sup Loss: 0.60209
Epoch 11, iter 356, Dice Sup Loss: 0.49428, BCE Sup Loss: 0.62349
Epoch 11, iter 357, Dice Sup Loss: 0.44367, BCE Sup Loss: 0.57767
Epoch 11, iter 358, Dice Sup Loss: 0.4481, BCE Sup Loss: 0.56919
Epoch 11, iter 359, Dice Sup Loss: 0.4854, BCE Sup Loss: 0.62766
Epoch 11, iter 360, Dice Sup Loss: 0.40974, BCE Sup Loss: 0.699
Epoch 11, Total train step 359 || AVG_loss: 0.52184, Avg Dice score: 0.1142, Avg IOU: 0.0648
Epoch 11, Validation || sum_loss: 1.0049, Dice score: 0.1647, IOU: 0.1024
New best epoch 11!===============================
Training and evaluating on epoch11 complete in 0m 8s
Epoch 12, iter 361, Dice Sup Loss: 0.4751, BCE Sup Loss: 0.6348
Epoch 12, iter 362, Dice Sup Loss: 0.3912, BCE Sup Loss: 0.58526
Epoch 12, iter 363, Dice Sup Loss: 0.43661, BCE Sup Loss: 0.50031
Epoch 12, iter 364, Dice Sup Loss: 0.49784, BCE Sup Loss: 0.62716
Epoch 12, iter 365, Dice Sup Loss: 0.38509, BCE Sup Loss: 0.52021
Epoch 12, iter 366, Dice Sup Loss: 0.41127, BCE Sup Loss: 0.49824
Epoch 12, iter 367, Dice Sup Loss: 0.4966, BCE Sup Loss: 0.61982
Epoch 12, iter 368, Dice Sup Loss: 0.4739, BCE Sup Loss: 0.63566
Epoch 12, iter 369, Dice Sup Loss: 0.43349, BCE Sup Loss: 0.56178
Epoch 12, iter 370, Dice Sup Loss: 0.49227, BCE Sup Loss: 0.62064
Epoch 12, iter 371, Dice Sup Loss: 0.35853, BCE Sup Loss: 0.52859
Epoch 12, iter 372, Dice Sup Loss: 0.45408, BCE Sup Loss: 0.57137
Epoch 12, iter 373, Dice Sup Loss: 0.49116, BCE Sup Loss: 0.6223
Epoch 12, iter 374, Dice Sup Loss: 0.4679, BCE Sup Loss: 0.56474
Epoch 12, iter 375, Dice Sup Loss: 0.4319, BCE Sup Loss: 0.58034
Epoch 12, iter 376, Dice Sup Loss: 0.48318, BCE Sup Loss: 0.6282
Epoch 12, iter 377, Dice Sup Loss: 0.47212, BCE Sup Loss: 0.63616
Epoch 12, iter 378, Dice Sup Loss: 0.47178, BCE Sup Loss: 0.63675
Epoch 12, iter 379, Dice Sup Loss: 0.48057, BCE Sup Loss: 0.63271
Epoch 12, iter 380, Dice Sup Loss: 0.44123, BCE Sup Loss: 0.65781
Epoch 12, iter 381, Dice Sup Loss: 0.4526, BCE Sup Loss: 0.65215
Epoch 12, iter 382, Dice Sup Loss: 0.40965, BCE Sup Loss: 0.59041
Epoch 12, iter 383, Dice Sup Loss: 0.45407, BCE Sup Loss: 0.65319
Epoch 12, iter 384, Dice Sup Loss: 0.41989, BCE Sup Loss: 0.58602
Epoch 12, iter 385, Dice Sup Loss: 0.42142, BCE Sup Loss: 0.59402
Epoch 12, iter 386, Dice Sup Loss: 0.3705, BCE Sup Loss: 0.59484
Epoch 12, iter 387, Dice Sup Loss: 0.55475, BCE Sup Loss: 0.60415
Epoch 12, iter 388, Dice Sup Loss: 0.39004, BCE Sup Loss: 0.51704
Epoch 12, iter 389, Dice Sup Loss: 0.45069, BCE Sup Loss: 0.5659
Epoch 12, iter 390, Dice Sup Loss: 0.64516, BCE Sup Loss: 0.5332
Epoch 12, Total train step 389 || AVG_loss: 0.52081, Avg Dice score: 0.1126, Avg IOU: 0.0644
Epoch 12, Validation || sum_loss: 0.99902, Dice score: 0.1667, IOU: 0.104
New best epoch 12!===============================
Training and evaluating on epoch12 complete in 0m 8s
Epoch 13, iter 391, Dice Sup Loss: 0.50304, BCE Sup Loss: 0.61556
Epoch 13, iter 392, Dice Sup Loss: 0.49149, BCE Sup Loss: 0.53302
Epoch 13, iter 393, Dice Sup Loss: 0.47198, BCE Sup Loss: 0.5469
Epoch 13, iter 394, Dice Sup Loss: 0.39198, BCE Sup Loss: 0.51136
Epoch 13, iter 395, Dice Sup Loss: 0.53702, BCE Sup Loss: 0.58919
Epoch 13, iter 396, Dice Sup Loss: 0.5065, BCE Sup Loss: 0.64159
Epoch 13, iter 397, Dice Sup Loss: 0.42859, BCE Sup Loss: 0.57712
Epoch 13, iter 398, Dice Sup Loss: 0.4756, BCE Sup Loss: 0.65907
Epoch 13, iter 399, Dice Sup Loss: 0.38561, BCE Sup Loss: 0.52383
Epoch 13, iter 400, Dice Sup Loss: 0.50756, BCE Sup Loss: 0.61248
Epoch 13, iter 401, Dice Sup Loss: 0.41564, BCE Sup Loss: 0.58396
Epoch 13, iter 402, Dice Sup Loss: 0.5005, BCE Sup Loss: 0.63509
Epoch 13, iter 403, Dice Sup Loss: 0.41474, BCE Sup Loss: 0.59618
Epoch 13, iter 404, Dice Sup Loss: 0.42118, BCE Sup Loss: 0.59542
Epoch 13, iter 405, Dice Sup Loss: 0.46644, BCE Sup Loss: 0.65242
Epoch 13, iter 406, Dice Sup Loss: 0.48724, BCE Sup Loss: 0.64584
Epoch 13, iter 407, Dice Sup Loss: 0.47235, BCE Sup Loss: 0.65154
Epoch 13, iter 408, Dice Sup Loss: 0.44654, BCE Sup Loss: 0.65559
Epoch 13, iter 409, Dice Sup Loss: 0.51189, BCE Sup Loss: 0.62429
Epoch 13, iter 410, Dice Sup Loss: 0.35855, BCE Sup Loss: 0.52925
Epoch 13, iter 411, Dice Sup Loss: 0.45313, BCE Sup Loss: 0.56644
Epoch 13, iter 412, Dice Sup Loss: 0.49266, BCE Sup Loss: 0.61971
Epoch 13, iter 413, Dice Sup Loss: 0.42839, BCE Sup Loss: 0.56103
Epoch 13, iter 414, Dice Sup Loss: 0.45934, BCE Sup Loss: 0.57646
Epoch 13, iter 415, Dice Sup Loss: 0.34196, BCE Sup Loss: 0.53112
Epoch 13, iter 416, Dice Sup Loss: 0.44478, BCE Sup Loss: 0.45707
Epoch 13, iter 417, Dice Sup Loss: 0.43071, BCE Sup Loss: 0.60904
Epoch 13, iter 418, Dice Sup Loss: 0.52664, BCE Sup Loss: 0.58895
Epoch 13, iter 419, Dice Sup Loss: 0.50691, BCE Sup Loss: 0.61052
Epoch 13, iter 420, Dice Sup Loss: 0.49985, BCE Sup Loss: 0.61815
Epoch 13, Total train step 419 || AVG_loss: 0.52393, Avg Dice score: 0.1096, Avg IOU: 0.0632
Epoch 13, Validation || sum_loss: 0.99976, Dice score: 0.167, IOU: 0.1041
New best epoch 13!===============================
Training and evaluating on epoch13 complete in 0m 8s
Epoch 14, iter 421, Dice Sup Loss: 0.50936, BCE Sup Loss: 0.60557
Epoch 14, iter 422, Dice Sup Loss: 0.52599, BCE Sup Loss: 0.5914
Epoch 14, iter 423, Dice Sup Loss: 0.53829, BCE Sup Loss: 0.5834
Epoch 14, iter 424, Dice Sup Loss: 0.42178, BCE Sup Loss: 0.52074
Epoch 14, iter 425, Dice Sup Loss: 0.40871, BCE Sup Loss: 0.61566
Epoch 14, iter 426, Dice Sup Loss: 0.4939, BCE Sup Loss: 0.61912
Epoch 14, iter 427, Dice Sup Loss: 0.39469, BCE Sup Loss: 0.59696
Epoch 14, iter 428, Dice Sup Loss: 0.30231, BCE Sup Loss: 0.459
Epoch 14, iter 429, Dice Sup Loss: 0.41301, BCE Sup Loss: 0.59903
Epoch 14, iter 430, Dice Sup Loss: 0.42224, BCE Sup Loss: 0.58294
Epoch 14, iter 431, Dice Sup Loss: 0.37785, BCE Sup Loss: 0.5314
Epoch 14, iter 432, Dice Sup Loss: 0.45113, BCE Sup Loss: 0.57556
Epoch 14, iter 433, Dice Sup Loss: 0.51001, BCE Sup Loss: 0.63642
Epoch 14, iter 434, Dice Sup Loss: 0.41555, BCE Sup Loss: 0.58882
Epoch 14, iter 435, Dice Sup Loss: 0.40406, BCE Sup Loss: 0.59583
Epoch 14, iter 436, Dice Sup Loss: 0.43828, BCE Sup Loss: 0.57746
Epoch 14, iter 437, Dice Sup Loss: 0.49461, BCE Sup Loss: 0.62667
Epoch 14, iter 438, Dice Sup Loss: 0.4998, BCE Sup Loss: 0.61901
Epoch 14, iter 439, Dice Sup Loss: 0.43162, BCE Sup Loss: 0.58683
Epoch 14, iter 440, Dice Sup Loss: 0.43075, BCE Sup Loss: 0.58269
Epoch 14, iter 441, Dice Sup Loss: 0.50844, BCE Sup Loss: 0.60505
Epoch 14, iter 442, Dice Sup Loss: 0.4142, BCE Sup Loss: 0.59197
Epoch 14, iter 443, Dice Sup Loss: 0.51344, BCE Sup Loss: 0.60282
Epoch 14, iter 444, Dice Sup Loss: 0.41593, BCE Sup Loss: 0.59997
Epoch 14, iter 445, Dice Sup Loss: 0.49744, BCE Sup Loss: 0.61645
Epoch 14, iter 446, Dice Sup Loss: 0.40181, BCE Sup Loss: 0.57145
Epoch 14, iter 447, Dice Sup Loss: 0.51026, BCE Sup Loss: 0.60515
Epoch 14, iter 448, Dice Sup Loss: 0.53436, BCE Sup Loss: 0.59008
Epoch 14, iter 449, Dice Sup Loss: 0.47168, BCE Sup Loss: 0.63924
Epoch 14, iter 450, Dice Sup Loss: 0.45492, BCE Sup Loss: 0.65656
Epoch 14, Total train step 449 || AVG_loss: 0.52201, Avg Dice score: 0.1054, Avg IOU: 0.0604
Epoch 14, Validation || sum_loss: 0.99935, Dice score: 0.1648, IOU: 0.1027
Training and evaluating on epoch14 complete in 0m 8s
Epoch 15, iter 451, Dice Sup Loss: 0.46505, BCE Sup Loss: 0.64314
Epoch 15, iter 452, Dice Sup Loss: 0.43348, BCE Sup Loss: 0.57954
Epoch 15, iter 453, Dice Sup Loss: 0.44773, BCE Sup Loss: 0.57116
Epoch 15, iter 454, Dice Sup Loss: 0.48571, BCE Sup Loss: 0.63124
Epoch 15, iter 455, Dice Sup Loss: 0.4675, BCE Sup Loss: 0.5583
Epoch 15, iter 456, Dice Sup Loss: 0.44671, BCE Sup Loss: 0.65433
Epoch 15, iter 457, Dice Sup Loss: 0.48574, BCE Sup Loss: 0.63317
Epoch 15, iter 458, Dice Sup Loss: 0.49777, BCE Sup Loss: 0.6266
Epoch 15, iter 459, Dice Sup Loss: 0.47121, BCE Sup Loss: 0.63879
Epoch 15, iter 460, Dice Sup Loss: 0.39904, BCE Sup Loss: 0.59955
Epoch 15, iter 461, Dice Sup Loss: 0.45404, BCE Sup Loss: 0.56573
Epoch 15, iter 462, Dice Sup Loss: 0.51519, BCE Sup Loss: 0.6105
Epoch 15, iter 463, Dice Sup Loss: 0.40143, BCE Sup Loss: 0.60681
Epoch 15, iter 464, Dice Sup Loss: 0.42375, BCE Sup Loss: 0.56289
Epoch 15, iter 465, Dice Sup Loss: 0.46576, BCE Sup Loss: 0.55764
Epoch 15, iter 466, Dice Sup Loss: 0.4109, BCE Sup Loss: 0.57898
Epoch 15, iter 467, Dice Sup Loss: 0.37782, BCE Sup Loss: 0.58557
Epoch 15, iter 468, Dice Sup Loss: 0.38948, BCE Sup Loss: 0.43016
Epoch 15, iter 469, Dice Sup Loss: 0.46434, BCE Sup Loss: 0.64772
Epoch 15, iter 470, Dice Sup Loss: 0.49316, BCE Sup Loss: 0.52804
Epoch 15, iter 471, Dice Sup Loss: 0.40924, BCE Sup Loss: 0.59512
Epoch 15, iter 472, Dice Sup Loss: 0.50776, BCE Sup Loss: 0.60714
Epoch 15, iter 473, Dice Sup Loss: 0.39835, BCE Sup Loss: 0.59023
Epoch 15, iter 474, Dice Sup Loss: 0.43504, BCE Sup Loss: 0.57506
Epoch 15, iter 475, Dice Sup Loss: 0.44471, BCE Sup Loss: 0.58857
Epoch 15, iter 476, Dice Sup Loss: 0.45276, BCE Sup Loss: 0.5508
Epoch 15, iter 477, Dice Sup Loss: 0.42853, BCE Sup Loss: 0.54748
Epoch 15, iter 478, Dice Sup Loss: 0.46909, BCE Sup Loss: 0.64118
Epoch 15, iter 479, Dice Sup Loss: 0.48431, BCE Sup Loss: 0.62738
Epoch 15, iter 480, Dice Sup Loss: 0.50668, BCE Sup Loss: 0.60834
Epoch 15, Total train step 479 || AVG_loss: 0.52013, Avg Dice score: 0.1179, Avg IOU: 0.0665
Epoch 15, Validation || sum_loss: 0.99842, Dice score: 0.1654, IOU: 0.1031
Training and evaluating on epoch15 complete in 0m 8s
Epoch 16, iter 481, Dice Sup Loss: 0.42336, BCE Sup Loss: 0.48645
Epoch 16, iter 482, Dice Sup Loss: 0.43903, BCE Sup Loss: 0.47108
Epoch 16, iter 483, Dice Sup Loss: 0.43276, BCE Sup Loss: 0.54786
Epoch 16, iter 484, Dice Sup Loss: 0.37611, BCE Sup Loss: 0.42194
Epoch 16, iter 485, Dice Sup Loss: 0.50326, BCE Sup Loss: 0.61616
Epoch 16, iter 486, Dice Sup Loss: 0.33645, BCE Sup Loss: 0.53658
Epoch 16, iter 487, Dice Sup Loss: 0.50597, BCE Sup Loss: 0.61562
Epoch 16, iter 488, Dice Sup Loss: 0.51292, BCE Sup Loss: 0.59748
Epoch 16, iter 489, Dice Sup Loss: 0.4216, BCE Sup Loss: 0.5467
Epoch 16, iter 490, Dice Sup Loss: 0.41602, BCE Sup Loss: 0.58
Epoch 16, iter 491, Dice Sup Loss: 0.46117, BCE Sup Loss: 0.54836
Epoch 16, iter 492, Dice Sup Loss: 0.47169, BCE Sup Loss: 0.64567
Epoch 16, iter 493, Dice Sup Loss: 0.42149, BCE Sup Loss: 0.57788
Epoch 16, iter 494, Dice Sup Loss: 0.49305, BCE Sup Loss: 0.54985
Epoch 16, iter 495, Dice Sup Loss: 0.42321, BCE Sup Loss: 0.58935
Epoch 16, iter 496, Dice Sup Loss: 0.51075, BCE Sup Loss: 0.61458
Epoch 16, iter 497, Dice Sup Loss: 0.45208, BCE Sup Loss: 0.65127
Epoch 16, iter 498, Dice Sup Loss: 0.49538, BCE Sup Loss: 0.62585
Epoch 16, iter 499, Dice Sup Loss: 0.50662, BCE Sup Loss: 0.62183
Epoch 16, iter 500, Dice Sup Loss: 0.36216, BCE Sup Loss: 0.53417
Epoch 16, iter 501, Dice Sup Loss: 0.46541, BCE Sup Loss: 0.64219
Epoch 16, iter 502, Dice Sup Loss: 0.40599, BCE Sup Loss: 0.6036
Epoch 16, iter 503, Dice Sup Loss: 0.46219, BCE Sup Loss: 0.64385
Epoch 16, iter 504, Dice Sup Loss: 0.4337, BCE Sup Loss: 0.66392
Epoch 16, iter 505, Dice Sup Loss: 0.4686, BCE Sup Loss: 0.64541
Epoch 16, iter 506, Dice Sup Loss: 0.44558, BCE Sup Loss: 0.65451
Epoch 16, iter 507, Dice Sup Loss: 0.49029, BCE Sup Loss: 0.63612
Epoch 16, iter 508, Dice Sup Loss: 0.43308, BCE Sup Loss: 0.58118
Epoch 16, iter 509, Dice Sup Loss: 0.49651, BCE Sup Loss: 0.63174
Epoch 16, iter 510, Dice Sup Loss: 0.42566, BCE Sup Loss: 0.66787
Epoch 16, Total train step 509 || AVG_loss: 0.5199, Avg Dice score: 0.1145, Avg IOU: 0.067
Epoch 16, Validation || sum_loss: 1.00466, Dice score: 0.1672, IOU: 0.1043
New best epoch 16!===============================
Training and evaluating on epoch16 complete in 0m 8s
Epoch 17, iter 511, Dice Sup Loss: 0.49322, BCE Sup Loss: 0.62986
Epoch 17, iter 512, Dice Sup Loss: 0.36533, BCE Sup Loss: 0.53332
Epoch 17, iter 513, Dice Sup Loss: 0.41295, BCE Sup Loss: 0.59155
Epoch 17, iter 514, Dice Sup Loss: 0.46491, BCE Sup Loss: 0.64221
Epoch 17, iter 515, Dice Sup Loss: 0.40676, BCE Sup Loss: 0.56742
Epoch 17, iter 516, Dice Sup Loss: 0.37715, BCE Sup Loss: 0.51408
Epoch 17, iter 517, Dice Sup Loss: 0.51074, BCE Sup Loss: 0.61146
Epoch 17, iter 518, Dice Sup Loss: 0.48665, BCE Sup Loss: 0.6248
Epoch 17, iter 519, Dice Sup Loss: 0.51891, BCE Sup Loss: 0.6009
Epoch 17, iter 520, Dice Sup Loss: 0.43958, BCE Sup Loss: 0.55504
Epoch 17, iter 521, Dice Sup Loss: 0.41332, BCE Sup Loss: 0.49668
Epoch 17, iter 522, Dice Sup Loss: 0.49813, BCE Sup Loss: 0.61694
Epoch 17, iter 523, Dice Sup Loss: 0.43073, BCE Sup Loss: 0.58974
Epoch 17, iter 524, Dice Sup Loss: 0.49839, BCE Sup Loss: 0.61755
Epoch 17, iter 525, Dice Sup Loss: 0.51496, BCE Sup Loss: 0.59971
Epoch 17, iter 526, Dice Sup Loss: 0.45577, BCE Sup Loss: 0.56266
Epoch 17, iter 527, Dice Sup Loss: 0.40897, BCE Sup Loss: 0.59625
Epoch 17, iter 528, Dice Sup Loss: 0.48396, BCE Sup Loss: 0.62779
Epoch 17, iter 529, Dice Sup Loss: 0.47983, BCE Sup Loss: 0.54772
Epoch 17, iter 530, Dice Sup Loss: 0.45359, BCE Sup Loss: 0.65094
Epoch 17, iter 531, Dice Sup Loss: 0.46584, BCE Sup Loss: 0.64117
Epoch 17, iter 532, Dice Sup Loss: 0.33507, BCE Sup Loss: 0.53134
Epoch 17, iter 533, Dice Sup Loss: 0.42761, BCE Sup Loss: 0.66703
Epoch 17, iter 534, Dice Sup Loss: 0.51749, BCE Sup Loss: 0.62603
Epoch 17, iter 535, Dice Sup Loss: 0.40735, BCE Sup Loss: 0.52756
Epoch 17, iter 536, Dice Sup Loss: 0.41921, BCE Sup Loss: 0.58938
Epoch 17, iter 537, Dice Sup Loss: 0.46654, BCE Sup Loss: 0.64507
Epoch 17, iter 538, Dice Sup Loss: 0.41788, BCE Sup Loss: 0.57469
Epoch 17, iter 539, Dice Sup Loss: 0.45467, BCE Sup Loss: 0.55906
Epoch 17, iter 540, Dice Sup Loss: 0.40723, BCE Sup Loss: 0.69539
Epoch 17, Total train step 539 || AVG_loss: 0.52019, Avg Dice score: 0.1133, Avg IOU: 0.0647
Epoch 17, Validation || sum_loss: 0.99816, Dice score: 0.1667, IOU: 0.1041
Training and evaluating on epoch17 complete in 0m 7s
Epoch 18, iter 541, Dice Sup Loss: 0.45307, BCE Sup Loss: 0.56045
Epoch 18, iter 542, Dice Sup Loss: 0.4811, BCE Sup Loss: 0.62944
Epoch 18, iter 543, Dice Sup Loss: 0.48858, BCE Sup Loss: 0.53637
Epoch 18, iter 544, Dice Sup Loss: 0.45237, BCE Sup Loss: 0.56397
Epoch 18, iter 545, Dice Sup Loss: 0.47943, BCE Sup Loss: 0.5416
Epoch 18, iter 546, Dice Sup Loss: 0.39034, BCE Sup Loss: 0.61305
Epoch 18, iter 547, Dice Sup Loss: 0.3807, BCE Sup Loss: 0.51118
Epoch 18, iter 548, Dice Sup Loss: 0.45723, BCE Sup Loss: 0.66004
Epoch 18, iter 549, Dice Sup Loss: 0.37609, BCE Sup Loss: 0.5813
Epoch 18, iter 550, Dice Sup Loss: 0.50383, BCE Sup Loss: 0.61186
Epoch 18, iter 551, Dice Sup Loss: 0.47558, BCE Sup Loss: 0.63407
Epoch 18, iter 552, Dice Sup Loss: 0.41962, BCE Sup Loss: 0.58071
Epoch 18, iter 553, Dice Sup Loss: 0.43399, BCE Sup Loss: 0.57831
Epoch 18, iter 554, Dice Sup Loss: 0.41095, BCE Sup Loss: 0.59132
Epoch 18, iter 555, Dice Sup Loss: 0.48106, BCE Sup Loss: 0.63341
Epoch 18, iter 556, Dice Sup Loss: 0.45286, BCE Sup Loss: 0.65067
Epoch 18, iter 557, Dice Sup Loss: 0.46672, BCE Sup Loss: 0.64359
Epoch 18, iter 558, Dice Sup Loss: 0.48991, BCE Sup Loss: 0.63417
Epoch 18, iter 559, Dice Sup Loss: 0.45439, BCE Sup Loss: 0.65003
Epoch 18, iter 560, Dice Sup Loss: 0.48373, BCE Sup Loss: 0.63721
Epoch 18, iter 561, Dice Sup Loss: 0.45122, BCE Sup Loss: 0.56784
Epoch 18, iter 562, Dice Sup Loss: 0.45511, BCE Sup Loss: 0.5596
Epoch 18, iter 563, Dice Sup Loss: 0.46602, BCE Sup Loss: 0.55344
Epoch 18, iter 564, Dice Sup Loss: 0.31691, BCE Sup Loss: 0.44963
Epoch 18, iter 565, Dice Sup Loss: 0.49619, BCE Sup Loss: 0.61685
Epoch 18, iter 566, Dice Sup Loss: 0.48072, BCE Sup Loss: 0.63562
Epoch 18, iter 567, Dice Sup Loss: 0.41999, BCE Sup Loss: 0.58565
Epoch 18, iter 568, Dice Sup Loss: 0.39046, BCE Sup Loss: 0.4927
Epoch 18, iter 569, Dice Sup Loss: 0.53284, BCE Sup Loss: 0.58364
Epoch 18, iter 570, Dice Sup Loss: 0.4448, BCE Sup Loss: 0.713
Epoch 18, Total train step 569 || AVG_loss: 0.51972, Avg Dice score: 0.1126, Avg IOU: 0.065
Epoch 18, Validation || sum_loss: 0.99519, Dice score: 0.1682, IOU: 0.1053
New best epoch 18!===============================
Training and evaluating on epoch18 complete in 0m 8s
Epoch 19, iter 571, Dice Sup Loss: 0.48004, BCE Sup Loss: 0.63917
Epoch 19, iter 572, Dice Sup Loss: 0.35093, BCE Sup Loss: 0.45163
Epoch 19, iter 573, Dice Sup Loss: 0.46794, BCE Sup Loss: 0.64143
Epoch 19, iter 574, Dice Sup Loss: 0.4752, BCE Sup Loss: 0.63457
Epoch 19, iter 575, Dice Sup Loss: 0.45653, BCE Sup Loss: 0.56415
Epoch 19, iter 576, Dice Sup Loss: 0.41029, BCE Sup Loss: 0.50176
Epoch 19, iter 577, Dice Sup Loss: 0.37295, BCE Sup Loss: 0.58812
Epoch 19, iter 578, Dice Sup Loss: 0.42542, BCE Sup Loss: 0.58822
Epoch 19, iter 579, Dice Sup Loss: 0.45472, BCE Sup Loss: 0.65385
Epoch 19, iter 580, Dice Sup Loss: 0.50138, BCE Sup Loss: 0.63286
Epoch 19, iter 581, Dice Sup Loss: 0.40092, BCE Sup Loss: 0.59177
Epoch 19, iter 582, Dice Sup Loss: 0.50977, BCE Sup Loss: 0.62272
Epoch 19, iter 583, Dice Sup Loss: 0.48361, BCE Sup Loss: 0.63076
Epoch 19, iter 584, Dice Sup Loss: 0.44327, BCE Sup Loss: 0.57123
Epoch 19, iter 585, Dice Sup Loss: 0.47737, BCE Sup Loss: 0.63225
Epoch 19, iter 586, Dice Sup Loss: 0.40978, BCE Sup Loss: 0.59348
Epoch 19, iter 587, Dice Sup Loss: 0.45041, BCE Sup Loss: 0.56341
Epoch 19, iter 588, Dice Sup Loss: 0.33972, BCE Sup Loss: 0.52248
Epoch 19, iter 589, Dice Sup Loss: 0.3588, BCE Sup Loss: 0.51733
Epoch 19, iter 590, Dice Sup Loss: 0.4844, BCE Sup Loss: 0.62823
Epoch 19, iter 591, Dice Sup Loss: 0.44437, BCE Sup Loss: 0.56642
Epoch 19, iter 592, Dice Sup Loss: 0.50057, BCE Sup Loss: 0.61316
Epoch 19, iter 593, Dice Sup Loss: 0.47545, BCE Sup Loss: 0.63529
Epoch 19, iter 594, Dice Sup Loss: 0.48786, BCE Sup Loss: 0.62373
Epoch 19, iter 595, Dice Sup Loss: 0.47582, BCE Sup Loss: 0.54789
Epoch 19, iter 596, Dice Sup Loss: 0.45661, BCE Sup Loss: 0.57574
Epoch 19, iter 597, Dice Sup Loss: 0.50742, BCE Sup Loss: 0.61081
Epoch 19, iter 598, Dice Sup Loss: 0.4836, BCE Sup Loss: 0.62748
Epoch 19, iter 599, Dice Sup Loss: 0.42096, BCE Sup Loss: 0.56579
Epoch 19, iter 600, Dice Sup Loss: 0.53581, BCE Sup Loss: 0.59324
Epoch 19, Total train step 599 || AVG_loss: 0.51988, Avg Dice score: 0.11, Avg IOU: 0.0634
Epoch 19, Validation || sum_loss: 0.99684, Dice score: 0.1657, IOU: 0.1035
Training and evaluating on epoch19 complete in 0m 8s
Epoch 20, iter 601, Dice Sup Loss: 0.43624, BCE Sup Loss: 0.57382
Epoch 20, iter 602, Dice Sup Loss: 0.45521, BCE Sup Loss: 0.65553
Epoch 20, iter 603, Dice Sup Loss: 0.50963, BCE Sup Loss: 0.60711
Epoch 20, iter 604, Dice Sup Loss: 0.55901, BCE Sup Loss: 0.5778
Epoch 20, iter 605, Dice Sup Loss: 0.42038, BCE Sup Loss: 0.56412
Epoch 20, iter 606, Dice Sup Loss: 0.48595, BCE Sup Loss: 0.62781
Epoch 20, iter 607, Dice Sup Loss: 0.46865, BCE Sup Loss: 0.64772
Epoch 20, iter 608, Dice Sup Loss: 0.40856, BCE Sup Loss: 0.53043
Epoch 20, iter 609, Dice Sup Loss: 0.50764, BCE Sup Loss: 0.60681
Epoch 20, iter 610, Dice Sup Loss: 0.41758, BCE Sup Loss: 0.5674
Epoch 20, iter 611, Dice Sup Loss: 0.49486, BCE Sup Loss: 0.61823
Epoch 20, iter 612, Dice Sup Loss: 0.47268, BCE Sup Loss: 0.63723
Epoch 20, iter 613, Dice Sup Loss: 0.48666, BCE Sup Loss: 0.62514
Epoch 20, iter 614, Dice Sup Loss: 0.46492, BCE Sup Loss: 0.55279
Epoch 20, iter 615, Dice Sup Loss: 0.47094, BCE Sup Loss: 0.5418
Epoch 20, iter 616, Dice Sup Loss: 0.42754, BCE Sup Loss: 0.58316
Epoch 20, iter 617, Dice Sup Loss: 0.44652, BCE Sup Loss: 0.65806
Epoch 20, iter 618, Dice Sup Loss: 0.437, BCE Sup Loss: 0.56196
Epoch 20, iter 619, Dice Sup Loss: 0.44144, BCE Sup Loss: 0.57132
Epoch 20, iter 620, Dice Sup Loss: 0.41983, BCE Sup Loss: 0.57367
Epoch 20, iter 621, Dice Sup Loss: 0.32759, BCE Sup Loss: 0.45617
Epoch 20, iter 622, Dice Sup Loss: 0.49218, BCE Sup Loss: 0.62356
Epoch 20, iter 623, Dice Sup Loss: 0.44621, BCE Sup Loss: 0.65732
Epoch 20, iter 624, Dice Sup Loss: 0.44841, BCE Sup Loss: 0.65452
Epoch 20, iter 625, Dice Sup Loss: 0.42037, BCE Sup Loss: 0.57441
Epoch 20, iter 626, Dice Sup Loss: 0.45781, BCE Sup Loss: 0.64558
Epoch 20, iter 627, Dice Sup Loss: 0.35532, BCE Sup Loss: 0.50117
Epoch 20, iter 628, Dice Sup Loss: 0.46034, BCE Sup Loss: 0.56331
Epoch 20, iter 629, Dice Sup Loss: 0.37765, BCE Sup Loss: 0.49602
Epoch 20, iter 630, Dice Sup Loss: 0.55444, BCE Sup Loss: 0.58891
Epoch 20, Total train step 629 || AVG_loss: 0.5187, Avg Dice score: 0.1164, Avg IOU: 0.0679
Epoch 20, Validation || sum_loss: 0.99484, Dice score: 0.1685, IOU: 0.1054
New best epoch 20!===============================
Training and evaluating on epoch20 complete in 0m 8s
Epoch 21, iter 631, Dice Sup Loss: 0.3982, BCE Sup Loss: 0.59961
Epoch 21, iter 632, Dice Sup Loss: 0.46033, BCE Sup Loss: 0.55375
Epoch 21, iter 633, Dice Sup Loss: 0.50081, BCE Sup Loss: 0.61213
Epoch 21, iter 634, Dice Sup Loss: 0.41272, BCE Sup Loss: 0.55291
Epoch 21, iter 635, Dice Sup Loss: 0.5401, BCE Sup Loss: 0.57859
Epoch 21, iter 636, Dice Sup Loss: 0.42054, BCE Sup Loss: 0.55308
Epoch 21, iter 637, Dice Sup Loss: 0.45249, BCE Sup Loss: 0.57329
Epoch 21, iter 638, Dice Sup Loss: 0.45888, BCE Sup Loss: 0.58212
Epoch 21, iter 639, Dice Sup Loss: 0.44024, BCE Sup Loss: 0.5309
Epoch 21, iter 640, Dice Sup Loss: 0.52992, BCE Sup Loss: 0.58533
Epoch 21, iter 641, Dice Sup Loss: 0.53666, BCE Sup Loss: 0.57957
Epoch 21, iter 642, Dice Sup Loss: 0.50055, BCE Sup Loss: 0.61731
Epoch 21, iter 643, Dice Sup Loss: 0.55448, BCE Sup Loss: 0.56506
Epoch 21, iter 644, Dice Sup Loss: 0.34562, BCE Sup Loss: 0.5135
Epoch 21, iter 645, Dice Sup Loss: 0.49526, BCE Sup Loss: 0.62252
Epoch 21, iter 646, Dice Sup Loss: 0.41144, BCE Sup Loss: 0.62586
Epoch 21, iter 647, Dice Sup Loss: 0.49971, BCE Sup Loss: 0.61373
Epoch 21, iter 648, Dice Sup Loss: 0.40202, BCE Sup Loss: 0.57946
Epoch 21, iter 649, Dice Sup Loss: 0.4635, BCE Sup Loss: 0.56034
Epoch 21, iter 650, Dice Sup Loss: 0.36627, BCE Sup Loss: 0.53689
Epoch 21, iter 651, Dice Sup Loss: 0.47117, BCE Sup Loss: 0.64753
Epoch 21, iter 652, Dice Sup Loss: 0.48062, BCE Sup Loss: 0.55836
Epoch 21, iter 653, Dice Sup Loss: 0.3987, BCE Sup Loss: 0.50792
Epoch 21, iter 654, Dice Sup Loss: 0.45321, BCE Sup Loss: 0.6505
Epoch 21, iter 655, Dice Sup Loss: 0.44256, BCE Sup Loss: 0.65859
Epoch 21, iter 656, Dice Sup Loss: 0.44234, BCE Sup Loss: 0.65768
Epoch 21, iter 657, Dice Sup Loss: 0.42151, BCE Sup Loss: 0.58393
Epoch 21, iter 658, Dice Sup Loss: 0.40115, BCE Sup Loss: 0.50408
Epoch 21, iter 659, Dice Sup Loss: 0.46467, BCE Sup Loss: 0.64347
Epoch 21, iter 660, Dice Sup Loss: 0.45358, BCE Sup Loss: 0.651
Epoch 21, Total train step 659 || AVG_loss: 0.51934, Avg Dice score: 0.1141, Avg IOU: 0.0653
Epoch 21, Validation || sum_loss: 0.99971, Dice score: 0.1666, IOU: 0.1041
Training and evaluating on epoch21 complete in 0m 7s
Epoch 22, iter 661, Dice Sup Loss: 0.43852, BCE Sup Loss: 0.49166
Epoch 22, iter 662, Dice Sup Loss: 0.48502, BCE Sup Loss: 0.63357
Epoch 22, iter 663, Dice Sup Loss: 0.41429, BCE Sup Loss: 0.57955
Epoch 22, iter 664, Dice Sup Loss: 0.50698, BCE Sup Loss: 0.614
Epoch 22, iter 665, Dice Sup Loss: 0.43877, BCE Sup Loss: 0.66773
Epoch 22, iter 666, Dice Sup Loss: 0.49395, BCE Sup Loss: 0.61918
Epoch 22, iter 667, Dice Sup Loss: 0.45742, BCE Sup Loss: 0.65049
Epoch 22, iter 668, Dice Sup Loss: 0.42152, BCE Sup Loss: 0.56154
Epoch 22, iter 669, Dice Sup Loss: 0.33443, BCE Sup Loss: 0.52379
Epoch 22, iter 670, Dice Sup Loss: 0.36744, BCE Sup Loss: 0.52222
Epoch 22, iter 671, Dice Sup Loss: 0.46371, BCE Sup Loss: 0.6469
Epoch 22, iter 672, Dice Sup Loss: 0.43908, BCE Sup Loss: 0.57765
Epoch 22, iter 673, Dice Sup Loss: 0.50213, BCE Sup Loss: 0.61285
Epoch 22, iter 674, Dice Sup Loss: 0.46455, BCE Sup Loss: 0.54265
Epoch 22, iter 675, Dice Sup Loss: 0.49393, BCE Sup Loss: 0.53154
Epoch 22, iter 676, Dice Sup Loss: 0.48999, BCE Sup Loss: 0.62206
Epoch 22, iter 677, Dice Sup Loss: 0.4118, BCE Sup Loss: 0.55502
Epoch 22, iter 678, Dice Sup Loss: 0.37789, BCE Sup Loss: 0.47394
Epoch 22, iter 679, Dice Sup Loss: 0.46672, BCE Sup Loss: 0.65551
Epoch 22, iter 680, Dice Sup Loss: 0.47908, BCE Sup Loss: 0.64022
Epoch 22, iter 681, Dice Sup Loss: 0.47138, BCE Sup Loss: 0.55433
Epoch 22, iter 682, Dice Sup Loss: 0.44919, BCE Sup Loss: 0.55762
Epoch 22, iter 683, Dice Sup Loss: 0.47749, BCE Sup Loss: 0.63714
Epoch 22, iter 684, Dice Sup Loss: 0.46658, BCE Sup Loss: 0.54969
Epoch 22, iter 685, Dice Sup Loss: 0.48785, BCE Sup Loss: 0.62395
Epoch 22, iter 686, Dice Sup Loss: 0.50786, BCE Sup Loss: 0.60913
Epoch 22, iter 687, Dice Sup Loss: 0.44752, BCE Sup Loss: 0.65919
Epoch 22, iter 688, Dice Sup Loss: 0.39446, BCE Sup Loss: 0.51651
Epoch 22, iter 689, Dice Sup Loss: 0.43931, BCE Sup Loss: 0.57104
Epoch 22, iter 690, Dice Sup Loss: 0.41023, BCE Sup Loss: 0.68208
Epoch 22, Total train step 689 || AVG_loss: 0.5189, Avg Dice score: 0.1174, Avg IOU: 0.0688
Epoch 22, Validation || sum_loss: 1.00178, Dice score: 0.1672, IOU: 0.1045
Training and evaluating on epoch22 complete in 0m 8s
Epoch 23, iter 691, Dice Sup Loss: 0.34266, BCE Sup Loss: 0.44753
Epoch 23, iter 692, Dice Sup Loss: 0.44658, BCE Sup Loss: 0.57623
Epoch 23, iter 693, Dice Sup Loss: 0.5048, BCE Sup Loss: 0.63417
Epoch 23, iter 694, Dice Sup Loss: 0.43366, BCE Sup Loss: 0.57662
Epoch 23, iter 695, Dice Sup Loss: 0.49927, BCE Sup Loss: 0.6323
Epoch 23, iter 696, Dice Sup Loss: 0.48485, BCE Sup Loss: 0.6335
Epoch 23, iter 697, Dice Sup Loss: 0.50419, BCE Sup Loss: 0.61988
Epoch 23, iter 698, Dice Sup Loss: 0.47525, BCE Sup Loss: 0.63399
Epoch 23, iter 699, Dice Sup Loss: 0.43592, BCE Sup Loss: 0.60365
Epoch 23, iter 700, Dice Sup Loss: 0.47299, BCE Sup Loss: 0.54397
Epoch 23, iter 701, Dice Sup Loss: 0.41731, BCE Sup Loss: 0.60273
Epoch 23, iter 702, Dice Sup Loss: 0.50099, BCE Sup Loss: 0.61266
Epoch 23, iter 703, Dice Sup Loss: 0.50274, BCE Sup Loss: 0.61101
Epoch 23, iter 704, Dice Sup Loss: 0.36344, BCE Sup Loss: 0.52025
Epoch 23, iter 705, Dice Sup Loss: 0.47792, BCE Sup Loss: 0.54277
Epoch 23, iter 706, Dice Sup Loss: 0.48322, BCE Sup Loss: 0.63047
Epoch 23, iter 707, Dice Sup Loss: 0.34247, BCE Sup Loss: 0.52811
Epoch 23, iter 708, Dice Sup Loss: 0.41107, BCE Sup Loss: 0.58222
Epoch 23, iter 709, Dice Sup Loss: 0.46978, BCE Sup Loss: 0.64191
Epoch 23, iter 710, Dice Sup Loss: 0.4843, BCE Sup Loss: 0.62667
Epoch 23, iter 711, Dice Sup Loss: 0.4925, BCE Sup Loss: 0.53254
Epoch 23, iter 712, Dice Sup Loss: 0.41245, BCE Sup Loss: 0.57244
Epoch 23, iter 713, Dice Sup Loss: 0.44136, BCE Sup Loss: 0.59217
Epoch 23, iter 714, Dice Sup Loss: 0.44663, BCE Sup Loss: 0.6585
Epoch 23, iter 715, Dice Sup Loss: 0.45714, BCE Sup Loss: 0.56573
Epoch 23, iter 716, Dice Sup Loss: 0.42666, BCE Sup Loss: 0.56783
Epoch 23, iter 717, Dice Sup Loss: 0.43972, BCE Sup Loss: 0.6609
Epoch 23, iter 718, Dice Sup Loss: 0.48207, BCE Sup Loss: 0.6317
Epoch 23, iter 719, Dice Sup Loss: 0.40781, BCE Sup Loss: 0.59387
Epoch 23, iter 720, Dice Sup Loss: 0.42677, BCE Sup Loss: 0.66873
Epoch 23, Total train step 719 || AVG_loss: 0.52143, Avg Dice score: 0.1122, Avg IOU: 0.0648
Epoch 23, Validation || sum_loss: 1.00482, Dice score: 0.1646, IOU: 0.1027
Training and evaluating on epoch23 complete in 0m 8s
Epoch 24, iter 721, Dice Sup Loss: 0.45187, BCE Sup Loss: 0.58233
Epoch 24, iter 722, Dice Sup Loss: 0.53114, BCE Sup Loss: 0.61979
Epoch 24, iter 723, Dice Sup Loss: 0.49178, BCE Sup Loss: 0.63275
Epoch 24, iter 724, Dice Sup Loss: 0.44149, BCE Sup Loss: 0.57627
Epoch 24, iter 725, Dice Sup Loss: 0.4745, BCE Sup Loss: 0.63714
Epoch 24, iter 726, Dice Sup Loss: 0.43767, BCE Sup Loss: 0.66182
Epoch 24, iter 727, Dice Sup Loss: 0.34463, BCE Sup Loss: 0.4633
Epoch 24, iter 728, Dice Sup Loss: 0.4691, BCE Sup Loss: 0.6403
Epoch 24, iter 729, Dice Sup Loss: 0.37102, BCE Sup Loss: 0.51568
Epoch 24, iter 730, Dice Sup Loss: 0.41499, BCE Sup Loss: 0.58646
Epoch 24, iter 731, Dice Sup Loss: 0.45313, BCE Sup Loss: 0.56068
Epoch 24, iter 732, Dice Sup Loss: 0.4572, BCE Sup Loss: 0.56137
Epoch 24, iter 733, Dice Sup Loss: 0.46743, BCE Sup Loss: 0.54986
Epoch 24, iter 734, Dice Sup Loss: 0.51857, BCE Sup Loss: 0.60186
Epoch 24, iter 735, Dice Sup Loss: 0.49834, BCE Sup Loss: 0.61507
Epoch 24, iter 736, Dice Sup Loss: 0.38186, BCE Sup Loss: 0.54158
Epoch 24, iter 737, Dice Sup Loss: 0.44981, BCE Sup Loss: 0.67256
Epoch 24, iter 738, Dice Sup Loss: 0.46564, BCE Sup Loss: 0.54833
Epoch 24, iter 739, Dice Sup Loss: 0.42954, BCE Sup Loss: 0.59279
Epoch 24, iter 740, Dice Sup Loss: 0.47169, BCE Sup Loss: 0.63839
Epoch 24, iter 741, Dice Sup Loss: 0.48183, BCE Sup Loss: 0.62872
Epoch 24, iter 742, Dice Sup Loss: 0.43706, BCE Sup Loss: 0.56923
Epoch 24, iter 743, Dice Sup Loss: 0.42395, BCE Sup Loss: 0.56396
Epoch 24, iter 744, Dice Sup Loss: 0.3648, BCE Sup Loss: 0.59194
Epoch 24, iter 745, Dice Sup Loss: 0.48416, BCE Sup Loss: 0.63248
Epoch 24, iter 746, Dice Sup Loss: 0.43702, BCE Sup Loss: 0.55533
Epoch 24, iter 747, Dice Sup Loss: 0.47922, BCE Sup Loss: 0.63181
Epoch 24, iter 748, Dice Sup Loss: 0.478, BCE Sup Loss: 0.63211
Epoch 24, iter 749, Dice Sup Loss: 0.39604, BCE Sup Loss: 0.57577
Epoch 24, iter 750, Dice Sup Loss: 0.49125, BCE Sup Loss: 0.62155
Epoch 24, Total train step 749 || AVG_loss: 0.52055, Avg Dice score: 0.1119, Avg IOU: 0.064
Epoch 24, Validation || sum_loss: 0.9964, Dice score: 0.1675, IOU: 0.1047
Training and evaluating on epoch24 complete in 0m 7s
Epoch 25, iter 751, Dice Sup Loss: 0.48112, BCE Sup Loss: 0.62958
Epoch 25, iter 752, Dice Sup Loss: 0.48675, BCE Sup Loss: 0.62485
Epoch 25, iter 753, Dice Sup Loss: 0.43315, BCE Sup Loss: 0.56279
Epoch 25, iter 754, Dice Sup Loss: 0.49271, BCE Sup Loss: 0.61972
Epoch 25, iter 755, Dice Sup Loss: 0.49395, BCE Sup Loss: 0.61874
Epoch 25, iter 756, Dice Sup Loss: 0.32487, BCE Sup Loss: 0.49378
Epoch 25, iter 757, Dice Sup Loss: 0.46224, BCE Sup Loss: 0.6523
Epoch 25, iter 758, Dice Sup Loss: 0.49324, BCE Sup Loss: 0.61984
Epoch 25, iter 759, Dice Sup Loss: 0.50079, BCE Sup Loss: 0.61282
Epoch 25, iter 760, Dice Sup Loss: 0.47927, BCE Sup Loss: 0.63296
Epoch 25, iter 761, Dice Sup Loss: 0.41707, BCE Sup Loss: 0.49931
Epoch 25, iter 762, Dice Sup Loss: 0.45402, BCE Sup Loss: 0.65689
Epoch 25, iter 763, Dice Sup Loss: 0.48107, BCE Sup Loss: 0.62937
Epoch 25, iter 764, Dice Sup Loss: 0.4213, BCE Sup Loss: 0.56289
Epoch 25, iter 765, Dice Sup Loss: 0.48829, BCE Sup Loss: 0.53655
Epoch 25, iter 766, Dice Sup Loss: 0.33989, BCE Sup Loss: 0.53749
Epoch 25, iter 767, Dice Sup Loss: 0.47138, BCE Sup Loss: 0.63704
Epoch 25, iter 768, Dice Sup Loss: 0.37912, BCE Sup Loss: 0.524
Epoch 25, iter 769, Dice Sup Loss: 0.40439, BCE Sup Loss: 0.50908
Epoch 25, iter 770, Dice Sup Loss: 0.47422, BCE Sup Loss: 0.63602
Epoch 25, iter 771, Dice Sup Loss: 0.53154, BCE Sup Loss: 0.6048
Epoch 25, iter 772, Dice Sup Loss: 0.45683, BCE Sup Loss: 0.57124
Epoch 25, iter 773, Dice Sup Loss: 0.43117, BCE Sup Loss: 0.67245
Epoch 25, iter 774, Dice Sup Loss: 0.40662, BCE Sup Loss: 0.56522
Epoch 25, iter 775, Dice Sup Loss: 0.39596, BCE Sup Loss: 0.51473
Epoch 25, iter 776, Dice Sup Loss: 0.42339, BCE Sup Loss: 0.57486
Epoch 25, iter 777, Dice Sup Loss: 0.44692, BCE Sup Loss: 0.57141
Epoch 25, iter 778, Dice Sup Loss: 0.48314, BCE Sup Loss: 0.62826
Epoch 25, iter 779, Dice Sup Loss: 0.49172, BCE Sup Loss: 0.54148
Epoch 25, iter 780, Dice Sup Loss: 0.46431, BCE Sup Loss: 0.64444
Epoch 25, Total train step 779 || AVG_loss: 0.51889, Avg Dice score: 0.113, Avg IOU: 0.0662
Epoch 25, Validation || sum_loss: 0.99593, Dice score: 0.1668, IOU: 0.1042
Training and evaluating on epoch25 complete in 0m 8s
Epoch 26, iter 781, Dice Sup Loss: 0.47443, BCE Sup Loss: 0.63453
Epoch 26, iter 782, Dice Sup Loss: 0.48706, BCE Sup Loss: 0.62442
Epoch 26, iter 783, Dice Sup Loss: 0.43334, BCE Sup Loss: 0.58185
Epoch 26, iter 784, Dice Sup Loss: 0.45169, BCE Sup Loss: 0.5563
Epoch 26, iter 785, Dice Sup Loss: 0.33654, BCE Sup Loss: 0.52282
Epoch 26, iter 786, Dice Sup Loss: 0.45791, BCE Sup Loss: 0.6494
Epoch 26, iter 787, Dice Sup Loss: 0.3862, BCE Sup Loss: 0.50827
Epoch 26, iter 788, Dice Sup Loss: 0.48677, BCE Sup Loss: 0.62587
Epoch 26, iter 789, Dice Sup Loss: 0.51104, BCE Sup Loss: 0.61176
Epoch 26, iter 790, Dice Sup Loss: 0.41316, BCE Sup Loss: 0.57648
Epoch 26, iter 791, Dice Sup Loss: 0.44086, BCE Sup Loss: 0.56884
Epoch 26, iter 792, Dice Sup Loss: 0.45547, BCE Sup Loss: 0.65111
Epoch 26, iter 793, Dice Sup Loss: 0.47359, BCE Sup Loss: 0.63517
Epoch 26, iter 794, Dice Sup Loss: 0.44008, BCE Sup Loss: 0.55378
Epoch 26, iter 795, Dice Sup Loss: 0.49136, BCE Sup Loss: 0.62251
Epoch 26, iter 796, Dice Sup Loss: 0.48111, BCE Sup Loss: 0.6299
Epoch 26, iter 797, Dice Sup Loss: 0.49254, BCE Sup Loss: 0.62129
Epoch 26, iter 798, Dice Sup Loss: 0.41641, BCE Sup Loss: 0.58188
Epoch 26, iter 799, Dice Sup Loss: 0.40785, BCE Sup Loss: 0.50215
Epoch 26, iter 800, Dice Sup Loss: 0.42601, BCE Sup Loss: 0.55256
Epoch 26, iter 801, Dice Sup Loss: 0.45832, BCE Sup Loss: 0.54918
Epoch 26, iter 802, Dice Sup Loss: 0.48994, BCE Sup Loss: 0.62244
Epoch 26, iter 803, Dice Sup Loss: 0.39225, BCE Sup Loss: 0.59999
Epoch 26, iter 804, Dice Sup Loss: 0.41176, BCE Sup Loss: 0.50841
Epoch 26, iter 805, Dice Sup Loss: 0.39972, BCE Sup Loss: 0.57059
Epoch 26, iter 806, Dice Sup Loss: 0.52891, BCE Sup Loss: 0.59117
Epoch 26, iter 807, Dice Sup Loss: 0.44686, BCE Sup Loss: 0.56733
Epoch 26, iter 808, Dice Sup Loss: 0.48422, BCE Sup Loss: 0.62801
Epoch 26, iter 809, Dice Sup Loss: 0.45544, BCE Sup Loss: 0.56455
Epoch 26, iter 810, Dice Sup Loss: 0.45865, BCE Sup Loss: 0.6507
Epoch 26, Total train step 809 || AVG_loss: 0.51815, Avg Dice score: 0.1142, Avg IOU: 0.0647
Epoch 26, Validation || sum_loss: 0.99577, Dice score: 0.1659, IOU: 0.1036
Training and evaluating on epoch26 complete in 0m 8s
Epoch 27, iter 811, Dice Sup Loss: 0.41022, BCE Sup Loss: 0.59774
Epoch 27, iter 812, Dice Sup Loss: 0.36318, BCE Sup Loss: 0.58935
Epoch 27, iter 813, Dice Sup Loss: 0.41271, BCE Sup Loss: 0.59347
Epoch 27, iter 814, Dice Sup Loss: 0.44004, BCE Sup Loss: 0.57586
Epoch 27, iter 815, Dice Sup Loss: 0.4116, BCE Sup Loss: 0.59012
Epoch 27, iter 816, Dice Sup Loss: 0.34416, BCE Sup Loss: 0.54335
Epoch 27, iter 817, Dice Sup Loss: 0.48205, BCE Sup Loss: 0.64695
Epoch 27, iter 818, Dice Sup Loss: 0.34272, BCE Sup Loss: 0.46296
Epoch 27, iter 819, Dice Sup Loss: 0.50534, BCE Sup Loss: 0.64063
Epoch 27, iter 820, Dice Sup Loss: 0.45521, BCE Sup Loss: 0.57207
Epoch 27, iter 821, Dice Sup Loss: 0.48668, BCE Sup Loss: 0.63571
Epoch 27, iter 822, Dice Sup Loss: 0.43171, BCE Sup Loss: 0.66499
Epoch 27, iter 823, Dice Sup Loss: 0.51087, BCE Sup Loss: 0.61556
Epoch 27, iter 824, Dice Sup Loss: 0.3833, BCE Sup Loss: 0.50537
Epoch 27, iter 825, Dice Sup Loss: 0.52633, BCE Sup Loss: 0.5985
Epoch 27, iter 826, Dice Sup Loss: 0.4277, BCE Sup Loss: 0.56606
Epoch 27, iter 827, Dice Sup Loss: 0.47941, BCE Sup Loss: 0.63515
Epoch 27, iter 828, Dice Sup Loss: 0.51102, BCE Sup Loss: 0.60339
Epoch 27, iter 829, Dice Sup Loss: 0.50366, BCE Sup Loss: 0.6113
Epoch 27, iter 830, Dice Sup Loss: 0.50335, BCE Sup Loss: 0.61167
Epoch 27, iter 831, Dice Sup Loss: 0.45171, BCE Sup Loss: 0.53515
Epoch 27, iter 832, Dice Sup Loss: 0.49025, BCE Sup Loss: 0.62816
Epoch 27, iter 833, Dice Sup Loss: 0.4768, BCE Sup Loss: 0.5398
Epoch 27, iter 834, Dice Sup Loss: 0.40524, BCE Sup Loss: 0.58327
Epoch 27, iter 835, Dice Sup Loss: 0.49696, BCE Sup Loss: 0.61791
Epoch 27, iter 836, Dice Sup Loss: 0.44614, BCE Sup Loss: 0.56758
Epoch 27, iter 837, Dice Sup Loss: 0.49466, BCE Sup Loss: 0.61899
Epoch 27, iter 838, Dice Sup Loss: 0.42025, BCE Sup Loss: 0.55911
Epoch 27, iter 839, Dice Sup Loss: 0.42993, BCE Sup Loss: 0.56813
Epoch 27, iter 840, Dice Sup Loss: 0.49434, BCE Sup Loss: 0.61884
Epoch 27, Total train step 839 || AVG_loss: 0.5195, Avg Dice score: 0.1114, Avg IOU: 0.0632
Epoch 27, Validation || sum_loss: 0.99689, Dice score: 0.1701, IOU: 0.1065
New best epoch 27!===============================
Training and evaluating on epoch27 complete in 0m 8s
Epoch 28, iter 841, Dice Sup Loss: 0.3347, BCE Sup Loss: 0.52812
Epoch 28, iter 842, Dice Sup Loss: 0.39885, BCE Sup Loss: 0.49848
Epoch 28, iter 843, Dice Sup Loss: 0.40967, BCE Sup Loss: 0.5695
Epoch 28, iter 844, Dice Sup Loss: 0.42877, BCE Sup Loss: 0.57339
Epoch 28, iter 845, Dice Sup Loss: 0.42935, BCE Sup Loss: 0.5799
Epoch 28, iter 846, Dice Sup Loss: 0.47976, BCE Sup Loss: 0.63039
Epoch 28, iter 847, Dice Sup Loss: 0.34593, BCE Sup Loss: 0.54084
Epoch 28, iter 848, Dice Sup Loss: 0.4108, BCE Sup Loss: 0.5764
Epoch 28, iter 849, Dice Sup Loss: 0.43486, BCE Sup Loss: 0.57664
Epoch 28, iter 850, Dice Sup Loss: 0.49457, BCE Sup Loss: 0.62285
Epoch 28, iter 851, Dice Sup Loss: 0.4746, BCE Sup Loss: 0.63538
Epoch 28, iter 852, Dice Sup Loss: 0.48322, BCE Sup Loss: 0.63047
Epoch 28, iter 853, Dice Sup Loss: 0.44575, BCE Sup Loss: 0.56205
Epoch 28, iter 854, Dice Sup Loss: 0.47787, BCE Sup Loss: 0.63301
Epoch 28, iter 855, Dice Sup Loss: 0.51665, BCE Sup Loss: 0.60894
Epoch 28, iter 856, Dice Sup Loss: 0.41903, BCE Sup Loss: 0.59211
Epoch 28, iter 857, Dice Sup Loss: 0.44535, BCE Sup Loss: 0.54823
Epoch 28, iter 858, Dice Sup Loss: 0.46906, BCE Sup Loss: 0.54849
Epoch 28, iter 859, Dice Sup Loss: 0.46829, BCE Sup Loss: 0.64354
Epoch 28, iter 860, Dice Sup Loss: 0.45307, BCE Sup Loss: 0.6611
Epoch 28, iter 861, Dice Sup Loss: 0.48338, BCE Sup Loss: 0.62764
Epoch 28, iter 862, Dice Sup Loss: 0.2917, BCE Sup Loss: 0.384
Epoch 28, iter 863, Dice Sup Loss: 0.45271, BCE Sup Loss: 0.56468
Epoch 28, iter 864, Dice Sup Loss: 0.47939, BCE Sup Loss: 0.63072
Epoch 28, iter 865, Dice Sup Loss: 0.50785, BCE Sup Loss: 0.61137
Epoch 28, iter 866, Dice Sup Loss: 0.5069, BCE Sup Loss: 0.61289
Epoch 28, iter 867, Dice Sup Loss: 0.47102, BCE Sup Loss: 0.63706
Epoch 28, iter 868, Dice Sup Loss: 0.52704, BCE Sup Loss: 0.6005
Epoch 28, iter 869, Dice Sup Loss: 0.47701, BCE Sup Loss: 0.63289
Epoch 28, iter 870, Dice Sup Loss: 0.43202, BCE Sup Loss: 0.67625
Epoch 28, Total train step 869 || AVG_loss: 0.51875, Avg Dice score: 0.1091, Avg IOU: 0.0646
Epoch 28, Validation || sum_loss: 0.9953, Dice score: 0.166, IOU: 0.1037
Training and evaluating on epoch28 complete in 0m 8s
Epoch 29, iter 871, Dice Sup Loss: 0.48511, BCE Sup Loss: 0.62633
Epoch 29, iter 872, Dice Sup Loss: 0.35554, BCE Sup Loss: 0.53476
Epoch 29, iter 873, Dice Sup Loss: 0.47458, BCE Sup Loss: 0.63487
Epoch 29, iter 874, Dice Sup Loss: 0.37929, BCE Sup Loss: 0.60105
Epoch 29, iter 875, Dice Sup Loss: 0.33977, BCE Sup Loss: 0.52317
Epoch 29, iter 876, Dice Sup Loss: 0.49916, BCE Sup Loss: 0.62835
Epoch 29, iter 877, Dice Sup Loss: 0.51898, BCE Sup Loss: 0.61712
Epoch 29, iter 878, Dice Sup Loss: 0.4391, BCE Sup Loss: 0.57202
Epoch 29, iter 879, Dice Sup Loss: 0.48432, BCE Sup Loss: 0.6296
Epoch 29, iter 880, Dice Sup Loss: 0.46218, BCE Sup Loss: 0.55388
Epoch 29, iter 881, Dice Sup Loss: 0.46752, BCE Sup Loss: 0.64036
Epoch 29, iter 882, Dice Sup Loss: 0.50345, BCE Sup Loss: 0.61245
Epoch 29, iter 883, Dice Sup Loss: 0.39815, BCE Sup Loss: 0.49672
Epoch 29, iter 884, Dice Sup Loss: 0.54013, BCE Sup Loss: 0.58363
Epoch 29, iter 885, Dice Sup Loss: 0.5064, BCE Sup Loss: 0.6079
Epoch 29, iter 886, Dice Sup Loss: 0.33499, BCE Sup Loss: 0.52295
Epoch 29, iter 887, Dice Sup Loss: 0.4569, BCE Sup Loss: 0.67958
Epoch 29, iter 888, Dice Sup Loss: 0.43559, BCE Sup Loss: 0.45984
Epoch 29, iter 889, Dice Sup Loss: 0.43037, BCE Sup Loss: 0.60472
Epoch 29, iter 890, Dice Sup Loss: 0.40293, BCE Sup Loss: 0.48046
Epoch 29, iter 891, Dice Sup Loss: 0.52145, BCE Sup Loss: 0.5954
Epoch 29, iter 892, Dice Sup Loss: 0.49889, BCE Sup Loss: 0.61441
Epoch 29, iter 893, Dice Sup Loss: 0.43478, BCE Sup Loss: 0.57275
Epoch 29, iter 894, Dice Sup Loss: 0.49288, BCE Sup Loss: 0.61961
Epoch 29, iter 895, Dice Sup Loss: 0.40437, BCE Sup Loss: 0.50594
Epoch 29, iter 896, Dice Sup Loss: 0.44493, BCE Sup Loss: 0.66537
Epoch 29, iter 897, Dice Sup Loss: 0.49692, BCE Sup Loss: 0.61776
Epoch 29, iter 898, Dice Sup Loss: 0.45382, BCE Sup Loss: 0.65088
Epoch 29, iter 899, Dice Sup Loss: 0.44286, BCE Sup Loss: 0.56811
Epoch 29, iter 900, Dice Sup Loss: 0.43928, BCE Sup Loss: 0.65949
Epoch 29, Total train step 899 || AVG_loss: 0.51953, Avg Dice score: 0.1111, Avg IOU: 0.0655
Epoch 29, Validation || sum_loss: 1.00227, Dice score: 0.1623, IOU: 0.1011
Training and evaluating on epoch29 complete in 0m 7s
Epoch 30, iter 901, Dice Sup Loss: 0.48646, BCE Sup Loss: 0.63142
Epoch 30, iter 902, Dice Sup Loss: 0.38433, BCE Sup Loss: 0.60754
Epoch 30, iter 903, Dice Sup Loss: 0.33448, BCE Sup Loss: 0.4599
Epoch 30, iter 904, Dice Sup Loss: 0.44473, BCE Sup Loss: 0.65609
Epoch 30, iter 905, Dice Sup Loss: 0.42587, BCE Sup Loss: 0.50635
Epoch 30, iter 906, Dice Sup Loss: 0.47918, BCE Sup Loss: 0.64299
Epoch 30, iter 907, Dice Sup Loss: 0.4556, BCE Sup Loss: 0.6507
Epoch 30, iter 908, Dice Sup Loss: 0.48662, BCE Sup Loss: 0.63575
Epoch 30, iter 909, Dice Sup Loss: 0.42367, BCE Sup Loss: 0.58627
Epoch 30, iter 910, Dice Sup Loss: 0.49866, BCE Sup Loss: 0.62423
Epoch 30, iter 911, Dice Sup Loss: 0.46415, BCE Sup Loss: 0.54564
Epoch 30, iter 912, Dice Sup Loss: 0.49265, BCE Sup Loss: 0.62122
Epoch 30, iter 913, Dice Sup Loss: 0.41577, BCE Sup Loss: 0.54897
Epoch 30, iter 914, Dice Sup Loss: 0.49609, BCE Sup Loss: 0.61701
Epoch 30, iter 915, Dice Sup Loss: 0.49737, BCE Sup Loss: 0.61912
Epoch 30, iter 916, Dice Sup Loss: 0.53472, BCE Sup Loss: 0.58126
Epoch 30, iter 917, Dice Sup Loss: 0.46805, BCE Sup Loss: 0.5551
Epoch 30, iter 918, Dice Sup Loss: 0.44677, BCE Sup Loss: 0.5811
Epoch 30, iter 919, Dice Sup Loss: 0.42756, BCE Sup Loss: 0.61935
Epoch 30, iter 920, Dice Sup Loss: 0.47187, BCE Sup Loss: 0.53997
Epoch 30, iter 921, Dice Sup Loss: 0.5107, BCE Sup Loss: 0.60432
Epoch 30, iter 922, Dice Sup Loss: 0.49804, BCE Sup Loss: 0.6164
Epoch 30, iter 923, Dice Sup Loss: 0.47614, BCE Sup Loss: 0.63674
Epoch 30, iter 924, Dice Sup Loss: 0.4651, BCE Sup Loss: 0.5647
Epoch 30, iter 925, Dice Sup Loss: 0.41329, BCE Sup Loss: 0.5709
Epoch 30, iter 926, Dice Sup Loss: 0.39895, BCE Sup Loss: 0.58283
Epoch 30, iter 927, Dice Sup Loss: 0.33373, BCE Sup Loss: 0.52083
Epoch 30, iter 928, Dice Sup Loss: 0.42602, BCE Sup Loss: 0.58318
Epoch 30, iter 929, Dice Sup Loss: 0.40659, BCE Sup Loss: 0.58961
Epoch 30, iter 930, Dice Sup Loss: 0.57888, BCE Sup Loss: 0.60043
Epoch 30, Total train step 929 || AVG_loss: 0.52034, Avg Dice score: 0.1132, Avg IOU: 0.0648
Epoch 30, Validation || sum_loss: 1.00024, Dice score: 0.1673, IOU: 0.1046
Training and evaluating on epoch30 complete in 0m 7s
Epoch 31, iter 931, Dice Sup Loss: 0.45738, BCE Sup Loss: 0.6476
Epoch 31, iter 932, Dice Sup Loss: 0.46531, BCE Sup Loss: 0.6433
Epoch 31, iter 933, Dice Sup Loss: 0.41546, BCE Sup Loss: 0.5793
Epoch 31, iter 934, Dice Sup Loss: 0.45961, BCE Sup Loss: 0.64593
Epoch 31, iter 935, Dice Sup Loss: 0.47783, BCE Sup Loss: 0.63429
Epoch 31, iter 936, Dice Sup Loss: 0.41197, BCE Sup Loss: 0.50453
Epoch 31, iter 937, Dice Sup Loss: 0.52257, BCE Sup Loss: 0.60844
Epoch 31, iter 938, Dice Sup Loss: 0.41933, BCE Sup Loss: 0.56402
Epoch 31, iter 939, Dice Sup Loss: 0.45635, BCE Sup Loss: 0.55123
Epoch 31, iter 940, Dice Sup Loss: 0.4792, BCE Sup Loss: 0.63114
Epoch 31, iter 941, Dice Sup Loss: 0.46037, BCE Sup Loss: 0.5532
Epoch 31, iter 942, Dice Sup Loss: 0.48966, BCE Sup Loss: 0.62281
Epoch 31, iter 943, Dice Sup Loss: 0.48017, BCE Sup Loss: 0.63396
Epoch 31, iter 944, Dice Sup Loss: 0.49366, BCE Sup Loss: 0.62002
Epoch 31, iter 945, Dice Sup Loss: 0.48422, BCE Sup Loss: 0.62982
Epoch 31, iter 946, Dice Sup Loss: 0.5367, BCE Sup Loss: 0.58444
Epoch 31, iter 947, Dice Sup Loss: 0.41761, BCE Sup Loss: 0.58374
Epoch 31, iter 948, Dice Sup Loss: 0.45633, BCE Sup Loss: 0.56259
Epoch 31, iter 949, Dice Sup Loss: 0.4505, BCE Sup Loss: 0.55979
Epoch 31, iter 950, Dice Sup Loss: 0.32088, BCE Sup Loss: 0.50243
Epoch 31, iter 951, Dice Sup Loss: 0.37543, BCE Sup Loss: 0.48573
Epoch 31, iter 952, Dice Sup Loss: 0.49018, BCE Sup Loss: 0.62244
Epoch 31, iter 953, Dice Sup Loss: 0.46452, BCE Sup Loss: 0.64899
Epoch 31, iter 954, Dice Sup Loss: 0.44548, BCE Sup Loss: 0.55999
Epoch 31, iter 955, Dice Sup Loss: 0.4232, BCE Sup Loss: 0.59805
Epoch 31, iter 956, Dice Sup Loss: 0.45875, BCE Sup Loss: 0.55699
Epoch 31, iter 957, Dice Sup Loss: 0.39298, BCE Sup Loss: 0.5019
Epoch 31, iter 958, Dice Sup Loss: 0.40322, BCE Sup Loss: 0.57904
Epoch 31, iter 959, Dice Sup Loss: 0.45533, BCE Sup Loss: 0.65021
Epoch 31, iter 960, Dice Sup Loss: 0.11097, BCE Sup Loss: 0.10591
Epoch 31, Total train step 959 || AVG_loss: 0.51772, Avg Dice score: 0.1146, Avg IOU: 0.0682
Epoch 31, Validation || sum_loss: 0.99619, Dice score: 0.1692, IOU: 0.1059
Training and evaluating on epoch31 complete in 0m 8s
Epoch 32, iter 961, Dice Sup Loss: 0.41604, BCE Sup Loss: 0.57714
Epoch 32, iter 962, Dice Sup Loss: 0.43581, BCE Sup Loss: 0.57402
Epoch 32, iter 963, Dice Sup Loss: 0.3851, BCE Sup Loss: 0.5959
Epoch 32, iter 964, Dice Sup Loss: 0.47317, BCE Sup Loss: 0.63822
Epoch 32, iter 965, Dice Sup Loss: 0.46487, BCE Sup Loss: 0.64276
Epoch 32, iter 966, Dice Sup Loss: 0.42535, BCE Sup Loss: 0.57877
Epoch 32, iter 967, Dice Sup Loss: 0.45536, BCE Sup Loss: 0.56571
Epoch 32, iter 968, Dice Sup Loss: 0.46681, BCE Sup Loss: 0.55762
Epoch 32, iter 969, Dice Sup Loss: 0.47555, BCE Sup Loss: 0.63593
Epoch 32, iter 970, Dice Sup Loss: 0.4748, BCE Sup Loss: 0.55503
Epoch 32, iter 971, Dice Sup Loss: 0.50194, BCE Sup Loss: 0.61548
Epoch 32, iter 972, Dice Sup Loss: 0.46981, BCE Sup Loss: 0.64012
Epoch 32, iter 973, Dice Sup Loss: 0.47168, BCE Sup Loss: 0.63864
Epoch 32, iter 974, Dice Sup Loss: 0.41243, BCE Sup Loss: 0.59763
Epoch 32, iter 975, Dice Sup Loss: 0.50968, BCE Sup Loss: 0.60563
Epoch 32, iter 976, Dice Sup Loss: 0.5, BCE Sup Loss: 0.61043
Epoch 32, iter 977, Dice Sup Loss: 0.45651, BCE Sup Loss: 0.55894
Epoch 32, iter 978, Dice Sup Loss: 0.4844, BCE Sup Loss: 0.62711
Epoch 32, iter 979, Dice Sup Loss: 0.47593, BCE Sup Loss: 0.63593
Epoch 32, iter 980, Dice Sup Loss: 0.43253, BCE Sup Loss: 0.57686
Epoch 32, iter 981, Dice Sup Loss: 0.51442, BCE Sup Loss: 0.60508
Epoch 32, iter 982, Dice Sup Loss: 0.40178, BCE Sup Loss: 0.50484
Epoch 32, iter 983, Dice Sup Loss: 0.40492, BCE Sup Loss: 0.58561
Epoch 32, iter 984, Dice Sup Loss: 0.46925, BCE Sup Loss: 0.63907
Epoch 32, iter 985, Dice Sup Loss: 0.43953, BCE Sup Loss: 0.66545
Epoch 32, iter 986, Dice Sup Loss: 0.44744, BCE Sup Loss: 0.57412
Epoch 32, iter 987, Dice Sup Loss: 0.29159, BCE Sup Loss: 0.44781
Epoch 32, iter 988, Dice Sup Loss: 0.46592, BCE Sup Loss: 0.56064
Epoch 32, iter 989, Dice Sup Loss: 0.37004, BCE Sup Loss: 0.51812
Epoch 32, iter 990, Dice Sup Loss: 0.53412, BCE Sup Loss: 0.60358
Epoch 32, Total train step 989 || AVG_loss: 0.51954, Avg Dice score: 0.112, Avg IOU: 0.0656
Epoch 32, Validation || sum_loss: 0.99729, Dice score: 0.1678, IOU: 0.1049
Training and evaluating on epoch32 complete in 0m 7s
Epoch 33, iter 991, Dice Sup Loss: 0.50144, BCE Sup Loss: 0.61704
Epoch 33, iter 992, Dice Sup Loss: 0.45819, BCE Sup Loss: 0.55607
Epoch 33, iter 993, Dice Sup Loss: 0.48167, BCE Sup Loss: 0.62902
Epoch 33, iter 994, Dice Sup Loss: 0.51448, BCE Sup Loss: 0.60176
Epoch 33, iter 995, Dice Sup Loss: 0.39919, BCE Sup Loss: 0.48174
Epoch 33, iter 996, Dice Sup Loss: 0.41162, BCE Sup Loss: 0.56681
Epoch 33, iter 997, Dice Sup Loss: 0.44048, BCE Sup Loss: 0.58334
Epoch 33, iter 998, Dice Sup Loss: 0.4997, BCE Sup Loss: 0.61936
Epoch 33, iter 999, Dice Sup Loss: 0.40921, BCE Sup Loss: 0.5679
Epoch 33, iter 1000, Dice Sup Loss: 0.44418, BCE Sup Loss: 0.54252
Epoch 33, iter 1001, Dice Sup Loss: 0.36744, BCE Sup Loss: 0.51841
Epoch 33, iter 1002, Dice Sup Loss: 0.4431, BCE Sup Loss: 0.57907
Epoch 33, iter 1003, Dice Sup Loss: 0.51842, BCE Sup Loss: 0.59723
Epoch 33, iter 1004, Dice Sup Loss: 0.42845, BCE Sup Loss: 0.5687
Epoch 33, iter 1005, Dice Sup Loss: 0.49536, BCE Sup Loss: 0.61758
Epoch 33, iter 1006, Dice Sup Loss: 0.47177, BCE Sup Loss: 0.63852
Epoch 33, iter 1007, Dice Sup Loss: 0.50434, BCE Sup Loss: 0.61237
Epoch 33, iter 1008, Dice Sup Loss: 0.42332, BCE Sup Loss: 0.58689
Epoch 33, iter 1009, Dice Sup Loss: 0.44625, BCE Sup Loss: 0.65616
Epoch 33, iter 1010, Dice Sup Loss: 0.34675, BCE Sup Loss: 0.44117
Epoch 33, iter 1011, Dice Sup Loss: 0.49723, BCE Sup Loss: 0.62717
Epoch 33, iter 1012, Dice Sup Loss: 0.4562, BCE Sup Loss: 0.64859
Epoch 33, iter 1013, Dice Sup Loss: 0.47975, BCE Sup Loss: 0.56499
Epoch 33, iter 1014, Dice Sup Loss: 0.45987, BCE Sup Loss: 0.64678
Epoch 33, iter 1015, Dice Sup Loss: 0.41982, BCE Sup Loss: 0.58262
Epoch 33, iter 1016, Dice Sup Loss: 0.50511, BCE Sup Loss: 0.62461
Epoch 33, iter 1017, Dice Sup Loss: 0.32874, BCE Sup Loss: 0.52703
Epoch 33, iter 1018, Dice Sup Loss: 0.45981, BCE Sup Loss: 0.55874
Epoch 33, iter 1019, Dice Sup Loss: 0.44999, BCE Sup Loss: 0.65336
Epoch 33, iter 1020, Dice Sup Loss: 0.40982, BCE Sup Loss: 0.69575
Epoch 33, Total train step 1019 || AVG_loss: 0.51872, Avg Dice score: 0.1128, Avg IOU: 0.0655
Epoch 33, Validation || sum_loss: 0.99883, Dice score: 0.167, IOU: 0.1042
Training and evaluating on epoch33 complete in 0m 8s
Epoch 34, iter 1021, Dice Sup Loss: 0.39309, BCE Sup Loss: 0.58892
Epoch 34, iter 1022, Dice Sup Loss: 0.45089, BCE Sup Loss: 0.6521
Epoch 34, iter 1023, Dice Sup Loss: 0.47807, BCE Sup Loss: 0.63356
Epoch 34, iter 1024, Dice Sup Loss: 0.51599, BCE Sup Loss: 0.61467
Epoch 34, iter 1025, Dice Sup Loss: 0.38902, BCE Sup Loss: 0.51374
Epoch 34, iter 1026, Dice Sup Loss: 0.35665, BCE Sup Loss: 0.50163
Epoch 34, iter 1027, Dice Sup Loss: 0.50114, BCE Sup Loss: 0.5363
Epoch 34, iter 1028, Dice Sup Loss: 0.4979, BCE Sup Loss: 0.62112
Epoch 34, iter 1029, Dice Sup Loss: 0.49122, BCE Sup Loss: 0.62109
Epoch 34, iter 1030, Dice Sup Loss: 0.49187, BCE Sup Loss: 0.61972
Epoch 34, iter 1031, Dice Sup Loss: 0.45713, BCE Sup Loss: 0.6608
Epoch 34, iter 1032, Dice Sup Loss: 0.4943, BCE Sup Loss: 0.61877
Epoch 34, iter 1033, Dice Sup Loss: 0.44822, BCE Sup Loss: 0.56782
Epoch 34, iter 1034, Dice Sup Loss: 0.48015, BCE Sup Loss: 0.63294
Epoch 34, iter 1035, Dice Sup Loss: 0.36841, BCE Sup Loss: 0.59214
Epoch 34, iter 1036, Dice Sup Loss: 0.51539, BCE Sup Loss: 0.60373
Epoch 34, iter 1037, Dice Sup Loss: 0.42404, BCE Sup Loss: 0.5681
Epoch 34, iter 1038, Dice Sup Loss: 0.42215, BCE Sup Loss: 0.59322
Epoch 34, iter 1039, Dice Sup Loss: 0.40242, BCE Sup Loss: 0.49917
Epoch 34, iter 1040, Dice Sup Loss: 0.48236, BCE Sup Loss: 0.62832
Epoch 34, iter 1041, Dice Sup Loss: 0.46686, BCE Sup Loss: 0.64037
Epoch 34, iter 1042, Dice Sup Loss: 0.49651, BCE Sup Loss: 0.62348
Epoch 34, iter 1043, Dice Sup Loss: 0.37512, BCE Sup Loss: 0.51898
Epoch 34, iter 1044, Dice Sup Loss: 0.42667, BCE Sup Loss: 0.56281
Epoch 34, iter 1045, Dice Sup Loss: 0.47255, BCE Sup Loss: 0.6378
Epoch 34, iter 1046, Dice Sup Loss: 0.37621, BCE Sup Loss: 0.52163
Epoch 34, iter 1047, Dice Sup Loss: 0.48205, BCE Sup Loss: 0.63043
Epoch 34, iter 1048, Dice Sup Loss: 0.39385, BCE Sup Loss: 0.51554
Epoch 34, iter 1049, Dice Sup Loss: 0.43454, BCE Sup Loss: 0.57658
Epoch 34, iter 1050, Dice Sup Loss: 0.55128, BCE Sup Loss: 0.59144
Epoch 34, Total train step 1049 || AVG_loss: 0.51885, Avg Dice score: 0.1131, Avg IOU: 0.0653
Epoch 34, Validation || sum_loss: 0.9933, Dice score: 0.1687, IOU: 0.1057
Training and evaluating on epoch34 complete in 0m 8s
Epoch 35, iter 1051, Dice Sup Loss: 0.40923, BCE Sup Loss: 0.49693
Epoch 35, iter 1052, Dice Sup Loss: 0.41588, BCE Sup Loss: 0.57884
Epoch 35, iter 1053, Dice Sup Loss: 0.46746, BCE Sup Loss: 0.64271
Epoch 35, iter 1054, Dice Sup Loss: 0.45604, BCE Sup Loss: 0.55663
Epoch 35, iter 1055, Dice Sup Loss: 0.43583, BCE Sup Loss: 0.57787
Epoch 35, iter 1056, Dice Sup Loss: 0.45995, BCE Sup Loss: 0.53833
Epoch 35, iter 1057, Dice Sup Loss: 0.44524, BCE Sup Loss: 0.56893
Epoch 35, iter 1058, Dice Sup Loss: 0.48745, BCE Sup Loss: 0.62342
Epoch 35, iter 1059, Dice Sup Loss: 0.42791, BCE Sup Loss: 0.53178
Epoch 35, iter 1060, Dice Sup Loss: 0.46284, BCE Sup Loss: 0.55253
Epoch 35, iter 1061, Dice Sup Loss: 0.51885, BCE Sup Loss: 0.59784
Epoch 35, iter 1062, Dice Sup Loss: 0.4134, BCE Sup Loss: 0.50305
Epoch 35, iter 1063, Dice Sup Loss: 0.41582, BCE Sup Loss: 0.58572
Epoch 35, iter 1064, Dice Sup Loss: 0.50992, BCE Sup Loss: 0.60544
Epoch 35, iter 1065, Dice Sup Loss: 0.47756, BCE Sup Loss: 0.52347
Epoch 35, iter 1066, Dice Sup Loss: 0.51025, BCE Sup Loss: 0.6042
Epoch 35, iter 1067, Dice Sup Loss: 0.50143, BCE Sup Loss: 0.61226
Epoch 35, iter 1068, Dice Sup Loss: 0.49492, BCE Sup Loss: 0.62021
Epoch 35, iter 1069, Dice Sup Loss: 0.48427, BCE Sup Loss: 0.62991
Epoch 35, iter 1070, Dice Sup Loss: 0.46123, BCE Sup Loss: 0.54796
Epoch 35, iter 1071, Dice Sup Loss: 0.40378, BCE Sup Loss: 0.59021
Epoch 35, iter 1072, Dice Sup Loss: 0.41523, BCE Sup Loss: 0.57608
Epoch 35, iter 1073, Dice Sup Loss: 0.45742, BCE Sup Loss: 0.65219
Epoch 35, iter 1074, Dice Sup Loss: 0.43511, BCE Sup Loss: 0.57574
Epoch 35, iter 1075, Dice Sup Loss: 0.45852, BCE Sup Loss: 0.64628
Epoch 35, iter 1076, Dice Sup Loss: 0.36833, BCE Sup Loss: 0.58369
Epoch 35, iter 1077, Dice Sup Loss: 0.43261, BCE Sup Loss: 0.57495
Epoch 35, iter 1078, Dice Sup Loss: 0.3755, BCE Sup Loss: 0.60503
Epoch 35, iter 1079, Dice Sup Loss: 0.4854, BCE Sup Loss: 0.63939
Epoch 35, iter 1080, Dice Sup Loss: 0.51573, BCE Sup Loss: 0.62807
Epoch 35, Total train step 1079 || AVG_loss: 0.51797, Avg Dice score: 0.1179, Avg IOU: 0.0661
Epoch 35, Validation || sum_loss: 1.00636, Dice score: 0.169, IOU: 0.1057
Training and evaluating on epoch35 complete in 0m 8s
Epoch 36, iter 1081, Dice Sup Loss: 0.43457, BCE Sup Loss: 0.58309
Epoch 36, iter 1082, Dice Sup Loss: 0.44814, BCE Sup Loss: 0.65335
Epoch 36, iter 1083, Dice Sup Loss: 0.51103, BCE Sup Loss: 0.62023
Epoch 36, iter 1084, Dice Sup Loss: 0.51589, BCE Sup Loss: 0.61435
Epoch 36, iter 1085, Dice Sup Loss: 0.42096, BCE Sup Loss: 0.59215
Epoch 36, iter 1086, Dice Sup Loss: 0.47855, BCE Sup Loss: 0.63141
Epoch 36, iter 1087, Dice Sup Loss: 0.4418, BCE Sup Loss: 0.56464
Epoch 36, iter 1088, Dice Sup Loss: 0.53326, BCE Sup Loss: 0.59122
Epoch 36, iter 1089, Dice Sup Loss: 0.38278, BCE Sup Loss: 0.60459
Epoch 36, iter 1090, Dice Sup Loss: 0.51009, BCE Sup Loss: 0.60454
Epoch 36, iter 1091, Dice Sup Loss: 0.43433, BCE Sup Loss: 0.55289
Epoch 36, iter 1092, Dice Sup Loss: 0.51685, BCE Sup Loss: 0.59766
Epoch 36, iter 1093, Dice Sup Loss: 0.43893, BCE Sup Loss: 0.57868
Epoch 36, iter 1094, Dice Sup Loss: 0.41979, BCE Sup Loss: 0.56127
Epoch 36, iter 1095, Dice Sup Loss: 0.47413, BCE Sup Loss: 0.646
Epoch 36, iter 1096, Dice Sup Loss: 0.40403, BCE Sup Loss: 0.49693
Epoch 36, iter 1097, Dice Sup Loss: 0.48403, BCE Sup Loss: 0.63011
Epoch 36, iter 1098, Dice Sup Loss: 0.48459, BCE Sup Loss: 0.62718
Epoch 36, iter 1099, Dice Sup Loss: 0.47394, BCE Sup Loss: 0.63583
Epoch 36, iter 1100, Dice Sup Loss: 0.44217, BCE Sup Loss: 0.56977
Epoch 36, iter 1101, Dice Sup Loss: 0.4725, BCE Sup Loss: 0.63606
Epoch 36, iter 1102, Dice Sup Loss: 0.5132, BCE Sup Loss: 0.61429
Epoch 36, iter 1103, Dice Sup Loss: 0.37006, BCE Sup Loss: 0.52665
Epoch 36, iter 1104, Dice Sup Loss: 0.41838, BCE Sup Loss: 0.57843
Epoch 36, iter 1105, Dice Sup Loss: 0.43381, BCE Sup Loss: 0.57551
Epoch 36, iter 1106, Dice Sup Loss: 0.45939, BCE Sup Loss: 0.64602
Epoch 36, iter 1107, Dice Sup Loss: 0.47336, BCE Sup Loss: 0.63864
Epoch 36, iter 1108, Dice Sup Loss: 0.32836, BCE Sup Loss: 0.44262
Epoch 36, iter 1109, Dice Sup Loss: 0.345, BCE Sup Loss: 0.50885
Epoch 36, iter 1110, Dice Sup Loss: 0.06793, BCE Sup Loss: 0.13048
Epoch 36, Total train step 1109 || AVG_loss: 0.51866, Avg Dice score: 0.1097, Avg IOU: 0.0652
Epoch 36, Validation || sum_loss: 0.9991, Dice score: 0.1656, IOU: 0.1033
Training and evaluating on epoch36 complete in 0m 8s
Epoch 37, iter 1111, Dice Sup Loss: 0.4578, BCE Sup Loss: 0.64672
Epoch 37, iter 1112, Dice Sup Loss: 0.36524, BCE Sup Loss: 0.51596
Epoch 37, iter 1113, Dice Sup Loss: 0.46442, BCE Sup Loss: 0.6416
Epoch 37, iter 1114, Dice Sup Loss: 0.5505, BCE Sup Loss: 0.59294
Epoch 37, iter 1115, Dice Sup Loss: 0.39886, BCE Sup Loss: 0.59622
Epoch 37, iter 1116, Dice Sup Loss: 0.41486, BCE Sup Loss: 0.59429
Epoch 37, iter 1117, Dice Sup Loss: 0.46514, BCE Sup Loss: 0.55221
Epoch 37, iter 1118, Dice Sup Loss: 0.47772, BCE Sup Loss: 0.63199
Epoch 37, iter 1119, Dice Sup Loss: 0.4839, BCE Sup Loss: 0.62718
Epoch 37, iter 1120, Dice Sup Loss: 0.47312, BCE Sup Loss: 0.5427
Epoch 37, iter 1121, Dice Sup Loss: 0.48198, BCE Sup Loss: 0.62852
Epoch 37, iter 1122, Dice Sup Loss: 0.46703, BCE Sup Loss: 0.54814
Epoch 37, iter 1123, Dice Sup Loss: 0.34858, BCE Sup Loss: 0.48801
Epoch 37, iter 1124, Dice Sup Loss: 0.45852, BCE Sup Loss: 0.65439
Epoch 37, iter 1125, Dice Sup Loss: 0.3575, BCE Sup Loss: 0.49866
Epoch 37, iter 1126, Dice Sup Loss: 0.40843, BCE Sup Loss: 0.52208
Epoch 37, iter 1127, Dice Sup Loss: 0.51021, BCE Sup Loss: 0.60456
Epoch 37, iter 1128, Dice Sup Loss: 0.49512, BCE Sup Loss: 0.61819
Epoch 37, iter 1129, Dice Sup Loss: 0.49169, BCE Sup Loss: 0.62104
Epoch 37, iter 1130, Dice Sup Loss: 0.38274, BCE Sup Loss: 0.52146
Epoch 37, iter 1131, Dice Sup Loss: 0.48552, BCE Sup Loss: 0.62704
Epoch 37, iter 1132, Dice Sup Loss: 0.37047, BCE Sup Loss: 0.49381
Epoch 37, iter 1133, Dice Sup Loss: 0.48952, BCE Sup Loss: 0.62286
Epoch 37, iter 1134, Dice Sup Loss: 0.47028, BCE Sup Loss: 0.6385
Epoch 37, iter 1135, Dice Sup Loss: 0.45392, BCE Sup Loss: 0.56008
Epoch 37, iter 1136, Dice Sup Loss: 0.50273, BCE Sup Loss: 0.61415
Epoch 37, iter 1137, Dice Sup Loss: 0.47772, BCE Sup Loss: 0.54373
Epoch 37, iter 1138, Dice Sup Loss: 0.4739, BCE Sup Loss: 0.63484
Epoch 37, iter 1139, Dice Sup Loss: 0.40018, BCE Sup Loss: 0.58133
Epoch 37, iter 1140, Dice Sup Loss: 0.35693, BCE Sup Loss: 0.79453
Epoch 37, Total train step 1139 || AVG_loss: 0.51819, Avg Dice score: 0.112, Avg IOU: 0.0662
Epoch 37, Validation || sum_loss: 0.99887, Dice score: 0.1673, IOU: 0.1045
Training and evaluating on epoch37 complete in 0m 8s
Epoch 38, iter 1141, Dice Sup Loss: 0.4668, BCE Sup Loss: 0.64114
Epoch 38, iter 1142, Dice Sup Loss: 0.49578, BCE Sup Loss: 0.63123
Epoch 38, iter 1143, Dice Sup Loss: 0.48031, BCE Sup Loss: 0.64261
Epoch 38, iter 1144, Dice Sup Loss: 0.44572, BCE Sup Loss: 0.65816
Epoch 38, iter 1145, Dice Sup Loss: 0.54019, BCE Sup Loss: 0.63277
Epoch 38, iter 1146, Dice Sup Loss: 0.38738, BCE Sup Loss: 0.52332
Epoch 38, iter 1147, Dice Sup Loss: 0.45022, BCE Sup Loss: 0.65629
Epoch 38, iter 1148, Dice Sup Loss: 0.43779, BCE Sup Loss: 0.66123
Epoch 38, iter 1149, Dice Sup Loss: 0.36174, BCE Sup Loss: 0.52283
Epoch 38, iter 1150, Dice Sup Loss: 0.36925, BCE Sup Loss: 0.61172
Epoch 38, iter 1151, Dice Sup Loss: 0.46457, BCE Sup Loss: 0.56664
Epoch 38, iter 1152, Dice Sup Loss: 0.34618, BCE Sup Loss: 0.60775
Epoch 38, iter 1153, Dice Sup Loss: 0.38165, BCE Sup Loss: 0.58696
Epoch 38, iter 1154, Dice Sup Loss: 0.47097, BCE Sup Loss: 0.5519
Epoch 38, iter 1155, Dice Sup Loss: 0.50277, BCE Sup Loss: 0.61814
Epoch 38, iter 1156, Dice Sup Loss: 0.44165, BCE Sup Loss: 0.56974
Epoch 38, iter 1157, Dice Sup Loss: 0.40561, BCE Sup Loss: 0.59457
Epoch 38, iter 1158, Dice Sup Loss: 0.45866, BCE Sup Loss: 0.56669
Epoch 38, iter 1159, Dice Sup Loss: 0.44598, BCE Sup Loss: 0.54499
Epoch 38, iter 1160, Dice Sup Loss: 0.46113, BCE Sup Loss: 0.65186
Epoch 38, iter 1161, Dice Sup Loss: 0.43443, BCE Sup Loss: 0.5754
Epoch 38, iter 1162, Dice Sup Loss: 0.47461, BCE Sup Loss: 0.63738
Epoch 38, iter 1163, Dice Sup Loss: 0.45399, BCE Sup Loss: 0.55734
Epoch 38, iter 1164, Dice Sup Loss: 0.41528, BCE Sup Loss: 0.5639
Epoch 38, iter 1165, Dice Sup Loss: 0.50735, BCE Sup Loss: 0.60851
Epoch 38, iter 1166, Dice Sup Loss: 0.50738, BCE Sup Loss: 0.6083
Epoch 38, iter 1167, Dice Sup Loss: 0.4426, BCE Sup Loss: 0.54566
Epoch 38, iter 1168, Dice Sup Loss: 0.41639, BCE Sup Loss: 0.48891
Epoch 38, iter 1169, Dice Sup Loss: 0.46525, BCE Sup Loss: 0.54959
Epoch 38, iter 1170, Dice Sup Loss: 0.44375, BCE Sup Loss: 0.67243
Epoch 38, Total train step 1169 || AVG_loss: 0.51926, Avg Dice score: 0.1148, Avg IOU: 0.0646
Epoch 38, Validation || sum_loss: 0.9923, Dice score: 0.1691, IOU: 0.1059
Training and evaluating on epoch38 complete in 0m 8s
Epoch 39, iter 1171, Dice Sup Loss: 0.51023, BCE Sup Loss: 0.60602
Epoch 39, iter 1172, Dice Sup Loss: 0.46434, BCE Sup Loss: 0.64544
Epoch 39, iter 1173, Dice Sup Loss: 0.44873, BCE Sup Loss: 0.55616
Epoch 39, iter 1174, Dice Sup Loss: 0.48491, BCE Sup Loss: 0.62651
Epoch 39, iter 1175, Dice Sup Loss: 0.44478, BCE Sup Loss: 0.56462
Epoch 39, iter 1176, Dice Sup Loss: 0.46189, BCE Sup Loss: 0.5557
Epoch 39, iter 1177, Dice Sup Loss: 0.50496, BCE Sup Loss: 0.61378
Epoch 39, iter 1178, Dice Sup Loss: 0.4905, BCE Sup Loss: 0.6228
Epoch 39, iter 1179, Dice Sup Loss: 0.31449, BCE Sup Loss: 0.51393
Epoch 39, iter 1180, Dice Sup Loss: 0.44315, BCE Sup Loss: 0.56662
Epoch 39, iter 1181, Dice Sup Loss: 0.50461, BCE Sup Loss: 0.6122
Epoch 39, iter 1182, Dice Sup Loss: 0.36607, BCE Sup Loss: 0.51243
Epoch 39, iter 1183, Dice Sup Loss: 0.44768, BCE Sup Loss: 0.59081
Epoch 39, iter 1184, Dice Sup Loss: 0.49645, BCE Sup Loss: 0.61714
Epoch 39, iter 1185, Dice Sup Loss: 0.39313, BCE Sup Loss: 0.5881
Epoch 39, iter 1186, Dice Sup Loss: 0.39778, BCE Sup Loss: 0.50658
Epoch 39, iter 1187, Dice Sup Loss: 0.4112, BCE Sup Loss: 0.59341
Epoch 39, iter 1188, Dice Sup Loss: 0.42381, BCE Sup Loss: 0.48661
Epoch 39, iter 1189, Dice Sup Loss: 0.43138, BCE Sup Loss: 0.6772
Epoch 39, iter 1190, Dice Sup Loss: 0.51913, BCE Sup Loss: 0.60659
Epoch 39, iter 1191, Dice Sup Loss: 0.41499, BCE Sup Loss: 0.59406
Epoch 39, iter 1192, Dice Sup Loss: 0.42111, BCE Sup Loss: 0.57674
Epoch 39, iter 1193, Dice Sup Loss: 0.5202, BCE Sup Loss: 0.61333
Epoch 39, iter 1194, Dice Sup Loss: 0.51814, BCE Sup Loss: 0.61367
Epoch 39, iter 1195, Dice Sup Loss: 0.47729, BCE Sup Loss: 0.63333
Epoch 39, iter 1196, Dice Sup Loss: 0.44746, BCE Sup Loss: 0.6551
Epoch 39, iter 1197, Dice Sup Loss: 0.39202, BCE Sup Loss: 0.57652
Epoch 39, iter 1198, Dice Sup Loss: 0.36989, BCE Sup Loss: 0.50147
Epoch 39, iter 1199, Dice Sup Loss: 0.47558, BCE Sup Loss: 0.63312
Epoch 39, iter 1200, Dice Sup Loss: 0.55139, BCE Sup Loss: 0.58968
Epoch 39, Total train step 1199 || AVG_loss: 0.51843, Avg Dice score: 0.1107, Avg IOU: 0.0641
Epoch 39, Validation || sum_loss: 0.99292, Dice score: 0.1688, IOU: 0.1058
Training and evaluating on epoch39 complete in 0m 8s
Epoch 40, iter 1201, Dice Sup Loss: 0.46307, BCE Sup Loss: 0.64375
Epoch 40, iter 1202, Dice Sup Loss: 0.52417, BCE Sup Loss: 0.59902
Epoch 40, iter 1203, Dice Sup Loss: 0.49079, BCE Sup Loss: 0.62135
Epoch 40, iter 1204, Dice Sup Loss: 0.44842, BCE Sup Loss: 0.55595
Epoch 40, iter 1205, Dice Sup Loss: 0.37266, BCE Sup Loss: 0.58049
Epoch 40, iter 1206, Dice Sup Loss: 0.50251, BCE Sup Loss: 0.61121
Epoch 40, iter 1207, Dice Sup Loss: 0.36021, BCE Sup Loss: 0.52044
Epoch 40, iter 1208, Dice Sup Loss: 0.424, BCE Sup Loss: 0.4938
Epoch 40, iter 1209, Dice Sup Loss: 0.45818, BCE Sup Loss: 0.66351
Epoch 40, iter 1210, Dice Sup Loss: 0.49965, BCE Sup Loss: 0.61397
Epoch 40, iter 1211, Dice Sup Loss: 0.41882, BCE Sup Loss: 0.58977
Epoch 40, iter 1212, Dice Sup Loss: 0.50059, BCE Sup Loss: 0.61338
Epoch 40, iter 1213, Dice Sup Loss: 0.37137, BCE Sup Loss: 0.50938
Epoch 40, iter 1214, Dice Sup Loss: 0.39897, BCE Sup Loss: 0.58063
Epoch 40, iter 1215, Dice Sup Loss: 0.48941, BCE Sup Loss: 0.62537
Epoch 40, iter 1216, Dice Sup Loss: 0.42735, BCE Sup Loss: 0.56356
Epoch 40, iter 1217, Dice Sup Loss: 0.45448, BCE Sup Loss: 0.55304
Epoch 40, iter 1218, Dice Sup Loss: 0.50372, BCE Sup Loss: 0.61865
Epoch 40, iter 1219, Dice Sup Loss: 0.44028, BCE Sup Loss: 0.56842
Epoch 40, iter 1220, Dice Sup Loss: 0.37705, BCE Sup Loss: 0.53309
Epoch 40, iter 1221, Dice Sup Loss: 0.43683, BCE Sup Loss: 0.56843
Epoch 40, iter 1222, Dice Sup Loss: 0.41961, BCE Sup Loss: 0.55284
Epoch 40, iter 1223, Dice Sup Loss: 0.45587, BCE Sup Loss: 0.55936
Epoch 40, iter 1224, Dice Sup Loss: 0.50516, BCE Sup Loss: 0.61139
Epoch 40, iter 1225, Dice Sup Loss: 0.48225, BCE Sup Loss: 0.6284
Epoch 40, iter 1226, Dice Sup Loss: 0.40095, BCE Sup Loss: 0.4855
Epoch 40, iter 1227, Dice Sup Loss: 0.45529, BCE Sup Loss: 0.65899
Epoch 40, iter 1228, Dice Sup Loss: 0.51982, BCE Sup Loss: 0.59808
Epoch 40, iter 1229, Dice Sup Loss: 0.46444, BCE Sup Loss: 0.64667
Epoch 40, iter 1230, Dice Sup Loss: 0.4624, BCE Sup Loss: 0.65113
Epoch 40, Total train step 1229 || AVG_loss: 0.518, Avg Dice score: 0.1147, Avg IOU: 0.0655
Epoch 40, Validation || sum_loss: 0.99367, Dice score: 0.1681, IOU: 0.1052
Training and evaluating on epoch40 complete in 0m 8s
Epoch 41, iter 1231, Dice Sup Loss: 0.40891, BCE Sup Loss: 0.57316
Epoch 41, iter 1232, Dice Sup Loss: 0.46903, BCE Sup Loss: 0.54612
Epoch 41, iter 1233, Dice Sup Loss: 0.46576, BCE Sup Loss: 0.64209
Epoch 41, iter 1234, Dice Sup Loss: 0.44252, BCE Sup Loss: 0.57021
Epoch 41, iter 1235, Dice Sup Loss: 0.48894, BCE Sup Loss: 0.53477
Epoch 41, iter 1236, Dice Sup Loss: 0.42986, BCE Sup Loss: 0.67376
Epoch 41, iter 1237, Dice Sup Loss: 0.40683, BCE Sup Loss: 0.59995
Epoch 41, iter 1238, Dice Sup Loss: 0.4533, BCE Sup Loss: 0.56346
Epoch 41, iter 1239, Dice Sup Loss: 0.48637, BCE Sup Loss: 0.6306
Epoch 41, iter 1240, Dice Sup Loss: 0.51925, BCE Sup Loss: 0.61665
Epoch 41, iter 1241, Dice Sup Loss: 0.31308, BCE Sup Loss: 0.44007
Epoch 41, iter 1242, Dice Sup Loss: 0.41695, BCE Sup Loss: 0.57461
Epoch 41, iter 1243, Dice Sup Loss: 0.46763, BCE Sup Loss: 0.64177
Epoch 41, iter 1244, Dice Sup Loss: 0.45048, BCE Sup Loss: 0.55562
Epoch 41, iter 1245, Dice Sup Loss: 0.49698, BCE Sup Loss: 0.61995
Epoch 41, iter 1246, Dice Sup Loss: 0.39135, BCE Sup Loss: 0.49433
Epoch 41, iter 1247, Dice Sup Loss: 0.47006, BCE Sup Loss: 0.63838
Epoch 41, iter 1248, Dice Sup Loss: 0.40324, BCE Sup Loss: 0.57755
Epoch 41, iter 1249, Dice Sup Loss: 0.4987, BCE Sup Loss: 0.6146
Epoch 41, iter 1250, Dice Sup Loss: 0.44358, BCE Sup Loss: 0.55767
Epoch 41, iter 1251, Dice Sup Loss: 0.51897, BCE Sup Loss: 0.59731
Epoch 41, iter 1252, Dice Sup Loss: 0.44609, BCE Sup Loss: 0.54567
Epoch 41, iter 1253, Dice Sup Loss: 0.39142, BCE Sup Loss: 0.59779
Epoch 41, iter 1254, Dice Sup Loss: 0.36131, BCE Sup Loss: 0.50544
Epoch 41, iter 1255, Dice Sup Loss: 0.43201, BCE Sup Loss: 0.58986
Epoch 41, iter 1256, Dice Sup Loss: 0.5095, BCE Sup Loss: 0.60448
Epoch 41, iter 1257, Dice Sup Loss: 0.48777, BCE Sup Loss: 0.62621
Epoch 41, iter 1258, Dice Sup Loss: 0.50411, BCE Sup Loss: 0.6105
Epoch 41, iter 1259, Dice Sup Loss: 0.47718, BCE Sup Loss: 0.63657
Epoch 41, iter 1260, Dice Sup Loss: 0.39894, BCE Sup Loss: 0.74645
Epoch 41, Total train step 1259 || AVG_loss: 0.518, Avg Dice score: 0.1159, Avg IOU: 0.0674
Epoch 41, Validation || sum_loss: 0.99403, Dice score: 0.1687, IOU: 0.1056
Training and evaluating on epoch41 complete in 0m 7s
Epoch 42, iter 1261, Dice Sup Loss: 0.42377, BCE Sup Loss: 0.58051
Epoch 42, iter 1262, Dice Sup Loss: 0.4986, BCE Sup Loss: 0.62249
Epoch 42, iter 1263, Dice Sup Loss: 0.34577, BCE Sup Loss: 0.52262
Epoch 42, iter 1264, Dice Sup Loss: 0.42345, BCE Sup Loss: 0.57702
Epoch 42, iter 1265, Dice Sup Loss: 0.48813, BCE Sup Loss: 0.63847
Epoch 42, iter 1266, Dice Sup Loss: 0.39171, BCE Sup Loss: 0.59428
Epoch 42, iter 1267, Dice Sup Loss: 0.48191, BCE Sup Loss: 0.64123
Epoch 42, iter 1268, Dice Sup Loss: 0.42386, BCE Sup Loss: 0.58125
Epoch 42, iter 1269, Dice Sup Loss: 0.40694, BCE Sup Loss: 0.59241
Epoch 42, iter 1270, Dice Sup Loss: 0.4352, BCE Sup Loss: 0.66109
Epoch 42, iter 1271, Dice Sup Loss: 0.52501, BCE Sup Loss: 0.62119
Epoch 42, iter 1272, Dice Sup Loss: 0.44285, BCE Sup Loss: 0.57101
Epoch 42, iter 1273, Dice Sup Loss: 0.43497, BCE Sup Loss: 0.57451
Epoch 42, iter 1274, Dice Sup Loss: 0.39484, BCE Sup Loss: 0.58631
Epoch 42, iter 1275, Dice Sup Loss: 0.33332, BCE Sup Loss: 0.52429
Epoch 42, iter 1276, Dice Sup Loss: 0.49755, BCE Sup Loss: 0.62085
Epoch 42, iter 1277, Dice Sup Loss: 0.42193, BCE Sup Loss: 0.57773
Epoch 42, iter 1278, Dice Sup Loss: 0.49763, BCE Sup Loss: 0.61791
Epoch 42, iter 1279, Dice Sup Loss: 0.46487, BCE Sup Loss: 0.6431
Epoch 42, iter 1280, Dice Sup Loss: 0.47666, BCE Sup Loss: 0.63278
Epoch 42, iter 1281, Dice Sup Loss: 0.49288, BCE Sup Loss: 0.61971
Epoch 42, iter 1282, Dice Sup Loss: 0.43835, BCE Sup Loss: 0.56731
Epoch 42, iter 1283, Dice Sup Loss: 0.41578, BCE Sup Loss: 0.56283
Epoch 42, iter 1284, Dice Sup Loss: 0.42378, BCE Sup Loss: 0.50052
Epoch 42, iter 1285, Dice Sup Loss: 0.44979, BCE Sup Loss: 0.56232
Epoch 42, iter 1286, Dice Sup Loss: 0.48229, BCE Sup Loss: 0.62929
Epoch 42, iter 1287, Dice Sup Loss: 0.47959, BCE Sup Loss: 0.53779
Epoch 42, iter 1288, Dice Sup Loss: 0.47323, BCE Sup Loss: 0.6381
Epoch 42, iter 1289, Dice Sup Loss: 0.44517, BCE Sup Loss: 0.54078
Epoch 42, iter 1290, Dice Sup Loss: 0.40507, BCE Sup Loss: 0.73997
Epoch 42, Total train step 1289 || AVG_loss: 0.51833, Avg Dice score: 0.1142, Avg IOU: 0.065
Epoch 42, Validation || sum_loss: 0.99382, Dice score: 0.167, IOU: 0.1044
Training and evaluating on epoch42 complete in 0m 8s
Epoch 43, iter 1291, Dice Sup Loss: 0.49161, BCE Sup Loss: 0.62089
Epoch 43, iter 1292, Dice Sup Loss: 0.51957, BCE Sup Loss: 0.60367
Epoch 43, iter 1293, Dice Sup Loss: 0.49292, BCE Sup Loss: 0.62114
Epoch 43, iter 1294, Dice Sup Loss: 0.4846, BCE Sup Loss: 0.62749
Epoch 43, iter 1295, Dice Sup Loss: 0.43237, BCE Sup Loss: 0.56855
Epoch 43, iter 1296, Dice Sup Loss: 0.5304, BCE Sup Loss: 0.60512
Epoch 43, iter 1297, Dice Sup Loss: 0.42708, BCE Sup Loss: 0.57363
Epoch 43, iter 1298, Dice Sup Loss: 0.38375, BCE Sup Loss: 0.49704
Epoch 43, iter 1299, Dice Sup Loss: 0.36002, BCE Sup Loss: 0.52036
Epoch 43, iter 1300, Dice Sup Loss: 0.42644, BCE Sup Loss: 0.5005
Epoch 43, iter 1301, Dice Sup Loss: 0.49124, BCE Sup Loss: 0.62177
Epoch 43, iter 1302, Dice Sup Loss: 0.44705, BCE Sup Loss: 0.54125
Epoch 43, iter 1303, Dice Sup Loss: 0.50267, BCE Sup Loss: 0.61195
Epoch 43, iter 1304, Dice Sup Loss: 0.44487, BCE Sup Loss: 0.67134
Epoch 43, iter 1305, Dice Sup Loss: 0.39129, BCE Sup Loss: 0.60125
Epoch 43, iter 1306, Dice Sup Loss: 0.41993, BCE Sup Loss: 0.54044
Epoch 43, iter 1307, Dice Sup Loss: 0.41166, BCE Sup Loss: 0.60421
Epoch 43, iter 1308, Dice Sup Loss: 0.41916, BCE Sup Loss: 0.56926
Epoch 43, iter 1309, Dice Sup Loss: 0.4879, BCE Sup Loss: 0.62373
Epoch 43, iter 1310, Dice Sup Loss: 0.45665, BCE Sup Loss: 0.55079
Epoch 43, iter 1311, Dice Sup Loss: 0.37927, BCE Sup Loss: 0.56411
Epoch 43, iter 1312, Dice Sup Loss: 0.44553, BCE Sup Loss: 0.56384
Epoch 43, iter 1313, Dice Sup Loss: 0.39623, BCE Sup Loss: 0.4928
Epoch 43, iter 1314, Dice Sup Loss: 0.42934, BCE Sup Loss: 0.5802
Epoch 43, iter 1315, Dice Sup Loss: 0.45256, BCE Sup Loss: 0.55825
Epoch 43, iter 1316, Dice Sup Loss: 0.49008, BCE Sup Loss: 0.62215
Epoch 43, iter 1317, Dice Sup Loss: 0.45665, BCE Sup Loss: 0.64992
Epoch 43, iter 1318, Dice Sup Loss: 0.46371, BCE Sup Loss: 0.64374
Epoch 43, iter 1319, Dice Sup Loss: 0.44838, BCE Sup Loss: 0.65757
Epoch 43, iter 1320, Dice Sup Loss: 0.52684, BCE Sup Loss: 0.60338
Epoch 43, Total train step 1319 || AVG_loss: 0.51727, Avg Dice score: 0.1186, Avg IOU: 0.0681
Epoch 43, Validation || sum_loss: 0.99451, Dice score: 0.1688, IOU: 0.1057
Training and evaluating on epoch43 complete in 0m 7s
Epoch 44, iter 1321, Dice Sup Loss: 0.46026, BCE Sup Loss: 0.64529
Epoch 44, iter 1322, Dice Sup Loss: 0.52054, BCE Sup Loss: 0.60816
Epoch 44, iter 1323, Dice Sup Loss: 0.42185, BCE Sup Loss: 0.57785
Epoch 44, iter 1324, Dice Sup Loss: 0.36877, BCE Sup Loss: 0.51867
Epoch 44, iter 1325, Dice Sup Loss: 0.37405, BCE Sup Loss: 0.59835
Epoch 44, iter 1326, Dice Sup Loss: 0.47541, BCE Sup Loss: 0.63476
Epoch 44, iter 1327, Dice Sup Loss: 0.46635, BCE Sup Loss: 0.55473
Epoch 44, iter 1328, Dice Sup Loss: 0.44594, BCE Sup Loss: 0.65475
Epoch 44, iter 1329, Dice Sup Loss: 0.44762, BCE Sup Loss: 0.65383
Epoch 44, iter 1330, Dice Sup Loss: 0.49661, BCE Sup Loss: 0.62572
Epoch 44, iter 1331, Dice Sup Loss: 0.40523, BCE Sup Loss: 0.57718
Epoch 44, iter 1332, Dice Sup Loss: 0.46611, BCE Sup Loss: 0.64185
Epoch 44, iter 1333, Dice Sup Loss: 0.33801, BCE Sup Loss: 0.51312
Epoch 44, iter 1334, Dice Sup Loss: 0.46434, BCE Sup Loss: 0.64289
Epoch 44, iter 1335, Dice Sup Loss: 0.46173, BCE Sup Loss: 0.55314
Epoch 44, iter 1336, Dice Sup Loss: 0.36531, BCE Sup Loss: 0.50891
Epoch 44, iter 1337, Dice Sup Loss: 0.40994, BCE Sup Loss: 0.59295
Epoch 44, iter 1338, Dice Sup Loss: 0.51482, BCE Sup Loss: 0.60613
Epoch 44, iter 1339, Dice Sup Loss: 0.48548, BCE Sup Loss: 0.62601
Epoch 44, iter 1340, Dice Sup Loss: 0.39604, BCE Sup Loss: 0.49475
Epoch 44, iter 1341, Dice Sup Loss: 0.46845, BCE Sup Loss: 0.54207
Epoch 44, iter 1342, Dice Sup Loss: 0.46726, BCE Sup Loss: 0.64835
Epoch 44, iter 1343, Dice Sup Loss: 0.42553, BCE Sup Loss: 0.56557
Epoch 44, iter 1344, Dice Sup Loss: 0.48983, BCE Sup Loss: 0.52489
Epoch 44, iter 1345, Dice Sup Loss: 0.48264, BCE Sup Loss: 0.63268
Epoch 44, iter 1346, Dice Sup Loss: 0.45143, BCE Sup Loss: 0.56271
Epoch 44, iter 1347, Dice Sup Loss: 0.48866, BCE Sup Loss: 0.62548
Epoch 44, iter 1348, Dice Sup Loss: 0.52548, BCE Sup Loss: 0.5919
Epoch 44, iter 1349, Dice Sup Loss: 0.40045, BCE Sup Loss: 0.49369
Epoch 44, iter 1350, Dice Sup Loss: 0.46029, BCE Sup Loss: 0.65487
Epoch 44, Total train step 1349 || AVG_loss: 0.51742, Avg Dice score: 0.115, Avg IOU: 0.0669
Epoch 44, Validation || sum_loss: 0.99356, Dice score: 0.1656, IOU: 0.1034
Training and evaluating on epoch44 complete in 0m 8s
Epoch 45, iter 1351, Dice Sup Loss: 0.41912, BCE Sup Loss: 0.56115
Epoch 45, iter 1352, Dice Sup Loss: 0.34611, BCE Sup Loss: 0.5052
Epoch 45, iter 1353, Dice Sup Loss: 0.47385, BCE Sup Loss: 0.63572
Epoch 45, iter 1354, Dice Sup Loss: 0.47889, BCE Sup Loss: 0.63055
Epoch 45, iter 1355, Dice Sup Loss: 0.50518, BCE Sup Loss: 0.61247
Epoch 45, iter 1356, Dice Sup Loss: 0.4118, BCE Sup Loss: 0.59342
Epoch 45, iter 1357, Dice Sup Loss: 0.49836, BCE Sup Loss: 0.53826
Epoch 45, iter 1358, Dice Sup Loss: 0.44008, BCE Sup Loss: 0.56875
Epoch 45, iter 1359, Dice Sup Loss: 0.46407, BCE Sup Loss: 0.64213
Epoch 45, iter 1360, Dice Sup Loss: 0.472, BCE Sup Loss: 0.63714
Epoch 45, iter 1361, Dice Sup Loss: 0.39799, BCE Sup Loss: 0.50122
Epoch 45, iter 1362, Dice Sup Loss: 0.50285, BCE Sup Loss: 0.61783
Epoch 45, iter 1363, Dice Sup Loss: 0.41775, BCE Sup Loss: 0.50669
Epoch 45, iter 1364, Dice Sup Loss: 0.43663, BCE Sup Loss: 0.57474
Epoch 45, iter 1365, Dice Sup Loss: 0.42079, BCE Sup Loss: 0.57776
Epoch 45, iter 1366, Dice Sup Loss: 0.32648, BCE Sup Loss: 0.43706
Epoch 45, iter 1367, Dice Sup Loss: 0.46276, BCE Sup Loss: 0.64304
Epoch 45, iter 1368, Dice Sup Loss: 0.49448, BCE Sup Loss: 0.62044
Epoch 45, iter 1369, Dice Sup Loss: 0.50315, BCE Sup Loss: 0.61539
Epoch 45, iter 1370, Dice Sup Loss: 0.44344, BCE Sup Loss: 0.56196
Epoch 45, iter 1371, Dice Sup Loss: 0.47896, BCE Sup Loss: 0.63094
Epoch 45, iter 1372, Dice Sup Loss: 0.42714, BCE Sup Loss: 0.5623
Epoch 45, iter 1373, Dice Sup Loss: 0.51779, BCE Sup Loss: 0.60151
Epoch 45, iter 1374, Dice Sup Loss: 0.45551, BCE Sup Loss: 0.65601
Epoch 45, iter 1375, Dice Sup Loss: 0.38704, BCE Sup Loss: 0.60373
Epoch 45, iter 1376, Dice Sup Loss: 0.49346, BCE Sup Loss: 0.61853
Epoch 45, iter 1377, Dice Sup Loss: 0.53627, BCE Sup Loss: 0.59073
Epoch 45, iter 1378, Dice Sup Loss: 0.38115, BCE Sup Loss: 0.55803
Epoch 45, iter 1379, Dice Sup Loss: 0.44637, BCE Sup Loss: 0.65993
Epoch 45, iter 1380, Dice Sup Loss: 0.09505, BCE Sup Loss: 0.19297
Epoch 45, Total train step 1379 || AVG_loss: 0.51739, Avg Dice score: 0.1117, Avg IOU: 0.0668
Epoch 45, Validation || sum_loss: 0.99645, Dice score: 0.1632, IOU: 0.1017
Training and evaluating on epoch45 complete in 0m 8s
Epoch 46, iter 1381, Dice Sup Loss: 0.44493, BCE Sup Loss: 0.66406
Epoch 46, iter 1382, Dice Sup Loss: 0.4685, BCE Sup Loss: 0.63883
Epoch 46, iter 1383, Dice Sup Loss: 0.43833, BCE Sup Loss: 0.55167
Epoch 46, iter 1384, Dice Sup Loss: 0.46896, BCE Sup Loss: 0.55897
Epoch 46, iter 1385, Dice Sup Loss: 0.42384, BCE Sup Loss: 0.51612
Epoch 46, iter 1386, Dice Sup Loss: 0.36489, BCE Sup Loss: 0.59365
Epoch 46, iter 1387, Dice Sup Loss: 0.46922, BCE Sup Loss: 0.55483
Epoch 46, iter 1388, Dice Sup Loss: 0.41269, BCE Sup Loss: 0.55993
Epoch 46, iter 1389, Dice Sup Loss: 0.47054, BCE Sup Loss: 0.55665
Epoch 46, iter 1390, Dice Sup Loss: 0.41773, BCE Sup Loss: 0.58628
Epoch 46, iter 1391, Dice Sup Loss: 0.43155, BCE Sup Loss: 0.58855
Epoch 46, iter 1392, Dice Sup Loss: 0.46021, BCE Sup Loss: 0.56214
Epoch 46, iter 1393, Dice Sup Loss: 0.424, BCE Sup Loss: 0.58216
Epoch 46, iter 1394, Dice Sup Loss: 0.35744, BCE Sup Loss: 0.44226
Epoch 46, iter 1395, Dice Sup Loss: 0.47054, BCE Sup Loss: 0.63816
Epoch 46, iter 1396, Dice Sup Loss: 0.4661, BCE Sup Loss: 0.56427
Epoch 46, iter 1397, Dice Sup Loss: 0.49067, BCE Sup Loss: 0.62167
Epoch 46, iter 1398, Dice Sup Loss: 0.47985, BCE Sup Loss: 0.63014
Epoch 46, iter 1399, Dice Sup Loss: 0.43586, BCE Sup Loss: 0.56444
Epoch 46, iter 1400, Dice Sup Loss: 0.46578, BCE Sup Loss: 0.64251
Epoch 46, iter 1401, Dice Sup Loss: 0.46047, BCE Sup Loss: 0.64638
Epoch 46, iter 1402, Dice Sup Loss: 0.46608, BCE Sup Loss: 0.53866
Epoch 46, iter 1403, Dice Sup Loss: 0.53288, BCE Sup Loss: 0.59706
Epoch 46, iter 1404, Dice Sup Loss: 0.46176, BCE Sup Loss: 0.64554
Epoch 46, iter 1405, Dice Sup Loss: 0.39258, BCE Sup Loss: 0.60939
Epoch 46, iter 1406, Dice Sup Loss: 0.47046, BCE Sup Loss: 0.63851
Epoch 46, iter 1407, Dice Sup Loss: 0.49428, BCE Sup Loss: 0.61847
Epoch 46, iter 1408, Dice Sup Loss: 0.45252, BCE Sup Loss: 0.56571
Epoch 46, iter 1409, Dice Sup Loss: 0.49138, BCE Sup Loss: 0.62148
Epoch 46, iter 1410, Dice Sup Loss: 0.45999, BCE Sup Loss: 0.64686
Epoch 46, Total train step 1409 || AVG_loss: 0.52053, Avg Dice score: 0.1138, Avg IOU: 0.0645
Epoch 46, Validation || sum_loss: 0.99905, Dice score: 0.1638, IOU: 0.102
Training and evaluating on epoch46 complete in 0m 7s
Epoch 47, iter 1411, Dice Sup Loss: 0.42199, BCE Sup Loss: 0.58172
Epoch 47, iter 1412, Dice Sup Loss: 0.49866, BCE Sup Loss: 0.61858
Epoch 47, iter 1413, Dice Sup Loss: 0.42105, BCE Sup Loss: 0.58261
Epoch 47, iter 1414, Dice Sup Loss: 0.43825, BCE Sup Loss: 0.57769
Epoch 47, iter 1415, Dice Sup Loss: 0.38102, BCE Sup Loss: 0.57818
Epoch 47, iter 1416, Dice Sup Loss: 0.43649, BCE Sup Loss: 0.66249
Epoch 47, iter 1417, Dice Sup Loss: 0.47387, BCE Sup Loss: 0.63675
Epoch 47, iter 1418, Dice Sup Loss: 0.49781, BCE Sup Loss: 0.62502
Epoch 47, iter 1419, Dice Sup Loss: 0.51888, BCE Sup Loss: 0.61709
Epoch 47, iter 1420, Dice Sup Loss: 0.43242, BCE Sup Loss: 0.56023
Epoch 47, iter 1421, Dice Sup Loss: 0.47018, BCE Sup Loss: 0.56723
Epoch 47, iter 1422, Dice Sup Loss: 0.3638, BCE Sup Loss: 0.51034
Epoch 47, iter 1423, Dice Sup Loss: 0.45499, BCE Sup Loss: 0.56004
Epoch 47, iter 1424, Dice Sup Loss: 0.44138, BCE Sup Loss: 0.56779
Epoch 47, iter 1425, Dice Sup Loss: 0.49704, BCE Sup Loss: 0.61583
Epoch 47, iter 1426, Dice Sup Loss: 0.4429, BCE Sup Loss: 0.57688
Epoch 47, iter 1427, Dice Sup Loss: 0.37503, BCE Sup Loss: 0.49868
Epoch 47, iter 1428, Dice Sup Loss: 0.49891, BCE Sup Loss: 0.61503
Epoch 47, iter 1429, Dice Sup Loss: 0.4917, BCE Sup Loss: 0.62284
Epoch 47, iter 1430, Dice Sup Loss: 0.46843, BCE Sup Loss: 0.64978
Epoch 47, iter 1431, Dice Sup Loss: 0.49968, BCE Sup Loss: 0.61327
Epoch 47, iter 1432, Dice Sup Loss: 0.42156, BCE Sup Loss: 0.57323
Epoch 47, iter 1433, Dice Sup Loss: 0.48206, BCE Sup Loss: 0.62915
Epoch 47, iter 1434, Dice Sup Loss: 0.45325, BCE Sup Loss: 0.55912
Epoch 47, iter 1435, Dice Sup Loss: 0.44349, BCE Sup Loss: 0.5649
Epoch 47, iter 1436, Dice Sup Loss: 0.33589, BCE Sup Loss: 0.54391
Epoch 47, iter 1437, Dice Sup Loss: 0.4793, BCE Sup Loss: 0.54669
Epoch 47, iter 1438, Dice Sup Loss: 0.48458, BCE Sup Loss: 0.62858
Epoch 47, iter 1439, Dice Sup Loss: 0.42186, BCE Sup Loss: 0.58156
Epoch 47, iter 1440, Dice Sup Loss: 0.5121, BCE Sup Loss: 0.61375
Epoch 47, Total train step 1439 || AVG_loss: 0.51935, Avg Dice score: 0.1111, Avg IOU: 0.0634
Epoch 47, Validation || sum_loss: 0.99912, Dice score: 0.1676, IOU: 0.1047
Training and evaluating on epoch47 complete in 0m 8s
Epoch 48, iter 1441, Dice Sup Loss: 0.50743, BCE Sup Loss: 0.61632
Epoch 48, iter 1442, Dice Sup Loss: 0.5016, BCE Sup Loss: 0.61744
Epoch 48, iter 1443, Dice Sup Loss: 0.46498, BCE Sup Loss: 0.64242
Epoch 48, iter 1444, Dice Sup Loss: 0.44603, BCE Sup Loss: 0.57041
Epoch 48, iter 1445, Dice Sup Loss: 0.47036, BCE Sup Loss: 0.6381
Epoch 48, iter 1446, Dice Sup Loss: 0.49411, BCE Sup Loss: 0.6194
Epoch 48, iter 1447, Dice Sup Loss: 0.37855, BCE Sup Loss: 0.50853
Epoch 48, iter 1448, Dice Sup Loss: 0.50624, BCE Sup Loss: 0.61085
Epoch 48, iter 1449, Dice Sup Loss: 0.31293, BCE Sup Loss: 0.44088
Epoch 48, iter 1450, Dice Sup Loss: 0.46266, BCE Sup Loss: 0.54197
Epoch 48, iter 1451, Dice Sup Loss: 0.46831, BCE Sup Loss: 0.64404
Epoch 48, iter 1452, Dice Sup Loss: 0.45825, BCE Sup Loss: 0.55284
Epoch 48, iter 1453, Dice Sup Loss: 0.47557, BCE Sup Loss: 0.63778
Epoch 48, iter 1454, Dice Sup Loss: 0.46914, BCE Sup Loss: 0.64489
Epoch 48, iter 1455, Dice Sup Loss: 0.49182, BCE Sup Loss: 0.62013
Epoch 48, iter 1456, Dice Sup Loss: 0.44983, BCE Sup Loss: 0.66296
Epoch 48, iter 1457, Dice Sup Loss: 0.43847, BCE Sup Loss: 0.5744
Epoch 48, iter 1458, Dice Sup Loss: 0.51312, BCE Sup Loss: 0.6083
Epoch 48, iter 1459, Dice Sup Loss: 0.44139, BCE Sup Loss: 0.55865
Epoch 48, iter 1460, Dice Sup Loss: 0.46414, BCE Sup Loss: 0.64254
Epoch 48, iter 1461, Dice Sup Loss: 0.47598, BCE Sup Loss: 0.6344
Epoch 48, iter 1462, Dice Sup Loss: 0.42439, BCE Sup Loss: 0.50354
Epoch 48, iter 1463, Dice Sup Loss: 0.39861, BCE Sup Loss: 0.5824
Epoch 48, iter 1464, Dice Sup Loss: 0.34402, BCE Sup Loss: 0.50491
Epoch 48, iter 1465, Dice Sup Loss: 0.47886, BCE Sup Loss: 0.63266
Epoch 48, iter 1466, Dice Sup Loss: 0.33629, BCE Sup Loss: 0.43245
Epoch 48, iter 1467, Dice Sup Loss: 0.44716, BCE Sup Loss: 0.65604
Epoch 48, iter 1468, Dice Sup Loss: 0.3675, BCE Sup Loss: 0.50657
Epoch 48, iter 1469, Dice Sup Loss: 0.46982, BCE Sup Loss: 0.6381
Epoch 48, iter 1470, Dice Sup Loss: 0.56239, BCE Sup Loss: 0.58341
Epoch 48, Total train step 1469 || AVG_loss: 0.51751, Avg Dice score: 0.1135, Avg IOU: 0.0692
Epoch 48, Validation || sum_loss: 0.9955, Dice score: 0.1668, IOU: 0.1041
Training and evaluating on epoch48 complete in 0m 7s
Epoch 49, iter 1471, Dice Sup Loss: 0.40364, BCE Sup Loss: 0.50682
Epoch 49, iter 1472, Dice Sup Loss: 0.44489, BCE Sup Loss: 0.66599
Epoch 49, iter 1473, Dice Sup Loss: 0.45928, BCE Sup Loss: 0.64973
Epoch 49, iter 1474, Dice Sup Loss: 0.37961, BCE Sup Loss: 0.47562
Epoch 49, iter 1475, Dice Sup Loss: 0.43644, BCE Sup Loss: 0.67442
Epoch 49, iter 1476, Dice Sup Loss: 0.53666, BCE Sup Loss: 0.59241
Epoch 49, iter 1477, Dice Sup Loss: 0.4059, BCE Sup Loss: 0.56897
Epoch 49, iter 1478, Dice Sup Loss: 0.42187, BCE Sup Loss: 0.56423
Epoch 49, iter 1479, Dice Sup Loss: 0.44047, BCE Sup Loss: 0.57795
Epoch 49, iter 1480, Dice Sup Loss: 0.51781, BCE Sup Loss: 0.6021
Epoch 49, iter 1481, Dice Sup Loss: 0.52362, BCE Sup Loss: 0.59746
Epoch 49, iter 1482, Dice Sup Loss: 0.42813, BCE Sup Loss: 0.56957
Epoch 49, iter 1483, Dice Sup Loss: 0.48701, BCE Sup Loss: 0.52693
Epoch 49, iter 1484, Dice Sup Loss: 0.47276, BCE Sup Loss: 0.6414
Epoch 49, iter 1485, Dice Sup Loss: 0.40842, BCE Sup Loss: 0.56249
Epoch 49, iter 1486, Dice Sup Loss: 0.45335, BCE Sup Loss: 0.55756
Epoch 49, iter 1487, Dice Sup Loss: 0.48646, BCE Sup Loss: 0.62852
Epoch 49, iter 1488, Dice Sup Loss: 0.48707, BCE Sup Loss: 0.62717
Epoch 49, iter 1489, Dice Sup Loss: 0.4091, BCE Sup Loss: 0.48153
Epoch 49, iter 1490, Dice Sup Loss: 0.43361, BCE Sup Loss: 0.53768
Epoch 49, iter 1491, Dice Sup Loss: 0.45015, BCE Sup Loss: 0.58781
Epoch 49, iter 1492, Dice Sup Loss: 0.48412, BCE Sup Loss: 0.62786
Epoch 49, iter 1493, Dice Sup Loss: 0.48504, BCE Sup Loss: 0.6273
Epoch 49, iter 1494, Dice Sup Loss: 0.44639, BCE Sup Loss: 0.56546
Epoch 49, iter 1495, Dice Sup Loss: 0.4604, BCE Sup Loss: 0.64847
Epoch 49, iter 1496, Dice Sup Loss: 0.4736, BCE Sup Loss: 0.63683
Epoch 49, iter 1497, Dice Sup Loss: 0.46741, BCE Sup Loss: 0.64
Epoch 49, iter 1498, Dice Sup Loss: 0.26001, BCE Sup Loss: 0.38596
Epoch 49, iter 1499, Dice Sup Loss: 0.50837, BCE Sup Loss: 0.6201
Epoch 49, iter 1500, Dice Sup Loss: 0.44802, BCE Sup Loss: 0.65277
Epoch 49, Total train step 1499 || AVG_loss: 0.51773, Avg Dice score: 0.1174, Avg IOU: 0.0701
Epoch 49, Validation || sum_loss: 0.99896, Dice score: 0.1676, IOU: 0.1048
Training and evaluating on epoch49 complete in 0m 7s
Epoch 50, iter 1501, Dice Sup Loss: 0.36679, BCE Sup Loss: 0.5264
Epoch 50, iter 1502, Dice Sup Loss: 0.40314, BCE Sup Loss: 0.57034
Epoch 50, iter 1503, Dice Sup Loss: 0.46719, BCE Sup Loss: 0.64082
Epoch 50, iter 1504, Dice Sup Loss: 0.4504, BCE Sup Loss: 0.65083
Epoch 50, iter 1505, Dice Sup Loss: 0.38837, BCE Sup Loss: 0.58888
Epoch 50, iter 1506, Dice Sup Loss: 0.44661, BCE Sup Loss: 0.57842
Epoch 50, iter 1507, Dice Sup Loss: 0.41685, BCE Sup Loss: 0.58444
Epoch 50, iter 1508, Dice Sup Loss: 0.46767, BCE Sup Loss: 0.64083
Epoch 50, iter 1509, Dice Sup Loss: 0.37857, BCE Sup Loss: 0.5994
Epoch 50, iter 1510, Dice Sup Loss: 0.4897, BCE Sup Loss: 0.62744
Epoch 50, iter 1511, Dice Sup Loss: 0.40968, BCE Sup Loss: 0.49465
Epoch 50, iter 1512, Dice Sup Loss: 0.33712, BCE Sup Loss: 0.51246
Epoch 50, iter 1513, Dice Sup Loss: 0.50366, BCE Sup Loss: 0.61953
Epoch 50, iter 1514, Dice Sup Loss: 0.41189, BCE Sup Loss: 0.57848
Epoch 50, iter 1515, Dice Sup Loss: 0.46558, BCE Sup Loss: 0.64093
Epoch 50, iter 1516, Dice Sup Loss: 0.50809, BCE Sup Loss: 0.61395
Epoch 50, iter 1517, Dice Sup Loss: 0.45988, BCE Sup Loss: 0.55392
Epoch 50, iter 1518, Dice Sup Loss: 0.4832, BCE Sup Loss: 0.62705
Epoch 50, iter 1519, Dice Sup Loss: 0.42252, BCE Sup Loss: 0.56467
Epoch 50, iter 1520, Dice Sup Loss: 0.39509, BCE Sup Loss: 0.51532
Epoch 50, iter 1521, Dice Sup Loss: 0.47265, BCE Sup Loss: 0.63638
Epoch 50, iter 1522, Dice Sup Loss: 0.48409, BCE Sup Loss: 0.62658
Epoch 50, iter 1523, Dice Sup Loss: 0.42937, BCE Sup Loss: 0.54469
Epoch 50, iter 1524, Dice Sup Loss: 0.54825, BCE Sup Loss: 0.58368
Epoch 50, iter 1525, Dice Sup Loss: 0.46644, BCE Sup Loss: 0.64595
Epoch 50, iter 1526, Dice Sup Loss: 0.41088, BCE Sup Loss: 0.49119
Epoch 50, iter 1527, Dice Sup Loss: 0.5127, BCE Sup Loss: 0.6046
Epoch 50, iter 1528, Dice Sup Loss: 0.44433, BCE Sup Loss: 0.55543
Epoch 50, iter 1529, Dice Sup Loss: 0.47456, BCE Sup Loss: 0.6384
Epoch 50, iter 1530, Dice Sup Loss: 0.45589, BCE Sup Loss: 0.66125
Epoch 50, Total train step 1529 || AVG_loss: 0.51692, Avg Dice score: 0.1148, Avg IOU: 0.0657
Epoch 50, Validation || sum_loss: 0.99364, Dice score: 0.1674, IOU: 0.1046
Training and evaluating on epoch50 complete in 0m 8s
Epoch 51, iter 1531, Dice Sup Loss: 0.48977, BCE Sup Loss: 0.62285
Epoch 51, iter 1532, Dice Sup Loss: 0.46823, BCE Sup Loss: 0.64369
Epoch 51, iter 1533, Dice Sup Loss: 0.51244, BCE Sup Loss: 0.6034
Epoch 51, iter 1534, Dice Sup Loss: 0.47749, BCE Sup Loss: 0.63249
Epoch 51, iter 1535, Dice Sup Loss: 0.49673, BCE Sup Loss: 0.61749
Epoch 51, iter 1536, Dice Sup Loss: 0.46553, BCE Sup Loss: 0.642
Epoch 51, iter 1537, Dice Sup Loss: 0.48058, BCE Sup Loss: 0.62938
Epoch 51, iter 1538, Dice Sup Loss: 0.46554, BCE Sup Loss: 0.64069
Epoch 51, iter 1539, Dice Sup Loss: 0.50294, BCE Sup Loss: 0.61537
Epoch 51, iter 1540, Dice Sup Loss: 0.36258, BCE Sup Loss: 0.52088
Epoch 51, iter 1541, Dice Sup Loss: 0.45891, BCE Sup Loss: 0.55978
Epoch 51, iter 1542, Dice Sup Loss: 0.47608, BCE Sup Loss: 0.63365
Epoch 51, iter 1543, Dice Sup Loss: 0.36737, BCE Sup Loss: 0.58169
Epoch 51, iter 1544, Dice Sup Loss: 0.47084, BCE Sup Loss: 0.63756
Epoch 51, iter 1545, Dice Sup Loss: 0.45944, BCE Sup Loss: 0.64548
Epoch 51, iter 1546, Dice Sup Loss: 0.4153, BCE Sup Loss: 0.58735
Epoch 51, iter 1547, Dice Sup Loss: 0.34089, BCE Sup Loss: 0.52595
Epoch 51, iter 1548, Dice Sup Loss: 0.50197, BCE Sup Loss: 0.62106
Epoch 51, iter 1549, Dice Sup Loss: 0.43211, BCE Sup Loss: 0.57275
Epoch 51, iter 1550, Dice Sup Loss: 0.48192, BCE Sup Loss: 0.63196
Epoch 51, iter 1551, Dice Sup Loss: 0.4198, BCE Sup Loss: 0.58223
Epoch 51, iter 1552, Dice Sup Loss: 0.3685, BCE Sup Loss: 0.51554
Epoch 51, iter 1553, Dice Sup Loss: 0.33884, BCE Sup Loss: 0.52897
Epoch 51, iter 1554, Dice Sup Loss: 0.45197, BCE Sup Loss: 0.57465
Epoch 51, iter 1555, Dice Sup Loss: 0.39867, BCE Sup Loss: 0.5038
Epoch 51, iter 1556, Dice Sup Loss: 0.39165, BCE Sup Loss: 0.51489
Epoch 51, iter 1557, Dice Sup Loss: 0.50423, BCE Sup Loss: 0.52435
Epoch 51, iter 1558, Dice Sup Loss: 0.47511, BCE Sup Loss: 0.63498
Epoch 51, iter 1559, Dice Sup Loss: 0.43214, BCE Sup Loss: 0.54631
Epoch 51, iter 1560, Dice Sup Loss: 0.66418, BCE Sup Loss: 0.54014
Epoch 51, Total train step 1559 || AVG_loss: 0.51758, Avg Dice score: 0.1129, Avg IOU: 0.0657
Epoch 51, Validation || sum_loss: 0.9941, Dice score: 0.1654, IOU: 0.1032
Training and evaluating on epoch51 complete in 0m 8s
Epoch 52, iter 1561, Dice Sup Loss: 0.46248, BCE Sup Loss: 0.64991
Epoch 52, iter 1562, Dice Sup Loss: 0.46902, BCE Sup Loss: 0.64534
Epoch 52, iter 1563, Dice Sup Loss: 0.37511, BCE Sup Loss: 0.46917
Epoch 52, iter 1564, Dice Sup Loss: 0.49332, BCE Sup Loss: 0.6218
Epoch 52, iter 1565, Dice Sup Loss: 0.45371, BCE Sup Loss: 0.55401
Epoch 52, iter 1566, Dice Sup Loss: 0.49117, BCE Sup Loss: 0.62698
Epoch 52, iter 1567, Dice Sup Loss: 0.482, BCE Sup Loss: 0.52494
Epoch 52, iter 1568, Dice Sup Loss: 0.48436, BCE Sup Loss: 0.63775
Epoch 52, iter 1569, Dice Sup Loss: 0.55293, BCE Sup Loss: 0.56702
Epoch 52, iter 1570, Dice Sup Loss: 0.36138, BCE Sup Loss: 0.51245
Epoch 52, iter 1571, Dice Sup Loss: 0.45319, BCE Sup Loss: 0.68753
Epoch 52, iter 1572, Dice Sup Loss: 0.51574, BCE Sup Loss: 0.59888
Epoch 52, iter 1573, Dice Sup Loss: 0.39197, BCE Sup Loss: 0.4943
Epoch 52, iter 1574, Dice Sup Loss: 0.46047, BCE Sup Loss: 0.56743
Epoch 52, iter 1575, Dice Sup Loss: 0.52227, BCE Sup Loss: 0.59465
Epoch 52, iter 1576, Dice Sup Loss: 0.5024, BCE Sup Loss: 0.61074
Epoch 52, iter 1577, Dice Sup Loss: 0.49092, BCE Sup Loss: 0.62107
Epoch 52, iter 1578, Dice Sup Loss: 0.46053, BCE Sup Loss: 0.55073
Epoch 52, iter 1579, Dice Sup Loss: 0.35738, BCE Sup Loss: 0.49753
Epoch 52, iter 1580, Dice Sup Loss: 0.45593, BCE Sup Loss: 0.55783
Epoch 52, iter 1581, Dice Sup Loss: 0.44137, BCE Sup Loss: 0.56851
Epoch 52, iter 1582, Dice Sup Loss: 0.46966, BCE Sup Loss: 0.54648
Epoch 52, iter 1583, Dice Sup Loss: 0.37532, BCE Sup Loss: 0.56617
Epoch 52, iter 1584, Dice Sup Loss: 0.44488, BCE Sup Loss: 0.5686
Epoch 52, iter 1585, Dice Sup Loss: 0.42769, BCE Sup Loss: 0.57268
Epoch 52, iter 1586, Dice Sup Loss: 0.39713, BCE Sup Loss: 0.58393
Epoch 52, iter 1587, Dice Sup Loss: 0.49006, BCE Sup Loss: 0.62169
Epoch 52, iter 1588, Dice Sup Loss: 0.40586, BCE Sup Loss: 0.60287
Epoch 52, iter 1589, Dice Sup Loss: 0.50457, BCE Sup Loss: 0.6125
Epoch 52, iter 1590, Dice Sup Loss: 0.52904, BCE Sup Loss: 0.59874
Epoch 52, Total train step 1589 || AVG_loss: 0.51789, Avg Dice score: 0.1153, Avg IOU: 0.0673
Epoch 52, Validation || sum_loss: 0.99598, Dice score: 0.1659, IOU: 0.1034
Training and evaluating on epoch52 complete in 0m 8s
Epoch 53, iter 1591, Dice Sup Loss: 0.49028, BCE Sup Loss: 0.62244
Epoch 53, iter 1592, Dice Sup Loss: 0.43451, BCE Sup Loss: 0.58687
Epoch 53, iter 1593, Dice Sup Loss: 0.51779, BCE Sup Loss: 0.60703
Epoch 53, iter 1594, Dice Sup Loss: 0.46178, BCE Sup Loss: 0.55045
Epoch 53, iter 1595, Dice Sup Loss: 0.45739, BCE Sup Loss: 0.64888
Epoch 53, iter 1596, Dice Sup Loss: 0.49514, BCE Sup Loss: 0.61979
Epoch 53, iter 1597, Dice Sup Loss: 0.42896, BCE Sup Loss: 0.55157
Epoch 53, iter 1598, Dice Sup Loss: 0.41486, BCE Sup Loss: 0.56648
Epoch 53, iter 1599, Dice Sup Loss: 0.3984, BCE Sup Loss: 0.50459
Epoch 53, iter 1600, Dice Sup Loss: 0.4851, BCE Sup Loss: 0.62479
Epoch 53, iter 1601, Dice Sup Loss: 0.42298, BCE Sup Loss: 0.4792
Epoch 53, iter 1602, Dice Sup Loss: 0.46386, BCE Sup Loss: 0.64455
Epoch 53, iter 1603, Dice Sup Loss: 0.51279, BCE Sup Loss: 0.60492
Epoch 53, iter 1604, Dice Sup Loss: 0.45216, BCE Sup Loss: 0.65763
Epoch 53, iter 1605, Dice Sup Loss: 0.42419, BCE Sup Loss: 0.56796
Epoch 53, iter 1606, Dice Sup Loss: 0.43507, BCE Sup Loss: 0.55017
Epoch 53, iter 1607, Dice Sup Loss: 0.29471, BCE Sup Loss: 0.45274
Epoch 53, iter 1608, Dice Sup Loss: 0.48691, BCE Sup Loss: 0.62439
Epoch 53, iter 1609, Dice Sup Loss: 0.51356, BCE Sup Loss: 0.60418
Epoch 53, iter 1610, Dice Sup Loss: 0.43201, BCE Sup Loss: 0.68541
Epoch 53, iter 1611, Dice Sup Loss: 0.45954, BCE Sup Loss: 0.64904
Epoch 53, iter 1612, Dice Sup Loss: 0.51485, BCE Sup Loss: 0.60442
Epoch 53, iter 1613, Dice Sup Loss: 0.4282, BCE Sup Loss: 0.56316
Epoch 53, iter 1614, Dice Sup Loss: 0.48154, BCE Sup Loss: 0.62772
Epoch 53, iter 1615, Dice Sup Loss: 0.38274, BCE Sup Loss: 0.52251
Epoch 53, iter 1616, Dice Sup Loss: 0.51727, BCE Sup Loss: 0.6063
Epoch 53, iter 1617, Dice Sup Loss: 0.43917, BCE Sup Loss: 0.56838
Epoch 53, iter 1618, Dice Sup Loss: 0.48072, BCE Sup Loss: 0.62913
Epoch 53, iter 1619, Dice Sup Loss: 0.29487, BCE Sup Loss: 0.46065
Epoch 53, iter 1620, Dice Sup Loss: 0.4922, BCE Sup Loss: 0.62358
Epoch 53, Total train step 1619 || AVG_loss: 0.51753, Avg Dice score: 0.1108, Avg IOU: 0.0657
Epoch 53, Validation || sum_loss: 0.99404, Dice score: 0.1686, IOU: 0.1055
Training and evaluating on epoch53 complete in 0m 8s
Epoch 54, iter 1621, Dice Sup Loss: 0.49096, BCE Sup Loss: 0.62295
Epoch 54, iter 1622, Dice Sup Loss: 0.37927, BCE Sup Loss: 0.51326
Epoch 54, iter 1623, Dice Sup Loss: 0.50665, BCE Sup Loss: 0.61387
Epoch 54, iter 1624, Dice Sup Loss: 0.26155, BCE Sup Loss: 0.38268
Epoch 54, iter 1625, Dice Sup Loss: 0.46681, BCE Sup Loss: 0.56185
Epoch 54, iter 1626, Dice Sup Loss: 0.44954, BCE Sup Loss: 0.56007
Epoch 54, iter 1627, Dice Sup Loss: 0.44725, BCE Sup Loss: 0.65608
Epoch 54, iter 1628, Dice Sup Loss: 0.41442, BCE Sup Loss: 0.57912
Epoch 54, iter 1629, Dice Sup Loss: 0.50458, BCE Sup Loss: 0.61346
Epoch 54, iter 1630, Dice Sup Loss: 0.41343, BCE Sup Loss: 0.55994
Epoch 54, iter 1631, Dice Sup Loss: 0.4809, BCE Sup Loss: 0.62843
Epoch 54, iter 1632, Dice Sup Loss: 0.49402, BCE Sup Loss: 0.61868
Epoch 54, iter 1633, Dice Sup Loss: 0.51762, BCE Sup Loss: 0.60259
Epoch 54, iter 1634, Dice Sup Loss: 0.40729, BCE Sup Loss: 0.58526
Epoch 54, iter 1635, Dice Sup Loss: 0.34297, BCE Sup Loss: 0.48906
Epoch 54, iter 1636, Dice Sup Loss: 0.49853, BCE Sup Loss: 0.61426
Epoch 54, iter 1637, Dice Sup Loss: 0.46875, BCE Sup Loss: 0.64312
Epoch 54, iter 1638, Dice Sup Loss: 0.46931, BCE Sup Loss: 0.63678
Epoch 54, iter 1639, Dice Sup Loss: 0.45693, BCE Sup Loss: 0.65598
Epoch 54, iter 1640, Dice Sup Loss: 0.51543, BCE Sup Loss: 0.60212
Epoch 54, iter 1641, Dice Sup Loss: 0.47935, BCE Sup Loss: 0.62993
Epoch 54, iter 1642, Dice Sup Loss: 0.39843, BCE Sup Loss: 0.50678
Epoch 54, iter 1643, Dice Sup Loss: 0.34396, BCE Sup Loss: 0.42229
Epoch 54, iter 1644, Dice Sup Loss: 0.40169, BCE Sup Loss: 0.57831
Epoch 54, iter 1645, Dice Sup Loss: 0.42574, BCE Sup Loss: 0.58773
Epoch 54, iter 1646, Dice Sup Loss: 0.53043, BCE Sup Loss: 0.59669
Epoch 54, iter 1647, Dice Sup Loss: 0.45202, BCE Sup Loss: 0.65293
Epoch 54, iter 1648, Dice Sup Loss: 0.46336, BCE Sup Loss: 0.64236
Epoch 54, iter 1649, Dice Sup Loss: 0.49076, BCE Sup Loss: 0.62495
Epoch 54, iter 1650, Dice Sup Loss: 0.60479, BCE Sup Loss: 0.57209
Epoch 54, Total train step 1649 || AVG_loss: 0.51675, Avg Dice score: 0.1095, Avg IOU: 0.0667
Epoch 54, Validation || sum_loss: 0.99327, Dice score: 0.169, IOU: 0.1058
Training and evaluating on epoch54 complete in 0m 7s
Epoch 55, iter 1651, Dice Sup Loss: 0.44721, BCE Sup Loss: 0.55555
Epoch 55, iter 1652, Dice Sup Loss: 0.41313, BCE Sup Loss: 0.55171
Epoch 55, iter 1653, Dice Sup Loss: 0.42507, BCE Sup Loss: 0.5785
Epoch 55, iter 1654, Dice Sup Loss: 0.45116, BCE Sup Loss: 0.65713
Epoch 55, iter 1655, Dice Sup Loss: 0.4116, BCE Sup Loss: 0.48504
Epoch 55, iter 1656, Dice Sup Loss: 0.52733, BCE Sup Loss: 0.59465
Epoch 55, iter 1657, Dice Sup Loss: 0.44175, BCE Sup Loss: 0.6723
Epoch 55, iter 1658, Dice Sup Loss: 0.44047, BCE Sup Loss: 0.54244
Epoch 55, iter 1659, Dice Sup Loss: 0.33905, BCE Sup Loss: 0.50444
Epoch 55, iter 1660, Dice Sup Loss: 0.50594, BCE Sup Loss: 0.60806
Epoch 55, iter 1661, Dice Sup Loss: 0.4753, BCE Sup Loss: 0.63639
Epoch 55, iter 1662, Dice Sup Loss: 0.43578, BCE Sup Loss: 0.57894
Epoch 55, iter 1663, Dice Sup Loss: 0.43261, BCE Sup Loss: 0.55562
Epoch 55, iter 1664, Dice Sup Loss: 0.3734, BCE Sup Loss: 0.57035
Epoch 55, iter 1665, Dice Sup Loss: 0.43155, BCE Sup Loss: 0.58329
Epoch 55, iter 1666, Dice Sup Loss: 0.51306, BCE Sup Loss: 0.60245
Epoch 55, iter 1667, Dice Sup Loss: 0.45549, BCE Sup Loss: 0.56393
Epoch 55, iter 1668, Dice Sup Loss: 0.45781, BCE Sup Loss: 0.54376
Epoch 55, iter 1669, Dice Sup Loss: 0.50788, BCE Sup Loss: 0.60751
Epoch 55, iter 1670, Dice Sup Loss: 0.50008, BCE Sup Loss: 0.61295
Epoch 55, iter 1671, Dice Sup Loss: 0.50437, BCE Sup Loss: 0.52161
Epoch 55, iter 1672, Dice Sup Loss: 0.45173, BCE Sup Loss: 0.55939
Epoch 55, iter 1673, Dice Sup Loss: 0.4846, BCE Sup Loss: 0.62637
Epoch 55, iter 1674, Dice Sup Loss: 0.48369, BCE Sup Loss: 0.62662
Epoch 55, iter 1675, Dice Sup Loss: 0.43758, BCE Sup Loss: 0.56921
Epoch 55, iter 1676, Dice Sup Loss: 0.46253, BCE Sup Loss: 0.64789
Epoch 55, iter 1677, Dice Sup Loss: 0.45998, BCE Sup Loss: 0.64988
Epoch 55, iter 1678, Dice Sup Loss: 0.46039, BCE Sup Loss: 0.64665
Epoch 55, iter 1679, Dice Sup Loss: 0.31778, BCE Sup Loss: 0.4399
Epoch 55, iter 1680, Dice Sup Loss: 0.51828, BCE Sup Loss: 0.60724
Epoch 55, Total train step 1679 || AVG_loss: 0.51642, Avg Dice score: 0.1176, Avg IOU: 0.0686
Epoch 55, Validation || sum_loss: 0.99388, Dice score: 0.169, IOU: 0.1058
Training and evaluating on epoch55 complete in 0m 7s
Epoch 56, iter 1681, Dice Sup Loss: 0.53056, BCE Sup Loss: 0.6022
Epoch 56, iter 1682, Dice Sup Loss: 0.40274, BCE Sup Loss: 0.57706
Epoch 56, iter 1683, Dice Sup Loss: 0.39547, BCE Sup Loss: 0.57381
Epoch 56, iter 1684, Dice Sup Loss: 0.49274, BCE Sup Loss: 0.62121
Epoch 56, iter 1685, Dice Sup Loss: 0.36315, BCE Sup Loss: 0.583
Epoch 56, iter 1686, Dice Sup Loss: 0.47989, BCE Sup Loss: 0.62998
Epoch 56, iter 1687, Dice Sup Loss: 0.45491, BCE Sup Loss: 0.65038
Epoch 56, iter 1688, Dice Sup Loss: 0.42836, BCE Sup Loss: 0.5768
Epoch 56, iter 1689, Dice Sup Loss: 0.42063, BCE Sup Loss: 0.58556
Epoch 56, iter 1690, Dice Sup Loss: 0.48161, BCE Sup Loss: 0.6293
Epoch 56, iter 1691, Dice Sup Loss: 0.43427, BCE Sup Loss: 0.55642
Epoch 56, iter 1692, Dice Sup Loss: 0.44343, BCE Sup Loss: 0.55891
Epoch 56, iter 1693, Dice Sup Loss: 0.32983, BCE Sup Loss: 0.45533
Epoch 56, iter 1694, Dice Sup Loss: 0.50885, BCE Sup Loss: 0.61545
Epoch 56, iter 1695, Dice Sup Loss: 0.45172, BCE Sup Loss: 0.65108
Epoch 56, iter 1696, Dice Sup Loss: 0.46452, BCE Sup Loss: 0.64106
Epoch 56, iter 1697, Dice Sup Loss: 0.48545, BCE Sup Loss: 0.62851
Epoch 56, iter 1698, Dice Sup Loss: 0.32393, BCE Sup Loss: 0.43995
Epoch 56, iter 1699, Dice Sup Loss: 0.49262, BCE Sup Loss: 0.62292
Epoch 56, iter 1700, Dice Sup Loss: 0.4918, BCE Sup Loss: 0.6214
Epoch 56, iter 1701, Dice Sup Loss: 0.48047, BCE Sup Loss: 0.62848
Epoch 56, iter 1702, Dice Sup Loss: 0.40337, BCE Sup Loss: 0.49233
Epoch 56, iter 1703, Dice Sup Loss: 0.50012, BCE Sup Loss: 0.61305
Epoch 56, iter 1704, Dice Sup Loss: 0.45733, BCE Sup Loss: 0.65226
Epoch 56, iter 1705, Dice Sup Loss: 0.47257, BCE Sup Loss: 0.63436
Epoch 56, iter 1706, Dice Sup Loss: 0.41671, BCE Sup Loss: 0.49687
Epoch 56, iter 1707, Dice Sup Loss: 0.44529, BCE Sup Loss: 0.56587
Epoch 56, iter 1708, Dice Sup Loss: 0.4318, BCE Sup Loss: 0.56638
Epoch 56, iter 1709, Dice Sup Loss: 0.41719, BCE Sup Loss: 0.55964
Epoch 56, iter 1710, Dice Sup Loss: 0.55283, BCE Sup Loss: 0.58358
Epoch 56, Total train step 1709 || AVG_loss: 0.51627, Avg Dice score: 0.1146, Avg IOU: 0.0674
Epoch 56, Validation || sum_loss: 0.99389, Dice score: 0.1647, IOU: 0.1027
Training and evaluating on epoch56 complete in 0m 8s
Epoch 57, iter 1711, Dice Sup Loss: 0.50932, BCE Sup Loss: 0.60657
Epoch 57, iter 1712, Dice Sup Loss: 0.49524, BCE Sup Loss: 0.61644
Epoch 57, iter 1713, Dice Sup Loss: 0.41823, BCE Sup Loss: 0.59863
Epoch 57, iter 1714, Dice Sup Loss: 0.42119, BCE Sup Loss: 0.55587
Epoch 57, iter 1715, Dice Sup Loss: 0.47057, BCE Sup Loss: 0.63902
Epoch 57, iter 1716, Dice Sup Loss: 0.38071, BCE Sup Loss: 0.60561
Epoch 57, iter 1717, Dice Sup Loss: 0.43656, BCE Sup Loss: 0.57332
Epoch 57, iter 1718, Dice Sup Loss: 0.38321, BCE Sup Loss: 0.50246
Epoch 57, iter 1719, Dice Sup Loss: 0.48541, BCE Sup Loss: 0.62451
Epoch 57, iter 1720, Dice Sup Loss: 0.43937, BCE Sup Loss: 0.56535
Epoch 57, iter 1721, Dice Sup Loss: 0.48568, BCE Sup Loss: 0.62553
Epoch 57, iter 1722, Dice Sup Loss: 0.41522, BCE Sup Loss: 0.58305
Epoch 57, iter 1723, Dice Sup Loss: 0.4192, BCE Sup Loss: 0.57189
Epoch 57, iter 1724, Dice Sup Loss: 0.48709, BCE Sup Loss: 0.62542
Epoch 57, iter 1725, Dice Sup Loss: 0.46142, BCE Sup Loss: 0.64202
Epoch 57, iter 1726, Dice Sup Loss: 0.35817, BCE Sup Loss: 0.51982
Epoch 57, iter 1727, Dice Sup Loss: 0.51172, BCE Sup Loss: 0.60875
Epoch 57, iter 1728, Dice Sup Loss: 0.52763, BCE Sup Loss: 0.60012
Epoch 57, iter 1729, Dice Sup Loss: 0.4451, BCE Sup Loss: 0.54251
Epoch 57, iter 1730, Dice Sup Loss: 0.42703, BCE Sup Loss: 0.57343
Epoch 57, iter 1731, Dice Sup Loss: 0.50592, BCE Sup Loss: 0.60799
Epoch 57, iter 1732, Dice Sup Loss: 0.50035, BCE Sup Loss: 0.61374
Epoch 57, iter 1733, Dice Sup Loss: 0.41504, BCE Sup Loss: 0.54288
Epoch 57, iter 1734, Dice Sup Loss: 0.43393, BCE Sup Loss: 0.58439
Epoch 57, iter 1735, Dice Sup Loss: 0.44891, BCE Sup Loss: 0.57745
Epoch 57, iter 1736, Dice Sup Loss: 0.30931, BCE Sup Loss: 0.43453
Epoch 57, iter 1737, Dice Sup Loss: 0.50175, BCE Sup Loss: 0.61212
Epoch 57, iter 1738, Dice Sup Loss: 0.44544, BCE Sup Loss: 0.56098
Epoch 57, iter 1739, Dice Sup Loss: 0.48263, BCE Sup Loss: 0.6302
Epoch 57, iter 1740, Dice Sup Loss: 0.46171, BCE Sup Loss: 0.65098
Epoch 57, Total train step 1739 || AVG_loss: 0.51682, Avg Dice score: 0.1126, Avg IOU: 0.0649
Epoch 57, Validation || sum_loss: 0.99046, Dice score: 0.1693, IOU: 0.1061
Training and evaluating on epoch57 complete in 0m 8s
Epoch 58, iter 1741, Dice Sup Loss: 0.42811, BCE Sup Loss: 0.57703
Epoch 58, iter 1742, Dice Sup Loss: 0.44626, BCE Sup Loss: 0.56535
Epoch 58, iter 1743, Dice Sup Loss: 0.42447, BCE Sup Loss: 0.55161
Epoch 58, iter 1744, Dice Sup Loss: 0.42157, BCE Sup Loss: 0.56399
Epoch 58, iter 1745, Dice Sup Loss: 0.35325, BCE Sup Loss: 0.50468
Epoch 58, iter 1746, Dice Sup Loss: 0.46757, BCE Sup Loss: 0.63731
Epoch 58, iter 1747, Dice Sup Loss: 0.4282, BCE Sup Loss: 0.58054
Epoch 58, iter 1748, Dice Sup Loss: 0.46032, BCE Sup Loss: 0.64425
Epoch 58, iter 1749, Dice Sup Loss: 0.28776, BCE Sup Loss: 0.44591
Epoch 58, iter 1750, Dice Sup Loss: 0.42782, BCE Sup Loss: 0.66868
Epoch 58, iter 1751, Dice Sup Loss: 0.46384, BCE Sup Loss: 0.55752
Epoch 58, iter 1752, Dice Sup Loss: 0.47475, BCE Sup Loss: 0.63776
Epoch 58, iter 1753, Dice Sup Loss: 0.44674, BCE Sup Loss: 0.65359
Epoch 58, iter 1754, Dice Sup Loss: 0.51059, BCE Sup Loss: 0.62059
Epoch 58, iter 1755, Dice Sup Loss: 0.38361, BCE Sup Loss: 0.51696
Epoch 58, iter 1756, Dice Sup Loss: 0.45858, BCE Sup Loss: 0.56086
Epoch 58, iter 1757, Dice Sup Loss: 0.52298, BCE Sup Loss: 0.60955
Epoch 58, iter 1758, Dice Sup Loss: 0.42991, BCE Sup Loss: 0.58067
Epoch 58, iter 1759, Dice Sup Loss: 0.28581, BCE Sup Loss: 0.46824
Epoch 58, iter 1760, Dice Sup Loss: 0.49367, BCE Sup Loss: 0.53909
Epoch 58, iter 1761, Dice Sup Loss: 0.47736, BCE Sup Loss: 0.63184
Epoch 58, iter 1762, Dice Sup Loss: 0.48953, BCE Sup Loss: 0.62166
Epoch 58, iter 1763, Dice Sup Loss: 0.48136, BCE Sup Loss: 0.62909
Epoch 58, iter 1764, Dice Sup Loss: 0.48972, BCE Sup Loss: 0.62118
Epoch 58, iter 1765, Dice Sup Loss: 0.48166, BCE Sup Loss: 0.62654
Epoch 58, iter 1766, Dice Sup Loss: 0.45492, BCE Sup Loss: 0.66072
Epoch 58, iter 1767, Dice Sup Loss: 0.43722, BCE Sup Loss: 0.55685
Epoch 58, iter 1768, Dice Sup Loss: 0.48455, BCE Sup Loss: 0.62497
Epoch 58, iter 1769, Dice Sup Loss: 0.54284, BCE Sup Loss: 0.58168
Epoch 58, iter 1770, Dice Sup Loss: 0.53022, BCE Sup Loss: 0.58575
Epoch 58, Total train step 1769 || AVG_loss: 0.51731, Avg Dice score: 0.1095, Avg IOU: 0.065
Epoch 58, Validation || sum_loss: 0.99103, Dice score: 0.1666, IOU: 0.1041
Training and evaluating on epoch58 complete in 0m 8s
Epoch 59, iter 1771, Dice Sup Loss: 0.36746, BCE Sup Loss: 0.4959
Epoch 59, iter 1772, Dice Sup Loss: 0.47506, BCE Sup Loss: 0.53943
Epoch 59, iter 1773, Dice Sup Loss: 0.41882, BCE Sup Loss: 0.56347
Epoch 59, iter 1774, Dice Sup Loss: 0.36922, BCE Sup Loss: 0.58422
Epoch 59, iter 1775, Dice Sup Loss: 0.50319, BCE Sup Loss: 0.6108
Epoch 59, iter 1776, Dice Sup Loss: 0.46593, BCE Sup Loss: 0.53687
Epoch 59, iter 1777, Dice Sup Loss: 0.48772, BCE Sup Loss: 0.62304
Epoch 59, iter 1778, Dice Sup Loss: 0.48244, BCE Sup Loss: 0.63155
Epoch 59, iter 1779, Dice Sup Loss: 0.49955, BCE Sup Loss: 0.60971
Epoch 59, iter 1780, Dice Sup Loss: 0.4902, BCE Sup Loss: 0.6208
Epoch 59, iter 1781, Dice Sup Loss: 0.49502, BCE Sup Loss: 0.62032
Epoch 59, iter 1782, Dice Sup Loss: 0.4174, BCE Sup Loss: 0.59022
Epoch 59, iter 1783, Dice Sup Loss: 0.47959, BCE Sup Loss: 0.63012
Epoch 59, iter 1784, Dice Sup Loss: 0.43436, BCE Sup Loss: 0.57501
Epoch 59, iter 1785, Dice Sup Loss: 0.46169, BCE Sup Loss: 0.64277
Epoch 59, iter 1786, Dice Sup Loss: 0.43027, BCE Sup Loss: 0.55645
Epoch 59, iter 1787, Dice Sup Loss: 0.42477, BCE Sup Loss: 0.57418
Epoch 59, iter 1788, Dice Sup Loss: 0.34353, BCE Sup Loss: 0.54861
Epoch 59, iter 1789, Dice Sup Loss: 0.35147, BCE Sup Loss: 0.44179
Epoch 59, iter 1790, Dice Sup Loss: 0.51061, BCE Sup Loss: 0.61654
Epoch 59, iter 1791, Dice Sup Loss: 0.42278, BCE Sup Loss: 0.55974
Epoch 59, iter 1792, Dice Sup Loss: 0.43215, BCE Sup Loss: 0.57346
Epoch 59, iter 1793, Dice Sup Loss: 0.48367, BCE Sup Loss: 0.62881
Epoch 59, iter 1794, Dice Sup Loss: 0.49176, BCE Sup Loss: 0.6258
Epoch 59, iter 1795, Dice Sup Loss: 0.47765, BCE Sup Loss: 0.63083
Epoch 59, iter 1796, Dice Sup Loss: 0.49759, BCE Sup Loss: 0.61892
Epoch 59, iter 1797, Dice Sup Loss: 0.40627, BCE Sup Loss: 0.58219
Epoch 59, iter 1798, Dice Sup Loss: 0.42108, BCE Sup Loss: 0.58012
Epoch 59, iter 1799, Dice Sup Loss: 0.43362, BCE Sup Loss: 0.55925
Epoch 59, iter 1800, Dice Sup Loss: 0.50918, BCE Sup Loss: 0.60529
Epoch 59, Total train step 1799 || AVG_loss: 0.51648, Avg Dice score: 0.1138, Avg IOU: 0.0647
Epoch 59, Validation || sum_loss: 0.9946, Dice score: 0.1643, IOU: 0.1023
Training and evaluating on epoch59 complete in 0m 8s
Epoch 60, iter 1801, Dice Sup Loss: 0.47606, BCE Sup Loss: 0.63044
Epoch 60, iter 1802, Dice Sup Loss: 0.38535, BCE Sup Loss: 0.49744
Epoch 60, iter 1803, Dice Sup Loss: 0.3955, BCE Sup Loss: 0.49537
Epoch 60, iter 1804, Dice Sup Loss: 0.45633, BCE Sup Loss: 0.54959
Epoch 60, iter 1805, Dice Sup Loss: 0.49608, BCE Sup Loss: 0.60978
Epoch 60, iter 1806, Dice Sup Loss: 0.47938, BCE Sup Loss: 0.62793
Epoch 60, iter 1807, Dice Sup Loss: 0.43794, BCE Sup Loss: 0.56326
Epoch 60, iter 1808, Dice Sup Loss: 0.46948, BCE Sup Loss: 0.63836
Epoch 60, iter 1809, Dice Sup Loss: 0.4348, BCE Sup Loss: 0.56578
Epoch 60, iter 1810, Dice Sup Loss: 0.35194, BCE Sup Loss: 0.52049
Epoch 60, iter 1811, Dice Sup Loss: 0.50079, BCE Sup Loss: 0.6106
Epoch 60, iter 1812, Dice Sup Loss: 0.40112, BCE Sup Loss: 0.59291
Epoch 60, iter 1813, Dice Sup Loss: 0.43524, BCE Sup Loss: 0.58384
Epoch 60, iter 1814, Dice Sup Loss: 0.44539, BCE Sup Loss: 0.56327
Epoch 60, iter 1815, Dice Sup Loss: 0.47467, BCE Sup Loss: 0.63472
Epoch 60, iter 1816, Dice Sup Loss: 0.39394, BCE Sup Loss: 0.58781
Epoch 60, iter 1817, Dice Sup Loss: 0.3836, BCE Sup Loss: 0.55758
Epoch 60, iter 1818, Dice Sup Loss: 0.47408, BCE Sup Loss: 0.63475
Epoch 60, iter 1819, Dice Sup Loss: 0.3749, BCE Sup Loss: 0.58746
Epoch 60, iter 1820, Dice Sup Loss: 0.47962, BCE Sup Loss: 0.63034
Epoch 60, iter 1821, Dice Sup Loss: 0.47445, BCE Sup Loss: 0.6347
Epoch 60, iter 1822, Dice Sup Loss: 0.44874, BCE Sup Loss: 0.56382
Epoch 60, iter 1823, Dice Sup Loss: 0.41906, BCE Sup Loss: 0.48602
Epoch 60, iter 1824, Dice Sup Loss: 0.52452, BCE Sup Loss: 0.60335
Epoch 60, iter 1825, Dice Sup Loss: 0.50648, BCE Sup Loss: 0.61098
Epoch 60, iter 1826, Dice Sup Loss: 0.48303, BCE Sup Loss: 0.62533
Epoch 60, iter 1827, Dice Sup Loss: 0.45735, BCE Sup Loss: 0.65202
Epoch 60, iter 1828, Dice Sup Loss: 0.49018, BCE Sup Loss: 0.62106
Epoch 60, iter 1829, Dice Sup Loss: 0.37694, BCE Sup Loss: 0.49249
Epoch 60, iter 1830, Dice Sup Loss: 0.56062, BCE Sup Loss: 0.56793
Epoch 60, Total train step 1829 || AVG_loss: 0.5157, Avg Dice score: 0.1159, Avg IOU: 0.067
Epoch 60, Validation || sum_loss: 0.99278, Dice score: 0.1665, IOU: 0.1039
Training and evaluating on epoch60 complete in 0m 7s
Epoch 61, iter 1831, Dice Sup Loss: 0.44158, BCE Sup Loss: 0.5636
Epoch 61, iter 1832, Dice Sup Loss: 0.43266, BCE Sup Loss: 0.58122
Epoch 61, iter 1833, Dice Sup Loss: 0.49484, BCE Sup Loss: 0.61618
Epoch 61, iter 1834, Dice Sup Loss: 0.4834, BCE Sup Loss: 0.62964
Epoch 61, iter 1835, Dice Sup Loss: 0.41499, BCE Sup Loss: 0.54624
Epoch 61, iter 1836, Dice Sup Loss: 0.47388, BCE Sup Loss: 0.63822
Epoch 61, iter 1837, Dice Sup Loss: 0.34404, BCE Sup Loss: 0.51529
Epoch 61, iter 1838, Dice Sup Loss: 0.49453, BCE Sup Loss: 0.61513
Epoch 61, iter 1839, Dice Sup Loss: 0.44243, BCE Sup Loss: 0.56559
Epoch 61, iter 1840, Dice Sup Loss: 0.43734, BCE Sup Loss: 0.57714
Epoch 61, iter 1841, Dice Sup Loss: 0.49864, BCE Sup Loss: 0.51797
Epoch 61, iter 1842, Dice Sup Loss: 0.51733, BCE Sup Loss: 0.59911
Epoch 61, iter 1843, Dice Sup Loss: 0.48119, BCE Sup Loss: 0.62368
Epoch 61, iter 1844, Dice Sup Loss: 0.45771, BCE Sup Loss: 0.64603
Epoch 61, iter 1845, Dice Sup Loss: 0.44855, BCE Sup Loss: 0.66009
Epoch 61, iter 1846, Dice Sup Loss: 0.40152, BCE Sup Loss: 0.57512
Epoch 61, iter 1847, Dice Sup Loss: 0.42208, BCE Sup Loss: 0.4722
Epoch 61, iter 1848, Dice Sup Loss: 0.42764, BCE Sup Loss: 0.5767
Epoch 61, iter 1849, Dice Sup Loss: 0.38669, BCE Sup Loss: 0.50696
Epoch 61, iter 1850, Dice Sup Loss: 0.4921, BCE Sup Loss: 0.62047
Epoch 61, iter 1851, Dice Sup Loss: 0.2956, BCE Sup Loss: 0.44242
Epoch 61, iter 1852, Dice Sup Loss: 0.46044, BCE Sup Loss: 0.64576
Epoch 61, iter 1853, Dice Sup Loss: 0.47518, BCE Sup Loss: 0.6331
Epoch 61, iter 1854, Dice Sup Loss: 0.47372, BCE Sup Loss: 0.5503
Epoch 61, iter 1855, Dice Sup Loss: 0.41717, BCE Sup Loss: 0.56109
Epoch 61, iter 1856, Dice Sup Loss: 0.47792, BCE Sup Loss: 0.63109
Epoch 61, iter 1857, Dice Sup Loss: 0.46507, BCE Sup Loss: 0.54317
Epoch 61, iter 1858, Dice Sup Loss: 0.48537, BCE Sup Loss: 0.62262
Epoch 61, iter 1859, Dice Sup Loss: 0.46477, BCE Sup Loss: 0.64778
Epoch 61, iter 1860, Dice Sup Loss: 0.58822, BCE Sup Loss: 0.56753
Epoch 61, Total train step 1859 || AVG_loss: 0.51634, Avg Dice score: 0.1168, Avg IOU: 0.0689
Epoch 61, Validation || sum_loss: 0.99367, Dice score: 0.164, IOU: 0.1022
Training and evaluating on epoch61 complete in 0m 7s
Epoch 62, iter 1861, Dice Sup Loss: 0.47473, BCE Sup Loss: 0.63424
Epoch 62, iter 1862, Dice Sup Loss: 0.45195, BCE Sup Loss: 0.55422
Epoch 62, iter 1863, Dice Sup Loss: 0.46252, BCE Sup Loss: 0.55071
Epoch 62, iter 1864, Dice Sup Loss: 0.41267, BCE Sup Loss: 0.5765
Epoch 62, iter 1865, Dice Sup Loss: 0.42867, BCE Sup Loss: 0.57904
Epoch 62, iter 1866, Dice Sup Loss: 0.45166, BCE Sup Loss: 0.6643
Epoch 62, iter 1867, Dice Sup Loss: 0.42364, BCE Sup Loss: 0.58678
Epoch 62, iter 1868, Dice Sup Loss: 0.46273, BCE Sup Loss: 0.54215
Epoch 62, iter 1869, Dice Sup Loss: 0.50845, BCE Sup Loss: 0.6076
Epoch 62, iter 1870, Dice Sup Loss: 0.51887, BCE Sup Loss: 0.60139
Epoch 62, iter 1871, Dice Sup Loss: 0.47807, BCE Sup Loss: 0.63022
Epoch 62, iter 1872, Dice Sup Loss: 0.47146, BCE Sup Loss: 0.5414
Epoch 62, iter 1873, Dice Sup Loss: 0.37529, BCE Sup Loss: 0.48782
Epoch 62, iter 1874, Dice Sup Loss: 0.39915, BCE Sup Loss: 0.60616
Epoch 62, iter 1875, Dice Sup Loss: 0.30461, BCE Sup Loss: 0.51932
Epoch 62, iter 1876, Dice Sup Loss: 0.41591, BCE Sup Loss: 0.57681
Epoch 62, iter 1877, Dice Sup Loss: 0.42818, BCE Sup Loss: 0.54588
Epoch 62, iter 1878, Dice Sup Loss: 0.42695, BCE Sup Loss: 0.59225
Epoch 62, iter 1879, Dice Sup Loss: 0.50331, BCE Sup Loss: 0.61293
Epoch 62, iter 1880, Dice Sup Loss: 0.5178, BCE Sup Loss: 0.60218
Epoch 62, iter 1881, Dice Sup Loss: 0.40605, BCE Sup Loss: 0.56141
Epoch 62, iter 1882, Dice Sup Loss: 0.49773, BCE Sup Loss: 0.61489
Epoch 62, iter 1883, Dice Sup Loss: 0.47726, BCE Sup Loss: 0.6342
Epoch 62, iter 1884, Dice Sup Loss: 0.46335, BCE Sup Loss: 0.64411
Epoch 62, iter 1885, Dice Sup Loss: 0.44299, BCE Sup Loss: 0.56952
Epoch 62, iter 1886, Dice Sup Loss: 0.45575, BCE Sup Loss: 0.54624
Epoch 62, iter 1887, Dice Sup Loss: 0.45655, BCE Sup Loss: 0.55258
Epoch 62, iter 1888, Dice Sup Loss: 0.48543, BCE Sup Loss: 0.62731
Epoch 62, iter 1889, Dice Sup Loss: 0.45239, BCE Sup Loss: 0.55621
Epoch 62, iter 1890, Dice Sup Loss: 0.45164, BCE Sup Loss: 0.65061
Epoch 62, Total train step 1889 || AVG_loss: 0.51691, Avg Dice score: 0.1152, Avg IOU: 0.0661
Epoch 62, Validation || sum_loss: 0.99142, Dice score: 0.1667, IOU: 0.1042
Training and evaluating on epoch62 complete in 0m 8s
Epoch 63, iter 1891, Dice Sup Loss: 0.4801, BCE Sup Loss: 0.6278
Epoch 63, iter 1892, Dice Sup Loss: 0.49144, BCE Sup Loss: 0.62243
Epoch 63, iter 1893, Dice Sup Loss: 0.45522, BCE Sup Loss: 0.65307
Epoch 63, iter 1894, Dice Sup Loss: 0.47363, BCE Sup Loss: 0.63336
Epoch 63, iter 1895, Dice Sup Loss: 0.41773, BCE Sup Loss: 0.55979
Epoch 63, iter 1896, Dice Sup Loss: 0.47187, BCE Sup Loss: 0.63425
Epoch 63, iter 1897, Dice Sup Loss: 0.43269, BCE Sup Loss: 0.55338
Epoch 63, iter 1898, Dice Sup Loss: 0.49497, BCE Sup Loss: 0.62058
Epoch 63, iter 1899, Dice Sup Loss: 0.42513, BCE Sup Loss: 0.48545
Epoch 63, iter 1900, Dice Sup Loss: 0.4796, BCE Sup Loss: 0.62968
Epoch 63, iter 1901, Dice Sup Loss: 0.43089, BCE Sup Loss: 0.57063
Epoch 63, iter 1902, Dice Sup Loss: 0.42572, BCE Sup Loss: 0.57584
Epoch 63, iter 1903, Dice Sup Loss: 0.50942, BCE Sup Loss: 0.60484
Epoch 63, iter 1904, Dice Sup Loss: 0.48659, BCE Sup Loss: 0.53991
Epoch 63, iter 1905, Dice Sup Loss: 0.34716, BCE Sup Loss: 0.54918
Epoch 63, iter 1906, Dice Sup Loss: 0.45252, BCE Sup Loss: 0.55774
Epoch 63, iter 1907, Dice Sup Loss: 0.45591, BCE Sup Loss: 0.55429
Epoch 63, iter 1908, Dice Sup Loss: 0.3925, BCE Sup Loss: 0.57888
Epoch 63, iter 1909, Dice Sup Loss: 0.44966, BCE Sup Loss: 0.65721
Epoch 63, iter 1910, Dice Sup Loss: 0.39833, BCE Sup Loss: 0.49555
Epoch 63, iter 1911, Dice Sup Loss: 0.47219, BCE Sup Loss: 0.6377
Epoch 63, iter 1912, Dice Sup Loss: 0.47225, BCE Sup Loss: 0.63523
Epoch 63, iter 1913, Dice Sup Loss: 0.43988, BCE Sup Loss: 0.56561
Epoch 63, iter 1914, Dice Sup Loss: 0.3615, BCE Sup Loss: 0.58339
Epoch 63, iter 1915, Dice Sup Loss: 0.50869, BCE Sup Loss: 0.61311
Epoch 63, iter 1916, Dice Sup Loss: 0.46006, BCE Sup Loss: 0.64164
Epoch 63, iter 1917, Dice Sup Loss: 0.48293, BCE Sup Loss: 0.62881
Epoch 63, iter 1918, Dice Sup Loss: 0.40289, BCE Sup Loss: 0.48684
Epoch 63, iter 1919, Dice Sup Loss: 0.35712, BCE Sup Loss: 0.50242
Epoch 63, iter 1920, Dice Sup Loss: 0.42951, BCE Sup Loss: 0.66229
Epoch 63, Total train step 1919 || AVG_loss: 0.51611, Avg Dice score: 0.1172, Avg IOU: 0.0678
Epoch 63, Validation || sum_loss: 0.99215, Dice score: 0.1682, IOU: 0.1053
Training and evaluating on epoch63 complete in 0m 8s
Epoch 64, iter 1921, Dice Sup Loss: 0.43378, BCE Sup Loss: 0.56718
Epoch 64, iter 1922, Dice Sup Loss: 0.48148, BCE Sup Loss: 0.62713
Epoch 64, iter 1923, Dice Sup Loss: 0.45577, BCE Sup Loss: 0.64839
Epoch 64, iter 1924, Dice Sup Loss: 0.47257, BCE Sup Loss: 0.63658
Epoch 64, iter 1925, Dice Sup Loss: 0.45455, BCE Sup Loss: 0.64866
Epoch 64, iter 1926, Dice Sup Loss: 0.47418, BCE Sup Loss: 0.63334
Epoch 64, iter 1927, Dice Sup Loss: 0.41372, BCE Sup Loss: 0.48223
Epoch 64, iter 1928, Dice Sup Loss: 0.46956, BCE Sup Loss: 0.63664
Epoch 64, iter 1929, Dice Sup Loss: 0.43941, BCE Sup Loss: 0.5652
Epoch 64, iter 1930, Dice Sup Loss: 0.39245, BCE Sup Loss: 0.60689
Epoch 64, iter 1931, Dice Sup Loss: 0.41228, BCE Sup Loss: 0.57173
Epoch 64, iter 1932, Dice Sup Loss: 0.44836, BCE Sup Loss: 0.56411
Epoch 64, iter 1933, Dice Sup Loss: 0.5019, BCE Sup Loss: 0.61585
Epoch 64, iter 1934, Dice Sup Loss: 0.36055, BCE Sup Loss: 0.50881
Epoch 64, iter 1935, Dice Sup Loss: 0.42105, BCE Sup Loss: 0.55514
Epoch 64, iter 1936, Dice Sup Loss: 0.5149, BCE Sup Loss: 0.60506
Epoch 64, iter 1937, Dice Sup Loss: 0.43087, BCE Sup Loss: 0.57646
Epoch 64, iter 1938, Dice Sup Loss: 0.50674, BCE Sup Loss: 0.60854
Epoch 64, iter 1939, Dice Sup Loss: 0.43861, BCE Sup Loss: 0.4843
Epoch 64, iter 1940, Dice Sup Loss: 0.46895, BCE Sup Loss: 0.64431
Epoch 64, iter 1941, Dice Sup Loss: 0.45849, BCE Sup Loss: 0.65064
Epoch 64, iter 1942, Dice Sup Loss: 0.46067, BCE Sup Loss: 0.54784
Epoch 64, iter 1943, Dice Sup Loss: 0.46562, BCE Sup Loss: 0.64579
Epoch 64, iter 1944, Dice Sup Loss: 0.40955, BCE Sup Loss: 0.56852
Epoch 64, iter 1945, Dice Sup Loss: 0.44654, BCE Sup Loss: 0.56569
Epoch 64, iter 1946, Dice Sup Loss: 0.45141, BCE Sup Loss: 0.53713
Epoch 64, iter 1947, Dice Sup Loss: 0.47962, BCE Sup Loss: 0.63186
Epoch 64, iter 1948, Dice Sup Loss: 0.33557, BCE Sup Loss: 0.48228
Epoch 64, iter 1949, Dice Sup Loss: 0.40188, BCE Sup Loss: 0.56447
Epoch 64, iter 1950, Dice Sup Loss: 0.50699, BCE Sup Loss: 0.60871
Epoch 64, Total train step 1949 || AVG_loss: 0.51539, Avg Dice score: 0.1209, Avg IOU: 0.0709
Epoch 64, Validation || sum_loss: 0.99074, Dice score: 0.1674, IOU: 0.1047
Training and evaluating on epoch64 complete in 0m 8s
Epoch 65, iter 1951, Dice Sup Loss: 0.46009, BCE Sup Loss: 0.55059
Epoch 65, iter 1952, Dice Sup Loss: 0.46836, BCE Sup Loss: 0.6406
Epoch 65, iter 1953, Dice Sup Loss: 0.4969, BCE Sup Loss: 0.61348
Epoch 65, iter 1954, Dice Sup Loss: 0.49978, BCE Sup Loss: 0.614
Epoch 65, iter 1955, Dice Sup Loss: 0.49385, BCE Sup Loss: 0.61521
Epoch 65, iter 1956, Dice Sup Loss: 0.50539, BCE Sup Loss: 0.60596
Epoch 65, iter 1957, Dice Sup Loss: 0.48797, BCE Sup Loss: 0.62415
Epoch 65, iter 1958, Dice Sup Loss: 0.44646, BCE Sup Loss: 0.56278
Epoch 65, iter 1959, Dice Sup Loss: 0.44101, BCE Sup Loss: 0.56558
Epoch 65, iter 1960, Dice Sup Loss: 0.46622, BCE Sup Loss: 0.64289
Epoch 65, iter 1961, Dice Sup Loss: 0.35946, BCE Sup Loss: 0.42906
Epoch 65, iter 1962, Dice Sup Loss: 0.46449, BCE Sup Loss: 0.64552
Epoch 65, iter 1963, Dice Sup Loss: 0.44099, BCE Sup Loss: 0.55798
Epoch 65, iter 1964, Dice Sup Loss: 0.46956, BCE Sup Loss: 0.54082
Epoch 65, iter 1965, Dice Sup Loss: 0.40942, BCE Sup Loss: 0.56867
Epoch 65, iter 1966, Dice Sup Loss: 0.44438, BCE Sup Loss: 0.56737
Epoch 65, iter 1967, Dice Sup Loss: 0.47555, BCE Sup Loss: 0.63035
Epoch 65, iter 1968, Dice Sup Loss: 0.31139, BCE Sup Loss: 0.45488
Epoch 65, iter 1969, Dice Sup Loss: 0.44606, BCE Sup Loss: 0.6557
Epoch 65, iter 1970, Dice Sup Loss: 0.31059, BCE Sup Loss: 0.53362
Epoch 65, iter 1971, Dice Sup Loss: 0.4895, BCE Sup Loss: 0.6222
Epoch 65, iter 1972, Dice Sup Loss: 0.40295, BCE Sup Loss: 0.57638
Epoch 65, iter 1973, Dice Sup Loss: 0.45748, BCE Sup Loss: 0.64516
Epoch 65, iter 1974, Dice Sup Loss: 0.35383, BCE Sup Loss: 0.53572
Epoch 65, iter 1975, Dice Sup Loss: 0.45247, BCE Sup Loss: 0.55868
Epoch 65, iter 1976, Dice Sup Loss: 0.45438, BCE Sup Loss: 0.54721
Epoch 65, iter 1977, Dice Sup Loss: 0.49679, BCE Sup Loss: 0.61799
Epoch 65, iter 1978, Dice Sup Loss: 0.48912, BCE Sup Loss: 0.62328
Epoch 65, iter 1979, Dice Sup Loss: 0.48258, BCE Sup Loss: 0.6268
Epoch 65, iter 1980, Dice Sup Loss: 0.4495, BCE Sup Loss: 0.65581
Epoch 65, Total train step 1979 || AVG_loss: 0.51653, Avg Dice score: 0.1114, Avg IOU: 0.0652
Epoch 65, Validation || sum_loss: 0.99213, Dice score: 0.1669, IOU: 0.1042
Training and evaluating on epoch65 complete in 0m 7s
Epoch 66, iter 1981, Dice Sup Loss: 0.4143, BCE Sup Loss: 0.5745
Epoch 66, iter 1982, Dice Sup Loss: 0.47081, BCE Sup Loss: 0.63588
Epoch 66, iter 1983, Dice Sup Loss: 0.48461, BCE Sup Loss: 0.62233
Epoch 66, iter 1984, Dice Sup Loss: 0.37816, BCE Sup Loss: 0.56137
Epoch 66, iter 1985, Dice Sup Loss: 0.46322, BCE Sup Loss: 0.64157
Epoch 66, iter 1986, Dice Sup Loss: 0.40432, BCE Sup Loss: 0.48913
Epoch 66, iter 1987, Dice Sup Loss: 0.45463, BCE Sup Loss: 0.55388
Epoch 66, iter 1988, Dice Sup Loss: 0.41276, BCE Sup Loss: 0.57532
Epoch 66, iter 1989, Dice Sup Loss: 0.44593, BCE Sup Loss: 0.5607
Epoch 66, iter 1990, Dice Sup Loss: 0.42444, BCE Sup Loss: 0.56708
Epoch 66, iter 1991, Dice Sup Loss: 0.40592, BCE Sup Loss: 0.4765
Epoch 66, iter 1992, Dice Sup Loss: 0.37496, BCE Sup Loss: 0.6066
Epoch 66, iter 1993, Dice Sup Loss: 0.50607, BCE Sup Loss: 0.60725
Epoch 66, iter 1994, Dice Sup Loss: 0.3821, BCE Sup Loss: 0.59277
Epoch 66, iter 1995, Dice Sup Loss: 0.40212, BCE Sup Loss: 0.49618
Epoch 66, iter 1996, Dice Sup Loss: 0.45521, BCE Sup Loss: 0.54587
Epoch 66, iter 1997, Dice Sup Loss: 0.52241, BCE Sup Loss: 0.59572
Epoch 66, iter 1998, Dice Sup Loss: 0.52826, BCE Sup Loss: 0.59554
Epoch 66, iter 1999, Dice Sup Loss: 0.44318, BCE Sup Loss: 0.67136
Epoch 66, iter 2000, Dice Sup Loss: 0.41907, BCE Sup Loss: 0.55403
Epoch 66, iter 2001, Dice Sup Loss: 0.46874, BCE Sup Loss: 0.64099
Epoch 66, iter 2002, Dice Sup Loss: 0.45038, BCE Sup Loss: 0.55775
Epoch 66, iter 2003, Dice Sup Loss: 0.48367, BCE Sup Loss: 0.62921
Epoch 66, iter 2004, Dice Sup Loss: 0.47213, BCE Sup Loss: 0.63525
Epoch 66, iter 2005, Dice Sup Loss: 0.51148, BCE Sup Loss: 0.60541
Epoch 66, iter 2006, Dice Sup Loss: 0.40357, BCE Sup Loss: 0.51435
Epoch 66, iter 2007, Dice Sup Loss: 0.47961, BCE Sup Loss: 0.62759
Epoch 66, iter 2008, Dice Sup Loss: 0.42581, BCE Sup Loss: 0.5808
Epoch 66, iter 2009, Dice Sup Loss: 0.48978, BCE Sup Loss: 0.61939
Epoch 66, iter 2010, Dice Sup Loss: 0.61441, BCE Sup Loss: 0.56418
Epoch 66, Total train step 2009 || AVG_loss: 0.51604, Avg Dice score: 0.118, Avg IOU: 0.0672
Epoch 66, Validation || sum_loss: 0.99326, Dice score: 0.1651, IOU: 0.103
Training and evaluating on epoch66 complete in 0m 8s
Epoch 67, iter 2011, Dice Sup Loss: 0.44925, BCE Sup Loss: 0.65237
Epoch 67, iter 2012, Dice Sup Loss: 0.38896, BCE Sup Loss: 0.58947
Epoch 67, iter 2013, Dice Sup Loss: 0.45441, BCE Sup Loss: 0.55222
Epoch 67, iter 2014, Dice Sup Loss: 0.42845, BCE Sup Loss: 0.58326
Epoch 67, iter 2015, Dice Sup Loss: 0.4775, BCE Sup Loss: 0.54017
Epoch 67, iter 2016, Dice Sup Loss: 0.51337, BCE Sup Loss: 0.60515
Epoch 67, iter 2017, Dice Sup Loss: 0.38563, BCE Sup Loss: 0.58924
Epoch 67, iter 2018, Dice Sup Loss: 0.48485, BCE Sup Loss: 0.62526
Epoch 67, iter 2019, Dice Sup Loss: 0.4752, BCE Sup Loss: 0.6302
Epoch 67, iter 2020, Dice Sup Loss: 0.42742, BCE Sup Loss: 0.48745
Epoch 67, iter 2021, Dice Sup Loss: 0.50843, BCE Sup Loss: 0.60715
Epoch 67, iter 2022, Dice Sup Loss: 0.43774, BCE Sup Loss: 0.57678
Epoch 67, iter 2023, Dice Sup Loss: 0.46872, BCE Sup Loss: 0.54381
Epoch 67, iter 2024, Dice Sup Loss: 0.42415, BCE Sup Loss: 0.6925
Epoch 67, iter 2025, Dice Sup Loss: 0.39942, BCE Sup Loss: 0.49945
Epoch 67, iter 2026, Dice Sup Loss: 0.48609, BCE Sup Loss: 0.62361
Epoch 67, iter 2027, Dice Sup Loss: 0.41863, BCE Sup Loss: 0.57394
Epoch 67, iter 2028, Dice Sup Loss: 0.47666, BCE Sup Loss: 0.63158
Epoch 67, iter 2029, Dice Sup Loss: 0.4436, BCE Sup Loss: 0.56499
Epoch 67, iter 2030, Dice Sup Loss: 0.42713, BCE Sup Loss: 0.55162
Epoch 67, iter 2031, Dice Sup Loss: 0.45094, BCE Sup Loss: 0.65179
Epoch 67, iter 2032, Dice Sup Loss: 0.38517, BCE Sup Loss: 0.55377
Epoch 67, iter 2033, Dice Sup Loss: 0.44088, BCE Sup Loss: 0.54464
Epoch 67, iter 2034, Dice Sup Loss: 0.47109, BCE Sup Loss: 0.63461
Epoch 67, iter 2035, Dice Sup Loss: 0.48283, BCE Sup Loss: 0.62609
Epoch 67, iter 2036, Dice Sup Loss: 0.45173, BCE Sup Loss: 0.55097
Epoch 67, iter 2037, Dice Sup Loss: 0.41862, BCE Sup Loss: 0.55839
Epoch 67, iter 2038, Dice Sup Loss: 0.49181, BCE Sup Loss: 0.61719
Epoch 67, iter 2039, Dice Sup Loss: 0.37798, BCE Sup Loss: 0.50313
Epoch 67, iter 2040, Dice Sup Loss: 0.45455, BCE Sup Loss: 0.64969
Epoch 67, Total train step 2039 || AVG_loss: 0.5158, Avg Dice score: 0.1215, Avg IOU: 0.0691
Epoch 67, Validation || sum_loss: 0.99208, Dice score: 0.1655, IOU: 0.1033
Training and evaluating on epoch67 complete in 0m 8s
Epoch 68, iter 2041, Dice Sup Loss: 0.5292, BCE Sup Loss: 0.58807
Epoch 68, iter 2042, Dice Sup Loss: 0.46195, BCE Sup Loss: 0.64823
Epoch 68, iter 2043, Dice Sup Loss: 0.48187, BCE Sup Loss: 0.62881
Epoch 68, iter 2044, Dice Sup Loss: 0.47511, BCE Sup Loss: 0.63338
Epoch 68, iter 2045, Dice Sup Loss: 0.38172, BCE Sup Loss: 0.55282
Epoch 68, iter 2046, Dice Sup Loss: 0.46586, BCE Sup Loss: 0.64393
Epoch 68, iter 2047, Dice Sup Loss: 0.51097, BCE Sup Loss: 0.60194
Epoch 68, iter 2048, Dice Sup Loss: 0.49986, BCE Sup Loss: 0.61495
Epoch 68, iter 2049, Dice Sup Loss: 0.39777, BCE Sup Loss: 0.49972
Epoch 68, iter 2050, Dice Sup Loss: 0.37852, BCE Sup Loss: 0.49863
Epoch 68, iter 2051, Dice Sup Loss: 0.48776, BCE Sup Loss: 0.62381
Epoch 68, iter 2052, Dice Sup Loss: 0.54125, BCE Sup Loss: 0.59058
Epoch 68, iter 2053, Dice Sup Loss: 0.49911, BCE Sup Loss: 0.60986
Epoch 68, iter 2054, Dice Sup Loss: 0.47803, BCE Sup Loss: 0.53464
Epoch 68, iter 2055, Dice Sup Loss: 0.3849, BCE Sup Loss: 0.51457
Epoch 68, iter 2056, Dice Sup Loss: 0.47869, BCE Sup Loss: 0.6281
Epoch 68, iter 2057, Dice Sup Loss: 0.37269, BCE Sup Loss: 0.54219
Epoch 68, iter 2058, Dice Sup Loss: 0.44015, BCE Sup Loss: 0.67137
Epoch 68, iter 2059, Dice Sup Loss: 0.39955, BCE Sup Loss: 0.56816
Epoch 68, iter 2060, Dice Sup Loss: 0.37579, BCE Sup Loss: 0.49652
Epoch 68, iter 2061, Dice Sup Loss: 0.5343, BCE Sup Loss: 0.59275
Epoch 68, iter 2062, Dice Sup Loss: 0.48518, BCE Sup Loss: 0.62256
Epoch 68, iter 2063, Dice Sup Loss: 0.41066, BCE Sup Loss: 0.56579
Epoch 68, iter 2064, Dice Sup Loss: 0.40849, BCE Sup Loss: 0.48428
Epoch 68, iter 2065, Dice Sup Loss: 0.41602, BCE Sup Loss: 0.58385
Epoch 68, iter 2066, Dice Sup Loss: 0.41997, BCE Sup Loss: 0.57577
Epoch 68, iter 2067, Dice Sup Loss: 0.36881, BCE Sup Loss: 0.50361
Epoch 68, iter 2068, Dice Sup Loss: 0.45204, BCE Sup Loss: 0.65543
Epoch 68, iter 2069, Dice Sup Loss: 0.46595, BCE Sup Loss: 0.63863
Epoch 68, iter 2070, Dice Sup Loss: 0.45675, BCE Sup Loss: 0.64102
Epoch 68, Total train step 2069 || AVG_loss: 0.51592, Avg Dice score: 0.1153, Avg IOU: 0.0672
Epoch 68, Validation || sum_loss: 0.99123, Dice score: 0.1675, IOU: 0.1048
Training and evaluating on epoch68 complete in 0m 8s
Epoch 69, iter 2071, Dice Sup Loss: 0.4321, BCE Sup Loss: 0.55464
Epoch 69, iter 2072, Dice Sup Loss: 0.41975, BCE Sup Loss: 0.56221
Epoch 69, iter 2073, Dice Sup Loss: 0.39464, BCE Sup Loss: 0.57233
Epoch 69, iter 2074, Dice Sup Loss: 0.42391, BCE Sup Loss: 0.5896
Epoch 69, iter 2075, Dice Sup Loss: 0.42399, BCE Sup Loss: 0.57782
Epoch 69, iter 2076, Dice Sup Loss: 0.50346, BCE Sup Loss: 0.61857
Epoch 69, iter 2077, Dice Sup Loss: 0.38556, BCE Sup Loss: 0.51477
Epoch 69, iter 2078, Dice Sup Loss: 0.45846, BCE Sup Loss: 0.64201
Epoch 69, iter 2079, Dice Sup Loss: 0.48992, BCE Sup Loss: 0.62311
Epoch 69, iter 2080, Dice Sup Loss: 0.45777, BCE Sup Loss: 0.64479
Epoch 69, iter 2081, Dice Sup Loss: 0.45809, BCE Sup Loss: 0.64269
Epoch 69, iter 2082, Dice Sup Loss: 0.45112, BCE Sup Loss: 0.55851
Epoch 69, iter 2083, Dice Sup Loss: 0.31218, BCE Sup Loss: 0.53415
Epoch 69, iter 2084, Dice Sup Loss: 0.48552, BCE Sup Loss: 0.62605
Epoch 69, iter 2085, Dice Sup Loss: 0.41886, BCE Sup Loss: 0.57463
Epoch 69, iter 2086, Dice Sup Loss: 0.44289, BCE Sup Loss: 0.55688
Epoch 69, iter 2087, Dice Sup Loss: 0.50176, BCE Sup Loss: 0.61658
Epoch 69, iter 2088, Dice Sup Loss: 0.48448, BCE Sup Loss: 0.62676
Epoch 69, iter 2089, Dice Sup Loss: 0.47641, BCE Sup Loss: 0.62803
Epoch 69, iter 2090, Dice Sup Loss: 0.44079, BCE Sup Loss: 0.55632
Epoch 69, iter 2091, Dice Sup Loss: 0.3769, BCE Sup Loss: 0.50772
Epoch 69, iter 2092, Dice Sup Loss: 0.47339, BCE Sup Loss: 0.63578
Epoch 69, iter 2093, Dice Sup Loss: 0.392, BCE Sup Loss: 0.47804
Epoch 69, iter 2094, Dice Sup Loss: 0.44981, BCE Sup Loss: 0.66368
Epoch 69, iter 2095, Dice Sup Loss: 0.46848, BCE Sup Loss: 0.64119
Epoch 69, iter 2096, Dice Sup Loss: 0.40032, BCE Sup Loss: 0.56554
Epoch 69, iter 2097, Dice Sup Loss: 0.41863, BCE Sup Loss: 0.48109
Epoch 69, iter 2098, Dice Sup Loss: 0.50119, BCE Sup Loss: 0.6109
Epoch 69, iter 2099, Dice Sup Loss: 0.51022, BCE Sup Loss: 0.60169
Epoch 69, iter 2100, Dice Sup Loss: 0.56981, BCE Sup Loss: 0.56726
Epoch 69, Total train step 2099 || AVG_loss: 0.51504, Avg Dice score: 0.1164, Avg IOU: 0.0671
Epoch 69, Validation || sum_loss: 0.98964, Dice score: 0.1676, IOU: 0.1048
Training and evaluating on epoch69 complete in 0m 8s
Epoch 70, iter 2101, Dice Sup Loss: 0.37294, BCE Sup Loss: 0.61352
Epoch 70, iter 2102, Dice Sup Loss: 0.50928, BCE Sup Loss: 0.60426
Epoch 70, iter 2103, Dice Sup Loss: 0.49284, BCE Sup Loss: 0.61741
Epoch 70, iter 2104, Dice Sup Loss: 0.49278, BCE Sup Loss: 0.61574
Epoch 70, iter 2105, Dice Sup Loss: 0.34233, BCE Sup Loss: 0.49609
Epoch 70, iter 2106, Dice Sup Loss: 0.48887, BCE Sup Loss: 0.62595
Epoch 70, iter 2107, Dice Sup Loss: 0.45544, BCE Sup Loss: 0.5494
Epoch 70, iter 2108, Dice Sup Loss: 0.50265, BCE Sup Loss: 0.60769
Epoch 70, iter 2109, Dice Sup Loss: 0.4749, BCE Sup Loss: 0.63317
Epoch 70, iter 2110, Dice Sup Loss: 0.50086, BCE Sup Loss: 0.60967
Epoch 70, iter 2111, Dice Sup Loss: 0.41803, BCE Sup Loss: 0.5655
Epoch 70, iter 2112, Dice Sup Loss: 0.43745, BCE Sup Loss: 0.55582
Epoch 70, iter 2113, Dice Sup Loss: 0.44761, BCE Sup Loss: 0.55647
Epoch 70, iter 2114, Dice Sup Loss: 0.45343, BCE Sup Loss: 0.56192
Epoch 70, iter 2115, Dice Sup Loss: 0.42699, BCE Sup Loss: 0.55818
Epoch 70, iter 2116, Dice Sup Loss: 0.44383, BCE Sup Loss: 0.55686
Epoch 70, iter 2117, Dice Sup Loss: 0.4648, BCE Sup Loss: 0.64392
Epoch 70, iter 2118, Dice Sup Loss: 0.37809, BCE Sup Loss: 0.51411
Epoch 70, iter 2119, Dice Sup Loss: 0.48063, BCE Sup Loss: 0.62799
Epoch 70, iter 2120, Dice Sup Loss: 0.48672, BCE Sup Loss: 0.62529
Epoch 70, iter 2121, Dice Sup Loss: 0.49686, BCE Sup Loss: 0.61766
Epoch 70, iter 2122, Dice Sup Loss: 0.47585, BCE Sup Loss: 0.63082
Epoch 70, iter 2123, Dice Sup Loss: 0.47219, BCE Sup Loss: 0.63645
Epoch 70, iter 2124, Dice Sup Loss: 0.52998, BCE Sup Loss: 0.60101
Epoch 70, iter 2125, Dice Sup Loss: 0.33832, BCE Sup Loss: 0.5134
Epoch 70, iter 2126, Dice Sup Loss: 0.35258, BCE Sup Loss: 0.43782
Epoch 70, iter 2127, Dice Sup Loss: 0.36498, BCE Sup Loss: 0.50954
Epoch 70, iter 2128, Dice Sup Loss: 0.44706, BCE Sup Loss: 0.56292
Epoch 70, iter 2129, Dice Sup Loss: 0.46039, BCE Sup Loss: 0.64304
Epoch 70, iter 2130, Dice Sup Loss: 0.52641, BCE Sup Loss: 0.59321
Epoch 70, Total train step 2129 || AVG_loss: 0.51571, Avg Dice score: 0.1106, Avg IOU: 0.0645
Epoch 70, Validation || sum_loss: 0.9922, Dice score: 0.1672, IOU: 0.1044
Training and evaluating on epoch70 complete in 0m 8s
Epoch 71, iter 2131, Dice Sup Loss: 0.49073, BCE Sup Loss: 0.62062
Epoch 71, iter 2132, Dice Sup Loss: 0.3846, BCE Sup Loss: 0.49003
Epoch 71, iter 2133, Dice Sup Loss: 0.44648, BCE Sup Loss: 0.56
Epoch 71, iter 2134, Dice Sup Loss: 0.36694, BCE Sup Loss: 0.57949
Epoch 71, iter 2135, Dice Sup Loss: 0.45877, BCE Sup Loss: 0.65243
Epoch 71, iter 2136, Dice Sup Loss: 0.42663, BCE Sup Loss: 0.57174
Epoch 71, iter 2137, Dice Sup Loss: 0.46964, BCE Sup Loss: 0.63727
Epoch 71, iter 2138, Dice Sup Loss: 0.53517, BCE Sup Loss: 0.60185
Epoch 71, iter 2139, Dice Sup Loss: 0.40532, BCE Sup Loss: 0.49805
Epoch 71, iter 2140, Dice Sup Loss: 0.49217, BCE Sup Loss: 0.62135
Epoch 71, iter 2141, Dice Sup Loss: 0.40749, BCE Sup Loss: 0.56779
Epoch 71, iter 2142, Dice Sup Loss: 0.41076, BCE Sup Loss: 0.55173
Epoch 71, iter 2143, Dice Sup Loss: 0.48814, BCE Sup Loss: 0.62355
Epoch 71, iter 2144, Dice Sup Loss: 0.46828, BCE Sup Loss: 0.63841
Epoch 71, iter 2145, Dice Sup Loss: 0.49032, BCE Sup Loss: 0.61927
Epoch 71, iter 2146, Dice Sup Loss: 0.40047, BCE Sup Loss: 0.58779
Epoch 71, iter 2147, Dice Sup Loss: 0.51412, BCE Sup Loss: 0.60337
Epoch 71, iter 2148, Dice Sup Loss: 0.48406, BCE Sup Loss: 0.62441
Epoch 71, iter 2149, Dice Sup Loss: 0.47392, BCE Sup Loss: 0.63182
Epoch 71, iter 2150, Dice Sup Loss: 0.29872, BCE Sup Loss: 0.36442
Epoch 71, iter 2151, Dice Sup Loss: 0.36186, BCE Sup Loss: 0.51011
Epoch 71, iter 2152, Dice Sup Loss: 0.46328, BCE Sup Loss: 0.53746
Epoch 71, iter 2153, Dice Sup Loss: 0.4727, BCE Sup Loss: 0.63414
Epoch 71, iter 2154, Dice Sup Loss: 0.49398, BCE Sup Loss: 0.61756
Epoch 71, iter 2155, Dice Sup Loss: 0.44542, BCE Sup Loss: 0.5536
Epoch 71, iter 2156, Dice Sup Loss: 0.48158, BCE Sup Loss: 0.62648
Epoch 71, iter 2157, Dice Sup Loss: 0.4176, BCE Sup Loss: 0.57306
Epoch 71, iter 2158, Dice Sup Loss: 0.45755, BCE Sup Loss: 0.65072
Epoch 71, iter 2159, Dice Sup Loss: 0.44829, BCE Sup Loss: 0.56776
Epoch 71, iter 2160, Dice Sup Loss: 0.52158, BCE Sup Loss: 0.59733
Epoch 71, Total train step 2159 || AVG_loss: 0.51521, Avg Dice score: 0.116, Avg IOU: 0.0685
Epoch 71, Validation || sum_loss: 0.99, Dice score: 0.1677, IOU: 0.1049
Training and evaluating on epoch71 complete in 0m 8s
Epoch 72, iter 2161, Dice Sup Loss: 0.48066, BCE Sup Loss: 0.62568
Epoch 72, iter 2162, Dice Sup Loss: 0.40666, BCE Sup Loss: 0.55878
Epoch 72, iter 2163, Dice Sup Loss: 0.40142, BCE Sup Loss: 0.57927
Epoch 72, iter 2164, Dice Sup Loss: 0.47388, BCE Sup Loss: 0.63147
Epoch 72, iter 2165, Dice Sup Loss: 0.4829, BCE Sup Loss: 0.62722
Epoch 72, iter 2166, Dice Sup Loss: 0.43059, BCE Sup Loss: 0.56436
Epoch 72, iter 2167, Dice Sup Loss: 0.37554, BCE Sup Loss: 0.60506
Epoch 72, iter 2168, Dice Sup Loss: 0.36685, BCE Sup Loss: 0.49899
Epoch 72, iter 2169, Dice Sup Loss: 0.43651, BCE Sup Loss: 0.56938
Epoch 72, iter 2170, Dice Sup Loss: 0.42151, BCE Sup Loss: 0.57619
Epoch 72, iter 2171, Dice Sup Loss: 0.42072, BCE Sup Loss: 0.56995
Epoch 72, iter 2172, Dice Sup Loss: 0.39521, BCE Sup Loss: 0.5803
Epoch 72, iter 2173, Dice Sup Loss: 0.44866, BCE Sup Loss: 0.65208
Epoch 72, iter 2174, Dice Sup Loss: 0.52027, BCE Sup Loss: 0.60859
Epoch 72, iter 2175, Dice Sup Loss: 0.41793, BCE Sup Loss: 0.58206
Epoch 72, iter 2176, Dice Sup Loss: 0.48818, BCE Sup Loss: 0.621
Epoch 72, iter 2177, Dice Sup Loss: 0.44893, BCE Sup Loss: 0.65138
Epoch 72, iter 2178, Dice Sup Loss: 0.49349, BCE Sup Loss: 0.62599
Epoch 72, iter 2179, Dice Sup Loss: 0.33233, BCE Sup Loss: 0.53272
Epoch 72, iter 2180, Dice Sup Loss: 0.4534, BCE Sup Loss: 0.55862
Epoch 72, iter 2181, Dice Sup Loss: 0.45119, BCE Sup Loss: 0.56287
Epoch 72, iter 2182, Dice Sup Loss: 0.40933, BCE Sup Loss: 0.48858
Epoch 72, iter 2183, Dice Sup Loss: 0.48159, BCE Sup Loss: 0.6284
Epoch 72, iter 2184, Dice Sup Loss: 0.47285, BCE Sup Loss: 0.63407
Epoch 72, iter 2185, Dice Sup Loss: 0.50343, BCE Sup Loss: 0.61294
Epoch 72, iter 2186, Dice Sup Loss: 0.50666, BCE Sup Loss: 0.60987
Epoch 72, iter 2187, Dice Sup Loss: 0.47964, BCE Sup Loss: 0.62676
Epoch 72, iter 2188, Dice Sup Loss: 0.46036, BCE Sup Loss: 0.55068
Epoch 72, iter 2189, Dice Sup Loss: 0.42295, BCE Sup Loss: 0.49062
Epoch 72, iter 2190, Dice Sup Loss: 0.55999, BCE Sup Loss: 0.56547
Epoch 72, Total train step 2189 || AVG_loss: 0.51585, Avg Dice score: 0.1152, Avg IOU: 0.0658
Epoch 72, Validation || sum_loss: 0.9928, Dice score: 0.1642, IOU: 0.1023
Training and evaluating on epoch72 complete in 0m 8s
Epoch 73, iter 2191, Dice Sup Loss: 0.39735, BCE Sup Loss: 0.50137
Epoch 73, iter 2192, Dice Sup Loss: 0.53982, BCE Sup Loss: 0.57884
Epoch 73, iter 2193, Dice Sup Loss: 0.49053, BCE Sup Loss: 0.62199
Epoch 73, iter 2194, Dice Sup Loss: 0.49241, BCE Sup Loss: 0.62254
Epoch 73, iter 2195, Dice Sup Loss: 0.49547, BCE Sup Loss: 0.61799
Epoch 73, iter 2196, Dice Sup Loss: 0.49243, BCE Sup Loss: 0.6258
Epoch 73, iter 2197, Dice Sup Loss: 0.46517, BCE Sup Loss: 0.65537
Epoch 73, iter 2198, Dice Sup Loss: 0.44365, BCE Sup Loss: 0.55847
Epoch 73, iter 2199, Dice Sup Loss: 0.46285, BCE Sup Loss: 0.64215
Epoch 73, iter 2200, Dice Sup Loss: 0.40551, BCE Sup Loss: 0.57598
Epoch 73, iter 2201, Dice Sup Loss: 0.43832, BCE Sup Loss: 0.56512
Epoch 73, iter 2202, Dice Sup Loss: 0.47639, BCE Sup Loss: 0.63002
Epoch 73, iter 2203, Dice Sup Loss: 0.44621, BCE Sup Loss: 0.65418
Epoch 73, iter 2204, Dice Sup Loss: 0.41296, BCE Sup Loss: 0.50647
Epoch 73, iter 2205, Dice Sup Loss: 0.4241, BCE Sup Loss: 0.57179
Epoch 73, iter 2206, Dice Sup Loss: 0.44349, BCE Sup Loss: 0.65278
Epoch 73, iter 2207, Dice Sup Loss: 0.4832, BCE Sup Loss: 0.55504
Epoch 73, iter 2208, Dice Sup Loss: 0.41582, BCE Sup Loss: 0.56314
Epoch 73, iter 2209, Dice Sup Loss: 0.40036, BCE Sup Loss: 0.57665
Epoch 73, iter 2210, Dice Sup Loss: 0.42076, BCE Sup Loss: 0.49067
Epoch 73, iter 2211, Dice Sup Loss: 0.40587, BCE Sup Loss: 0.58129
Epoch 73, iter 2212, Dice Sup Loss: 0.48085, BCE Sup Loss: 0.62828
Epoch 73, iter 2213, Dice Sup Loss: 0.35303, BCE Sup Loss: 0.51021
Epoch 73, iter 2214, Dice Sup Loss: 0.40005, BCE Sup Loss: 0.58032
Epoch 73, iter 2215, Dice Sup Loss: 0.3997, BCE Sup Loss: 0.58274
Epoch 73, iter 2216, Dice Sup Loss: 0.48297, BCE Sup Loss: 0.62855
Epoch 73, iter 2217, Dice Sup Loss: 0.49068, BCE Sup Loss: 0.61865
Epoch 73, iter 2218, Dice Sup Loss: 0.53115, BCE Sup Loss: 0.58989
Epoch 73, iter 2219, Dice Sup Loss: 0.39298, BCE Sup Loss: 0.50536
Epoch 73, iter 2220, Dice Sup Loss: 0.61097, BCE Sup Loss: 0.54397
Epoch 73, Total train step 2219 || AVG_loss: 0.51708, Avg Dice score: 0.1181, Avg IOU: 0.0678
Epoch 73, Validation || sum_loss: 0.99084, Dice score: 0.1691, IOU: 0.1058
Training and evaluating on epoch73 complete in 0m 8s
Epoch 74, iter 2221, Dice Sup Loss: 0.28314, BCE Sup Loss: 0.44474
Epoch 74, iter 2222, Dice Sup Loss: 0.44656, BCE Sup Loss: 0.57065
Epoch 74, iter 2223, Dice Sup Loss: 0.5032, BCE Sup Loss: 0.60958
Epoch 74, iter 2224, Dice Sup Loss: 0.41444, BCE Sup Loss: 0.50573
Epoch 74, iter 2225, Dice Sup Loss: 0.45669, BCE Sup Loss: 0.54881
Epoch 74, iter 2226, Dice Sup Loss: 0.46815, BCE Sup Loss: 0.52719
Epoch 74, iter 2227, Dice Sup Loss: 0.49165, BCE Sup Loss: 0.62589
Epoch 74, iter 2228, Dice Sup Loss: 0.50052, BCE Sup Loss: 0.61243
Epoch 74, iter 2229, Dice Sup Loss: 0.46412, BCE Sup Loss: 0.66283
Epoch 74, iter 2230, Dice Sup Loss: 0.4474, BCE Sup Loss: 0.56355
Epoch 74, iter 2231, Dice Sup Loss: 0.45766, BCE Sup Loss: 0.66257
Epoch 74, iter 2232, Dice Sup Loss: 0.50515, BCE Sup Loss: 0.60719
Epoch 74, iter 2233, Dice Sup Loss: 0.32756, BCE Sup Loss: 0.52944
Epoch 74, iter 2234, Dice Sup Loss: 0.53034, BCE Sup Loss: 0.59485
Epoch 74, iter 2235, Dice Sup Loss: 0.49222, BCE Sup Loss: 0.62108
Epoch 74, iter 2236, Dice Sup Loss: 0.47453, BCE Sup Loss: 0.63371
Epoch 74, iter 2237, Dice Sup Loss: 0.49897, BCE Sup Loss: 0.61895
Epoch 74, iter 2238, Dice Sup Loss: 0.38983, BCE Sup Loss: 0.59649
Epoch 74, iter 2239, Dice Sup Loss: 0.40662, BCE Sup Loss: 0.49188
Epoch 74, iter 2240, Dice Sup Loss: 0.48431, BCE Sup Loss: 0.62759
Epoch 74, iter 2241, Dice Sup Loss: 0.44085, BCE Sup Loss: 0.56423
Epoch 74, iter 2242, Dice Sup Loss: 0.47057, BCE Sup Loss: 0.55862
Epoch 74, iter 2243, Dice Sup Loss: 0.45711, BCE Sup Loss: 0.64498
Epoch 74, iter 2244, Dice Sup Loss: 0.43888, BCE Sup Loss: 0.55458
Epoch 74, iter 2245, Dice Sup Loss: 0.49732, BCE Sup Loss: 0.61888
Epoch 74, iter 2246, Dice Sup Loss: 0.50186, BCE Sup Loss: 0.61639
Epoch 74, iter 2247, Dice Sup Loss: 0.46131, BCE Sup Loss: 0.54997
Epoch 74, iter 2248, Dice Sup Loss: 0.47245, BCE Sup Loss: 0.63491
Epoch 74, iter 2249, Dice Sup Loss: 0.34545, BCE Sup Loss: 0.53607
Epoch 74, iter 2250, Dice Sup Loss: 0.44826, BCE Sup Loss: 0.66024
Epoch 74, Total train step 2249 || AVG_loss: 0.51848, Avg Dice score: 0.1085, Avg IOU: 0.0639
Epoch 74, Validation || sum_loss: 0.99247, Dice score: 0.1662, IOU: 0.1038
Training and evaluating on epoch74 complete in 0m 7s
Epoch 75, iter 2251, Dice Sup Loss: 0.51167, BCE Sup Loss: 0.60646
Epoch 75, iter 2252, Dice Sup Loss: 0.4633, BCE Sup Loss: 0.6439
Epoch 75, iter 2253, Dice Sup Loss: 0.46983, BCE Sup Loss: 0.63422
Epoch 75, iter 2254, Dice Sup Loss: 0.44798, BCE Sup Loss: 0.5581
Epoch 75, iter 2255, Dice Sup Loss: 0.47996, BCE Sup Loss: 0.62928
Epoch 75, iter 2256, Dice Sup Loss: 0.44935, BCE Sup Loss: 0.55891
Epoch 75, iter 2257, Dice Sup Loss: 0.46933, BCE Sup Loss: 0.63533
Epoch 75, iter 2258, Dice Sup Loss: 0.34422, BCE Sup Loss: 0.42305
Epoch 75, iter 2259, Dice Sup Loss: 0.47594, BCE Sup Loss: 0.62825
Epoch 75, iter 2260, Dice Sup Loss: 0.44938, BCE Sup Loss: 0.56025
Epoch 75, iter 2261, Dice Sup Loss: 0.37008, BCE Sup Loss: 0.57152
Epoch 75, iter 2262, Dice Sup Loss: 0.49359, BCE Sup Loss: 0.61451
Epoch 75, iter 2263, Dice Sup Loss: 0.39061, BCE Sup Loss: 0.57083
Epoch 75, iter 2264, Dice Sup Loss: 0.38714, BCE Sup Loss: 0.50995
Epoch 75, iter 2265, Dice Sup Loss: 0.48916, BCE Sup Loss: 0.5291
Epoch 75, iter 2266, Dice Sup Loss: 0.45703, BCE Sup Loss: 0.64682
Epoch 75, iter 2267, Dice Sup Loss: 0.50149, BCE Sup Loss: 0.61616
Epoch 75, iter 2268, Dice Sup Loss: 0.46303, BCE Sup Loss: 0.64904
Epoch 75, iter 2269, Dice Sup Loss: 0.44393, BCE Sup Loss: 0.54015
Epoch 75, iter 2270, Dice Sup Loss: 0.51409, BCE Sup Loss: 0.60406
Epoch 75, iter 2271, Dice Sup Loss: 0.40591, BCE Sup Loss: 0.56035
Epoch 75, iter 2272, Dice Sup Loss: 0.4587, BCE Sup Loss: 0.65371
Epoch 75, iter 2273, Dice Sup Loss: 0.44243, BCE Sup Loss: 0.55881
Epoch 75, iter 2274, Dice Sup Loss: 0.48959, BCE Sup Loss: 0.62045
Epoch 75, iter 2275, Dice Sup Loss: 0.52207, BCE Sup Loss: 0.59674
Epoch 75, iter 2276, Dice Sup Loss: 0.35861, BCE Sup Loss: 0.53823
Epoch 75, iter 2277, Dice Sup Loss: 0.39104, BCE Sup Loss: 0.50218
Epoch 75, iter 2278, Dice Sup Loss: 0.41488, BCE Sup Loss: 0.59022
Epoch 75, iter 2279, Dice Sup Loss: 0.40451, BCE Sup Loss: 0.57312
Epoch 75, iter 2280, Dice Sup Loss: 0.61348, BCE Sup Loss: 0.55726
Epoch 75, Total train step 2279 || AVG_loss: 0.51552, Avg Dice score: 0.1157, Avg IOU: 0.0669
Epoch 75, Validation || sum_loss: 0.992, Dice score: 0.1669, IOU: 0.1042
Training and evaluating on epoch75 complete in 0m 7s
Epoch 76, iter 2281, Dice Sup Loss: 0.49639, BCE Sup Loss: 0.61487
Epoch 76, iter 2282, Dice Sup Loss: 0.39937, BCE Sup Loss: 0.57546
Epoch 76, iter 2283, Dice Sup Loss: 0.42544, BCE Sup Loss: 0.57993
Epoch 76, iter 2284, Dice Sup Loss: 0.44812, BCE Sup Loss: 0.5623
Epoch 76, iter 2285, Dice Sup Loss: 0.46354, BCE Sup Loss: 0.64509
Epoch 76, iter 2286, Dice Sup Loss: 0.512, BCE Sup Loss: 0.60271
Epoch 76, iter 2287, Dice Sup Loss: 0.39323, BCE Sup Loss: 0.57853
Epoch 76, iter 2288, Dice Sup Loss: 0.45416, BCE Sup Loss: 0.55727
Epoch 76, iter 2289, Dice Sup Loss: 0.46618, BCE Sup Loss: 0.63493
Epoch 76, iter 2290, Dice Sup Loss: 0.51136, BCE Sup Loss: 0.6033
Epoch 76, iter 2291, Dice Sup Loss: 0.41188, BCE Sup Loss: 0.57242
Epoch 76, iter 2292, Dice Sup Loss: 0.4834, BCE Sup Loss: 0.62563
Epoch 76, iter 2293, Dice Sup Loss: 0.36262, BCE Sup Loss: 0.58653
Epoch 76, iter 2294, Dice Sup Loss: 0.46243, BCE Sup Loss: 0.54814
Epoch 76, iter 2295, Dice Sup Loss: 0.46599, BCE Sup Loss: 0.64128
Epoch 76, iter 2296, Dice Sup Loss: 0.43715, BCE Sup Loss: 0.55827
Epoch 76, iter 2297, Dice Sup Loss: 0.45344, BCE Sup Loss: 0.54605
Epoch 76, iter 2298, Dice Sup Loss: 0.4898, BCE Sup Loss: 0.62611
Epoch 76, iter 2299, Dice Sup Loss: 0.44515, BCE Sup Loss: 0.53979
Epoch 76, iter 2300, Dice Sup Loss: 0.48235, BCE Sup Loss: 0.62562
Epoch 76, iter 2301, Dice Sup Loss: 0.44405, BCE Sup Loss: 0.55984
Epoch 76, iter 2302, Dice Sup Loss: 0.47743, BCE Sup Loss: 0.62441
Epoch 76, iter 2303, Dice Sup Loss: 0.40052, BCE Sup Loss: 0.57931
Epoch 76, iter 2304, Dice Sup Loss: 0.42271, BCE Sup Loss: 0.59169
Epoch 76, iter 2305, Dice Sup Loss: 0.41822, BCE Sup Loss: 0.54261
Epoch 76, iter 2306, Dice Sup Loss: 0.39531, BCE Sup Loss: 0.50261
Epoch 76, iter 2307, Dice Sup Loss: 0.39442, BCE Sup Loss: 0.52021
Epoch 76, iter 2308, Dice Sup Loss: 0.49075, BCE Sup Loss: 0.62003
Epoch 76, iter 2309, Dice Sup Loss: 0.45147, BCE Sup Loss: 0.54877
Epoch 76, iter 2310, Dice Sup Loss: 0.50267, BCE Sup Loss: 0.61581
Epoch 76, Total train step 2309 || AVG_loss: 0.51523, Avg Dice score: 0.1191, Avg IOU: 0.0667
Epoch 76, Validation || sum_loss: 0.99069, Dice score: 0.1676, IOU: 0.1049
Training and evaluating on epoch76 complete in 0m 7s
Epoch 77, iter 2311, Dice Sup Loss: 0.46453, BCE Sup Loss: 0.64044
Epoch 77, iter 2312, Dice Sup Loss: 0.44474, BCE Sup Loss: 0.55476
Epoch 77, iter 2313, Dice Sup Loss: 0.42206, BCE Sup Loss: 0.57902
Epoch 77, iter 2314, Dice Sup Loss: 0.49441, BCE Sup Loss: 0.6183
Epoch 77, iter 2315, Dice Sup Loss: 0.4513, BCE Sup Loss: 0.5625
Epoch 77, iter 2316, Dice Sup Loss: 0.55636, BCE Sup Loss: 0.5814
Epoch 77, iter 2317, Dice Sup Loss: 0.50487, BCE Sup Loss: 0.61107
Epoch 77, iter 2318, Dice Sup Loss: 0.44593, BCE Sup Loss: 0.66067
Epoch 77, iter 2319, Dice Sup Loss: 0.51398, BCE Sup Loss: 0.60483
Epoch 77, iter 2320, Dice Sup Loss: 0.32072, BCE Sup Loss: 0.43537
Epoch 77, iter 2321, Dice Sup Loss: 0.44752, BCE Sup Loss: 0.55947
Epoch 77, iter 2322, Dice Sup Loss: 0.44496, BCE Sup Loss: 0.57844
Epoch 77, iter 2323, Dice Sup Loss: 0.45531, BCE Sup Loss: 0.54948
Epoch 77, iter 2324, Dice Sup Loss: 0.41788, BCE Sup Loss: 0.55342
Epoch 77, iter 2325, Dice Sup Loss: 0.43887, BCE Sup Loss: 0.56316
Epoch 77, iter 2326, Dice Sup Loss: 0.30786, BCE Sup Loss: 0.50892
Epoch 77, iter 2327, Dice Sup Loss: 0.47022, BCE Sup Loss: 0.63683
Epoch 77, iter 2328, Dice Sup Loss: 0.4755, BCE Sup Loss: 0.6402
Epoch 77, iter 2329, Dice Sup Loss: 0.35666, BCE Sup Loss: 0.49759
Epoch 77, iter 2330, Dice Sup Loss: 0.45367, BCE Sup Loss: 0.65594
Epoch 77, iter 2331, Dice Sup Loss: 0.4255, BCE Sup Loss: 0.56576
Epoch 77, iter 2332, Dice Sup Loss: 0.49137, BCE Sup Loss: 0.61977
Epoch 77, iter 2333, Dice Sup Loss: 0.45991, BCE Sup Loss: 0.64267
Epoch 77, iter 2334, Dice Sup Loss: 0.48651, BCE Sup Loss: 0.62241
Epoch 77, iter 2335, Dice Sup Loss: 0.42157, BCE Sup Loss: 0.56114
Epoch 77, iter 2336, Dice Sup Loss: 0.39628, BCE Sup Loss: 0.50286
Epoch 77, iter 2337, Dice Sup Loss: 0.50328, BCE Sup Loss: 0.61406
Epoch 77, iter 2338, Dice Sup Loss: 0.4567, BCE Sup Loss: 0.64515
Epoch 77, iter 2339, Dice Sup Loss: 0.44771, BCE Sup Loss: 0.56348
Epoch 77, iter 2340, Dice Sup Loss: 0.52564, BCE Sup Loss: 0.60628
Epoch 77, Total train step 2339 || AVG_loss: 0.51582, Avg Dice score: 0.1119, Avg IOU: 0.066
Epoch 77, Validation || sum_loss: 0.99112, Dice score: 0.1684, IOU: 0.1054
Training and evaluating on epoch77 complete in 0m 8s
Epoch 78, iter 2341, Dice Sup Loss: 0.44901, BCE Sup Loss: 0.65099
Epoch 78, iter 2342, Dice Sup Loss: 0.39851, BCE Sup Loss: 0.50058
Epoch 78, iter 2343, Dice Sup Loss: 0.3885, BCE Sup Loss: 0.58643
Epoch 78, iter 2344, Dice Sup Loss: 0.49646, BCE Sup Loss: 0.61537
Epoch 78, iter 2345, Dice Sup Loss: 0.46472, BCE Sup Loss: 0.54838
Epoch 78, iter 2346, Dice Sup Loss: 0.42102, BCE Sup Loss: 0.55363
Epoch 78, iter 2347, Dice Sup Loss: 0.5256, BCE Sup Loss: 0.59384
Epoch 78, iter 2348, Dice Sup Loss: 0.45975, BCE Sup Loss: 0.64427
Epoch 78, iter 2349, Dice Sup Loss: 0.45012, BCE Sup Loss: 0.57033
Epoch 78, iter 2350, Dice Sup Loss: 0.46022, BCE Sup Loss: 0.54711
Epoch 78, iter 2351, Dice Sup Loss: 0.4543, BCE Sup Loss: 0.65444
Epoch 78, iter 2352, Dice Sup Loss: 0.48361, BCE Sup Loss: 0.62672
Epoch 78, iter 2353, Dice Sup Loss: 0.45822, BCE Sup Loss: 0.64851
Epoch 78, iter 2354, Dice Sup Loss: 0.37206, BCE Sup Loss: 0.56582
Epoch 78, iter 2355, Dice Sup Loss: 0.34728, BCE Sup Loss: 0.42179
Epoch 78, iter 2356, Dice Sup Loss: 0.46532, BCE Sup Loss: 0.6419
Epoch 78, iter 2357, Dice Sup Loss: 0.5197, BCE Sup Loss: 0.60134
Epoch 78, iter 2358, Dice Sup Loss: 0.46901, BCE Sup Loss: 0.63533
Epoch 78, iter 2359, Dice Sup Loss: 0.46461, BCE Sup Loss: 0.64113
Epoch 78, iter 2360, Dice Sup Loss: 0.40259, BCE Sup Loss: 0.56038
Epoch 78, iter 2361, Dice Sup Loss: 0.4615, BCE Sup Loss: 0.63978
Epoch 78, iter 2362, Dice Sup Loss: 0.42722, BCE Sup Loss: 0.56748
Epoch 78, iter 2363, Dice Sup Loss: 0.51072, BCE Sup Loss: 0.61
Epoch 78, iter 2364, Dice Sup Loss: 0.32738, BCE Sup Loss: 0.4169
Epoch 78, iter 2365, Dice Sup Loss: 0.40558, BCE Sup Loss: 0.48963
Epoch 78, iter 2366, Dice Sup Loss: 0.49249, BCE Sup Loss: 0.61739
Epoch 78, iter 2367, Dice Sup Loss: 0.49985, BCE Sup Loss: 0.61175
Epoch 78, iter 2368, Dice Sup Loss: 0.46209, BCE Sup Loss: 0.64812
Epoch 78, iter 2369, Dice Sup Loss: 0.37917, BCE Sup Loss: 0.51447
Epoch 78, iter 2370, Dice Sup Loss: 0.45829, BCE Sup Loss: 0.65339
Epoch 78, Total train step 2369 || AVG_loss: 0.51467, Avg Dice score: 0.1186, Avg IOU: 0.0709
Epoch 78, Validation || sum_loss: 0.99306, Dice score: 0.1644, IOU: 0.1024
Training and evaluating on epoch78 complete in 0m 8s
Epoch 79, iter 2371, Dice Sup Loss: 0.47098, BCE Sup Loss: 0.54159
Epoch 79, iter 2372, Dice Sup Loss: 0.36625, BCE Sup Loss: 0.48875
Epoch 79, iter 2373, Dice Sup Loss: 0.45566, BCE Sup Loss: 0.54134
Epoch 79, iter 2374, Dice Sup Loss: 0.48693, BCE Sup Loss: 0.62079
Epoch 79, iter 2375, Dice Sup Loss: 0.49036, BCE Sup Loss: 0.61445
Epoch 79, iter 2376, Dice Sup Loss: 0.4761, BCE Sup Loss: 0.63051
Epoch 79, iter 2377, Dice Sup Loss: 0.45975, BCE Sup Loss: 0.64919
Epoch 79, iter 2378, Dice Sup Loss: 0.45892, BCE Sup Loss: 0.64605
Epoch 79, iter 2379, Dice Sup Loss: 0.37181, BCE Sup Loss: 0.56956
Epoch 79, iter 2380, Dice Sup Loss: 0.49202, BCE Sup Loss: 0.61634
Epoch 79, iter 2381, Dice Sup Loss: 0.46605, BCE Sup Loss: 0.63769
Epoch 79, iter 2382, Dice Sup Loss: 0.49543, BCE Sup Loss: 0.61707
Epoch 79, iter 2383, Dice Sup Loss: 0.41407, BCE Sup Loss: 0.47685
Epoch 79, iter 2384, Dice Sup Loss: 0.46106, BCE Sup Loss: 0.64176
Epoch 79, iter 2385, Dice Sup Loss: 0.4357, BCE Sup Loss: 0.56334
Epoch 79, iter 2386, Dice Sup Loss: 0.41352, BCE Sup Loss: 0.56391
Epoch 79, iter 2387, Dice Sup Loss: 0.49917, BCE Sup Loss: 0.61321
Epoch 79, iter 2388, Dice Sup Loss: 0.50512, BCE Sup Loss: 0.60355
Epoch 79, iter 2389, Dice Sup Loss: 0.46101, BCE Sup Loss: 0.64432
Epoch 79, iter 2390, Dice Sup Loss: 0.41696, BCE Sup Loss: 0.50667
Epoch 79, iter 2391, Dice Sup Loss: 0.29186, BCE Sup Loss: 0.35887
Epoch 79, iter 2392, Dice Sup Loss: 0.33214, BCE Sup Loss: 0.50413
Epoch 79, iter 2393, Dice Sup Loss: 0.44678, BCE Sup Loss: 0.66453
Epoch 79, iter 2394, Dice Sup Loss: 0.4784, BCE Sup Loss: 0.63455
Epoch 79, iter 2395, Dice Sup Loss: 0.41518, BCE Sup Loss: 0.59036
Epoch 79, iter 2396, Dice Sup Loss: 0.4588, BCE Sup Loss: 0.54628
Epoch 79, iter 2397, Dice Sup Loss: 0.43031, BCE Sup Loss: 0.67384
Epoch 79, iter 2398, Dice Sup Loss: 0.52436, BCE Sup Loss: 0.60024
Epoch 79, iter 2399, Dice Sup Loss: 0.48042, BCE Sup Loss: 0.63004
Epoch 79, iter 2400, Dice Sup Loss: 0.10208, BCE Sup Loss: 0.09655
Epoch 79, Total train step 2399 || AVG_loss: 0.5145, Avg Dice score: 0.1185, Avg IOU: 0.0736
Epoch 79, Validation || sum_loss: 0.99388, Dice score: 0.1663, IOU: 0.1039
Training and evaluating on epoch79 complete in 0m 7s
Complete training ---------------------------------------------------- 
 The best epoch is 27
========================================================================================
Test || Average loss: 0.99689, Dice score: 0.1701, IOU: 0.1065
